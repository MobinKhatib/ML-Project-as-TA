{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Simulation Question 8.**\n",
        "Attempt to train an attacker model for the given private model\n",
        "(private_model.pth). We will test it on our dataset during the online presentation session. A\n",
        "competitive bonus point is available for the best performance."
      ],
      "metadata": {
        "id": "kF90FNgsSkbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import joblib\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "hu-_aP4veOLy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jwz9tZKKefJ2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='../cifar10', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='../cifar10', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo2Lc9ivefmA",
        "outputId": "54845789-506e-4a68-9fae-b1d03871c78f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 40899746.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../cifar10/cifar-10-python.tar.gz to ../cifar10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])"
      ],
      "metadata": {
        "id": "2H2ES-92fai7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5NzI2Z-fPoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MembershipInferenceAttack:\n",
        "    def __init__(self, train_dataset, test_dataset, target_model, device, epochs=5, num_shadow_models=5, overlap_percent=0.1):\n",
        "        self.target_model = target_model\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.device = device\n",
        "        self.epochs = epochs\n",
        "        self.num_shadow_models = num_shadow_models\n",
        "        self.overlap_percent = overlap_percent\n",
        "\n",
        "        self.shadow_models = []\n",
        "        self.shadow_model_splits = []\n",
        "        self.shadow_model_indices = []  # To save the indices of each shadow model's training set\n",
        "        self.remaining_indices = []  # To save the indices of data not in shadow models' training sets\n",
        "\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.batch_size = 64\n",
        "        self.train_loader = DataLoader(self.train_dataset, batch_size = self.batch_size, shuffle=True)\n",
        "        #self.test_loader = DataLoader(self.test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        self.attack_models = []\n",
        "        self.attack_data = [[] for _ in range(10)]\n",
        "        self.attack_labels = [[] for _ in range(10)]\n",
        "\n",
        "    def select_high_confidence_records(self, threshold=0.9):\n",
        "        self.target_model.to(self.device)\n",
        "        data_loader = self.train_loader\n",
        "        model = self.target_model\n",
        "        high_confidence_indices = []\n",
        "\n",
        "        j = 0\n",
        "        for inputs, labels in data_loader:\n",
        "            j += 1\n",
        "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "                max_probs, preds = torch.max(probabilities, dim=1)\n",
        "\n",
        "                for i in range(len(inputs)):\n",
        "                    if max_probs[i].item() >= threshold:\n",
        "                        high_confidence_indices.append( (j-1)*self.batch_size + i)  # Save index instead of data\n",
        "\n",
        "        print(len(high_confidence_indices))\n",
        "        print(np.shape(high_confidence_indices))\n",
        "\n",
        "        return high_confidence_indices\n",
        "\n",
        "    def stratified_split_indices(self, indices):\n",
        "\n",
        "        self.shadow_model_splits = []\n",
        "        self.shadow_model_indices = []  # To save the indices of each shadow model's training set\n",
        "        self.remaining_indices = []  # To save the indices of data not in shadow models' training sets\n",
        "\n",
        "        num_splits = self.num_shadow_models\n",
        "        overlap_percent = self.overlap_percent\n",
        "        unique_classes = np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "        split_indices = [[] for _ in range(num_splits)]\n",
        "        remaining_indices_per_split = [[] for _ in range(num_splits)]\n",
        "        #overlap_count = int(overlap_percent * self.num_shadow_models / num_splits)\n",
        "        overlap_count = 0\n",
        "\n",
        "        for cls in unique_classes:\n",
        "            print(\"cls=\",cls)\n",
        "            cls_indices = [i for i in indices if self.train_dataset.targets[i] == int(cls)]\n",
        "            print(cls_indices)\n",
        "            print(len(cls_indices))\n",
        "            print()\n",
        "            random.shuffle(cls_indices)\n",
        "\n",
        "            split_cls_indices = np.array_split(cls_indices, num_splits)\n",
        "\n",
        "            for i in range(num_splits):\n",
        "                split_indices[i].extend(split_cls_indices[i])\n",
        "\n",
        "                if overlap_count > 0:\n",
        "                    remaining_indices = list(set(cls_indices) - set(split_cls_indices[i]))\n",
        "                    overlap_indices = random.sample(remaining_indices, min(overlap_count, len(remaining_indices)))\n",
        "                    split_indices[i].extend(overlap_indices)\n",
        "\n",
        "        self.shadow_model_splits = split_indices\n",
        "\n",
        "        # Calculate non-shadow indices for each split\n",
        "        for i in range(num_splits):\n",
        "            all_shadow_indices = set(split_indices[i])\n",
        "            remaining_indices_per_split[i] = list(set(indices) - all_shadow_indices)\n",
        "\n",
        "        self.remaining_indices = remaining_indices_per_split\n",
        "\n",
        "        return self.shadow_model_splits\n",
        "\n",
        "    def create_shadow_models(self):\n",
        "        self.shadow_models = []\n",
        "        dataset = self.train_dataset\n",
        "        split_indices = self.shadow_model_splits\n",
        "        #shadow_model_data = []\n",
        "\n",
        "        for i in range(self.num_shadow_models):\n",
        "            indices = split_indices[i]\n",
        "            self.shadow_model_indices.append(indices)  # Save the indices used for this shadow model\n",
        "            shadow_dataset = Subset(dataset, indices)\n",
        "            shadow_loader = DataLoader(shadow_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "            # Train the shadow model\n",
        "            model = CIFAR10Classifier().to(self.device)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "            loss = 0\n",
        "            for epoch in range(self.epochs):\n",
        "                model.train()\n",
        "                for inputs, labels in shadow_loader:\n",
        "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                print(\"shadow model:\",i,\" epoch:\",epoch,\" loss=\", loss.item())\n",
        "            print()\n",
        "\n",
        "            self.shadow_models.append(model)\n",
        "            #shadow_model_data.append((shadow_loader, model))\n",
        "\n",
        "        pass\n",
        "\n",
        "    def set_shadow_model(self, index, model):\n",
        "        self.shadow_models[index] = model\n",
        "\n",
        "    def prepare_attack_data(self):\n",
        "        attack_data = [[] for _ in range(10)]\n",
        "        attack_labels = [[] for _ in range(10)]\n",
        "\n",
        "        for cls in range(10):\n",
        "            print(\"cls=\",cls)\n",
        "            for shadow_idx in range(self.num_shadow_models):\n",
        "                print(\"shadow model=\",shadow_idx+1)\n",
        "                shadow_model = self.shadow_models[shadow_idx]\n",
        "                shadow_model.eval()\n",
        "                shadow_indices = [idx for idx in self.shadow_model_indices[shadow_idx] if self.train_dataset.targets[idx] == cls]\n",
        "\n",
        "                shadow_data_loader = DataLoader(Subset(self.train_dataset, shadow_indices), batch_size=64, shuffle=False)\n",
        "\n",
        "                # Prepare test data loader including test set with the same length as shadow_indices\n",
        "                test_indices_cls = [idx for idx, label in enumerate(self.test_dataset.targets) if label == cls]\n",
        "                random.shuffle(test_indices_cls)\n",
        "                test_indices_cls = test_indices_cls[:len(shadow_indices)]\n",
        "\n",
        "                #print(len(shadow_indices))\n",
        "                #print(len(test_indices_cls))\n",
        "\n",
        "                test_data_loader = DataLoader(Subset(self.test_dataset, test_indices_cls), batch_size=64, shuffle=False)\n",
        "\n",
        "                for inputs, labels in shadow_data_loader:\n",
        "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = shadow_model(inputs)\n",
        "                        #max_probs, preds = torch.max(probabilities, dim=1)\n",
        "\n",
        "                        for i in range(len(inputs)):\n",
        "                                attack_data[cls].append(outputs[i].cpu().numpy())\n",
        "                                attack_labels[cls].append(1)  # Label as in the training set\n",
        "\n",
        "                for inputs, labels in test_data_loader:\n",
        "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = shadow_model(inputs)\n",
        "\n",
        "                        for i in range(len(inputs)):\n",
        "                                attack_data[cls].append(outputs[i].cpu().numpy())\n",
        "                                attack_labels[cls].append(0)  # Label as not in the training set\n",
        "\n",
        "        self.attack_data = attack_data\n",
        "        self.attack_labels = attack_labels\n",
        "\n",
        "        pass\n",
        "\n",
        "    def train_attack_models(self, epochs=10):\n",
        "            for cls in range(10):\n",
        "                print(cls)\n",
        "                attack_data_array = np.array(self.attack_data[cls])\n",
        "                attack_labels_array = np.array(self.attack_labels[cls])\n",
        "                print(len(attack_data_array))\n",
        "                print(len(attack_labels_array))\n",
        "\n",
        "                attack_model = RandomForestClassifier(n_estimators=100)\n",
        "                attack_model.fit(attack_data_array.reshape(len(attack_data_array), -1), attack_labels_array)\n",
        "\n",
        "                self.attack_models.append(attack_model)\n",
        "\n",
        "\n",
        "\n",
        "    def predict_membership(self, target_model, test_loader):\n",
        "        predictions = []\n",
        "        target_model.eval()  # Set the target model to evaluation mode\n",
        "        softmax_outputs = []\n",
        "\n",
        "        for inputs, _ in test_loader:\n",
        "            inputs = inputs.to(self.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = target_model(inputs)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "                all_outputs.extend(outputs.cpu().numpy())\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(test_loader.dataset):\n",
        "            cls = labels\n",
        "            attack_model = self.attack_models[cls]\n",
        "            input_data = all_outputs[i].reshape(1, -1)\n",
        "            pred = attack_model.predict(input_data)\n",
        "            print(pred)\n",
        "            predictions.append(pred[0])\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def evaluate_attack_models_just_in(self, train_indices):\n",
        "        attack_predictions = self.predict_membership(self.target_model, DataLoader(torch.utils.data.Subset(self.train_dataset, train_indices), batch_size=64, shuffle=False))\n",
        "        print(attack_predictions)\n",
        "        true_labels = [1] * len(train_indices)\n",
        "        accuracy = accuracy_score(true_labels, attack_predictions)\n",
        "        return accuracy\n",
        "\n",
        "    def evaluate_attack_models_in_and_out(self, train_indices, true_labels):\n",
        "        attack_predictions = self.predict_membership(self.target_model, DataLoader(torch.utils.data.Subset(self.train_dataset, train_indices), batch_size=64, shuffle=False))\n",
        "        print(attack_predictions)\n",
        "        print(true_labels)\n",
        "        accuracy = accuracy_score(true_labels, attack_predictions)\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "    def save_shadow_models(self, folder_path='shadow_models'):\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        for i, model in enumerate(self.shadow_models):\n",
        "            model_path = os.path.join(folder_path, f'shadow_model_{i}.pth')\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'shadow_model_indices.pkl'), 'wb') as f:\n",
        "            joblib.dump(self.shadow_model_indices, f)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'remaining_indices.pkl'), 'wb') as f:\n",
        "            joblib.dump(self.remaining_indices, f)\n",
        "\n",
        "    def load_shadow_models(self, folder_path='shadow_models'):\n",
        "        self.shadow_models = []\n",
        "        for i in range(len(os.listdir(folder_path)) - 2):  # Assuming two non-model files\n",
        "            model_path = os.path.join(folder_path, f'shadow_model_{i}.pth')\n",
        "            model = CIFAR10Classifier().to(self.device)\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "            self.shadow_models.append(model)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'shadow_model_indices.pkl'), 'rb') as f:\n",
        "            self.shadow_model_indices = joblib.load(f)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'remaining_indices.pkl'), 'rb') as f:\n",
        "            self.remaining_indices = joblib.load(f)\n",
        "\n",
        "    def save_attack_models(self, folder_path='attack_models'):\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        for i, model in enumerate(self.attack_models):\n",
        "            model_path = os.path.join(folder_path, f'attack_model_{i}.joblib')\n",
        "            joblib.dump(model, model_path)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'attack_data.pkl'), 'wb') as f:\n",
        "            joblib.dump(self.attack_data, f)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'attack_labels.pkl'), 'wb') as f:\n",
        "            joblib.dump(self.attack_labels, f)\n",
        "\n",
        "    def load_attack_models(self, folder_path='attack_models'):\n",
        "        self.attack_models = []\n",
        "        for i in range(len(os.listdir(folder_path)) - 2):  # Assuming two non-model files\n",
        "            model_path = os.path.join(folder_path, f'attack_model_{i}.joblib')\n",
        "            model = joblib.load(model_path)\n",
        "            self.attack_models.append(model)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'attack_data.pkl'), 'rb') as f:\n",
        "            self.attack_data = joblib.load(f)\n",
        "\n",
        "        with open(os.path.join(folder_path, 'attack_labels.pkl'), 'rb') as f:\n",
        "            self.attack_labels = joblib.load(f)\n",
        "\n",
        "    def upload_to_drive(self, local_folder, drive_folder):\n",
        "        drive.mount('/content/drive')\n",
        "        drive_folder_path = os.path.join('/content/drive/My Drive/', drive_folder)\n",
        "        if not os.path.exists(drive_folder_path):\n",
        "            os.makedirs(drive_folder_path)\n",
        "\n",
        "        zip_filename = local_folder + '.zip'\n",
        "        with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "            for root, _, files in os.walk(local_folder):\n",
        "                for file in files:\n",
        "                    zipf.write(os.path.join(root, file), arcname=file)\n",
        "\n",
        "        shutil.copy(zip_filename, drive_folder_path)\n",
        "\n",
        "    def download_from_drive(self, drive_folder, local_folder):\n",
        "        drive.mount('/content/drive')\n",
        "        drive_folder_path = os.path.join('/content/drive/My Drive/', drive_folder)\n",
        "        if not os.path.exists(local_folder):\n",
        "            os.makedirs(local_folder)\n",
        "\n",
        "        zip_filename = local_folder + '.zip'\n",
        "        shutil.copy(os.path.join(drive_folder_path, zip_filename), zip_filename)\n",
        "\n",
        "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(local_folder)\n"
      ],
      "metadata": {
        "id": "SGTBFyi3cAbC"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save"
      ],
      "metadata": {
        "id": "T8ZNl-2cfMUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install pydrive2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qOYoz3kfHdZ",
        "outputId": "c8a75472-0a49-432a-fb4f-b70de9cc677f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: pydrive2 in /usr/local/lib/python3.10/dist-packages (1.6.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.5 in /usr/local/lib/python3.10/dist-packages (from pydrive2) (2.84.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pydrive2) (1.16.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pydrive2) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from pydrive2) (6.0.1)\n",
            "Requirement already satisfied: pyOpenSSL>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from pydrive2) (24.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (2.16.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.12.5->pydrive2) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive2) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive2) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive2) (4.9)\n",
            "Requirement already satisfied: cryptography<43,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=19.1.0->pydrive2) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (1.63.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.12.5->pydrive2) (5.3.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.12.5->pydrive2) (3.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43,>=41.0.5->pyOpenSSL>=19.1.0->pydrive2) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.12.5->pydrive2) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "from model import CIFAR10Classifier  # Importing the model\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import gdown"
      ],
      "metadata": {
        "id": "K6_uGTLnfH1J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save the model\n",
        "def zip_model(local_path, zip_name):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
        "        zipf.write(local_path)\n",
        "\n",
        "# Define functions for Google Drive operations\n",
        "def upload_to_drive(local_path, drive_path):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    shutil.move(local_path, drive_path)\n",
        "\n",
        "def download_from_drive(drive_path, local_path):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    shutil.copy(drive_path, local_path)\n",
        "\n",
        "def unzip_model(zip_name, extract_path):\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zipf:\n",
        "        zipf.extractall(extract_path)\n",
        "\n",
        "# Function to save the model\n",
        "def save_model(model, path='cifar10_classifier.pth'):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f'Model saved to {path}')\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model, path='cifar10_classifier.pth'):\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f'Model loaded from {path}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZIc7o0VjfLjx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and zip the model\n",
        "save_model(model, 'cifar10_classifier.pth')\n",
        "zip_model('cifar10_classifier.pth', 'cifar10_classifier.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Svqy30WfzuJ",
        "outputId": "8e043990-c1aa-4ece-d45f-8ba3f9f67d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to cifar10_classifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the model to Google Drive\n",
        "upload_to_drive('cifar10_classifier.zip', '/content/drive/MyDrive/cifar10_classifier.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzcXLC21f0Vc",
        "outputId": "78d2b9e5-ce57-488e-8f52-cfecdcf3f26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model from Google Drive and unzip it\n",
        "download_from_drive('/content/drive/MyDrive/cifar10_classifier.zip', 'cifar10_classifier.zip')"
      ],
      "metadata": {
        "id": "UQ1IGj6Mf2Ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36572fc7-f991-4c1e-cbd4-068db94a32b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_model('cifar10_classifier.zip', './')"
      ],
      "metadata": {
        "id": "joiZdAWif3zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = CIFAR10Classifier().to(device)\n",
        "model = load_model(model, 'cifar10_classifier.pth')"
      ],
      "metadata": {
        "id": "aPkXlJKlf6Al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1106de-1ad2-4519-9086-2f6da3a69ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from cifar10_classifier.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "N-FQ1vWNfQ4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from model import CIFAR10Classifier"
      ],
      "metadata": {
        "id": "kKrA8an7efzo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "dJtveOSIegHp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.CIFAR10(root='../cifar10', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR10(root='../cifar10', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQq7dUqPe7Qg",
        "outputId": "30234dc7-c3ea-4cdf-b01e-abb5d6f9da1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset = torch.utils.data.ConcatDataset([trainset, testset])"
      ],
      "metadata": {
        "id": "NR_eQTqFfhje"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom Dataset to combine train and test datasets\n",
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, train_dataset, test_dataset):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.train_len = len(train_dataset)\n",
        "        self.test_len = len(test_dataset)\n",
        "        self.total_len = self.train_len + self.test_len\n",
        "\n",
        "        # Combine the targets\n",
        "        self.targets = train_dataset.targets + test_dataset.targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < self.train_len:\n",
        "            return self.train_dataset[idx]\n",
        "        else:\n",
        "            return self.test_dataset[idx - self.train_len]\n",
        "\n",
        "# Create the combined dataset\n",
        "combined_dataset = CombinedDataset(trainset, testset)"
      ],
      "metadata": {
        "id": "ji5-VCR7goCy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 10,000 random indices for the training subset\n",
        "train_indices = torch.randperm(len(trainset))[:10000]\n",
        "\n"
      ],
      "metadata": {
        "id": "L9LbbBOTe2-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = torch.utils.data.Subset(trainset, train_indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "8GOMSj3r0q4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wh9j8a53bln",
        "outputId": "e595f090-6cd6-4f83-b0b8-94dbbcf0c9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([28969, 32526, 17748,  ..., 41984, 44073,  2753])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = CIFAR10Classifier().to(device)\n"
      ],
      "metadata": {
        "id": "W4vxrj3afBeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "ML-JJaPQ03Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 40\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6xqXzF_FgmyI",
        "outputId": "2b5b0c83-a847-4f80-eb8d-478d64222f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'optimizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-89095b9bac47>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        model.eval()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Loss: {test_loss / len(test_loader)}')\n",
        "print(f'Test Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKS8crKZmtSQ",
        "outputId": "e4b9bcec-59d9-42fa-d35b-49a654668c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.4993273331101533\n",
            "Test Accuracy: 56.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the train indices\n",
        "with open('train_indices.pkl', 'wb') as f:\n",
        "    pickle.dump(train_indices, f)"
      ],
      "metadata": {
        "id": "KKjmAHUfgqCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def load_indices(local_path):\n",
        "    with open(local_path, 'rb') as f:\n",
        "        indices = pickle.load(f)\n",
        "    return indices\n",
        "\n",
        "# Example usage:\n",
        "local_path = 'train_indices.pkl'\n",
        "train_indices = load_indices(local_path)\n",
        "print(f'Loaded indices: {loaded_indices}')"
      ],
      "metadata": {
        "id": "wlGmj_G9pMAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c36e17-7a7f-43b4-947d-ed57abc8993e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded indices: tensor([ 8437, 12535,  6630,  ..., 41142, 48978, 46697])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack"
      ],
      "metadata": {
        "id": "yrGNH-SgogE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from model import CIFAR10Classifier\n",
        "\n",
        "# Instantiate the model\n",
        "model = CIFAR10Classifier()\n",
        "\n",
        "# Load the state dict\n",
        "state_dict = torch.load(\"model_state_dict.pth\")\n",
        "new_state_dict = {}\n",
        "for key, value in state_dict.items():\n",
        "    new_key = key.replace('_module.', '')\n",
        "    new_state_dict[new_key] = value\n",
        "\n",
        "# Load the state dict into the model\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded and set to evaluation mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vhCyM-s2ZOI",
        "outputId": "9a34d220-3bee-4ba0-8447-f8e79c1d3685"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and set to evaluation mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MembershipInferenceAttack\n",
        "mia = MembershipInferenceAttack(combined_dataset, testset, model, device, epochs=150, num_shadow_models=100)"
      ],
      "metadata": {
        "id": "Yq03o-Wfh2uM"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_records = mia.select_high_confidence_records(threshold=0.55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKQ1XNFApLqy",
        "outputId": "28b9db3f-7eed-42d2-d700-d120fb121e64"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17694\n",
            "(17694,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits = mia.stratified_split_indices(high_confidence_records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CySP-sQxpOsy",
        "outputId": "69910297-cf88-468c-a593-22fecbd872c7"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cls= 0\n",
            "[49, 93, 129, 199, 264, 308, 317, 373, 401, 453, 468, 504, 663, 694, 695, 708, 731, 782, 843, 905, 927, 1119, 1142, 1147, 1166, 1178, 1187, 1211, 1214, 1227, 1249, 1278, 1319, 1335, 1424, 1432, 1434, 1463, 1466, 1481, 1522, 1589, 1668, 1684, 1757, 1913, 1954, 1980, 2010, 2027, 2034, 2053, 2107, 2169, 2209, 2248, 2287, 2322, 2330, 2345, 2350, 2403, 2420, 2504, 2574, 2598, 2714, 2720, 2780, 2804, 2848, 2859, 2861, 2885, 2895, 2932, 2946, 2949, 2962, 2964, 2996, 3011, 3049, 3073, 3304, 3332, 3336, 3337, 3347, 3352, 3609, 3674, 3689, 3694, 3731, 3842, 3891, 3900, 3903, 3909, 3938, 3940, 3951, 3962, 3964, 3971, 3979, 4018, 4030, 4046, 4048, 4165, 4229, 4269, 4270, 4271, 4273, 4314, 4322, 4477, 4523, 4524, 4537, 4540, 4552, 4567, 4574, 4592, 4601, 4619, 4651, 4673, 4683, 4726, 4798, 4821, 4861, 4869, 4918, 4919, 4929, 4935, 4940, 4941, 4991, 5015, 5033, 5037, 5069, 5082, 5094, 5115, 5163, 5194, 5249, 5266, 5314, 5322, 5346, 5404, 5426, 5457, 5494, 5533, 5549, 5640, 5702, 5757, 5765, 5828, 5873, 5874, 5928, 5952, 5956, 5988, 5994, 6008, 6085, 6112, 6132, 6165, 6187, 6221, 6242, 6260, 6313, 6328, 6370, 6376, 6393, 6428, 6503, 6504, 6650, 6711, 6735, 6833, 6904, 6919, 6929, 6954, 6973, 7060, 7179, 7263, 7299, 7311, 7360, 7409, 7462, 7464, 7490, 7509, 7528, 7530, 7547, 7592, 7643, 7654, 7655, 7660, 7674, 7731, 7747, 7782, 7792, 7810, 7842, 7859, 7907, 7925, 7970, 7972, 8079, 8099, 8155, 8190, 8199, 8207, 8209, 8242, 8313, 8355, 8365, 8376, 8387, 8421, 8437, 8453, 8478, 8553, 8623, 8638, 8660, 8695, 8748, 8753, 8782, 8833, 8842, 8868, 8925, 8994, 9062, 9064, 9157, 9171, 9230, 9236, 9312, 9314, 9325, 9328, 9362, 9373, 9379, 9384, 9385, 9401, 9413, 9438, 9464, 9493, 9512, 9542, 9566, 9596, 9604, 9616, 9666, 9767, 9799, 9800, 9831, 9860, 9881, 9890, 9895, 9905, 9920, 9925, 9966, 10008, 10124, 10148, 10151, 10197, 10205, 10243, 10267, 10330, 10334, 10355, 10394, 10399, 10455, 10499, 10690, 10764, 10811, 10867, 10872, 11018, 11023, 11031, 11056, 11078, 11122, 11178, 11218, 11224, 11229, 11240, 11280, 11304, 11305, 11356, 11372, 11374, 11400, 11425, 11431, 11440, 11479, 11509, 11514, 11554, 11572, 11612, 11615, 11618, 11661, 11682, 11775, 11844, 11849, 11887, 11913, 11946, 12009, 12010, 12028, 12030, 12052, 12056, 12083, 12121, 12131, 12133, 12165, 12226, 12230, 12252, 12270, 12297, 12325, 12328, 12345, 12363, 12375, 12430, 12469, 12492, 12493, 12542, 12634, 12668, 12730, 12757, 12764, 12767, 12802, 12807, 12808, 12817, 12818, 12883, 12922, 12944, 12960, 13030, 13060, 13068, 13090, 13206, 13248, 13289, 13326, 13348, 13401, 13434, 13457, 13473, 13507, 13522, 13570, 13613, 13716, 13747, 13801, 13833, 13861, 13876, 13894, 13902, 13937, 13951, 14056, 14079, 14138, 14153, 14169, 14190, 14210, 14216, 14329, 14335, 14341, 14350, 14365, 14393, 14407, 14413, 14434, 14456, 14460, 14479, 14486, 14488, 14567, 14585, 14592, 14689, 14732, 14754, 14806, 14807, 14867, 14898, 14945, 14949, 15003, 15113, 15147, 15149, 15153, 15225, 15333, 15352, 15414, 15439, 15466, 15571, 15581, 15623, 15677, 15689, 15707, 15767, 15827, 15866, 15870, 15931, 15946, 15959, 15992, 16002, 16011, 16048, 16060, 16100, 16113, 16182, 16191, 16235, 16297, 16313, 16487, 16511, 16552, 16553, 16567, 16579, 16625, 16634, 16637, 16733, 16801, 16825, 16838, 16965, 17071, 17082, 17093, 17115, 17133, 17166, 17174, 17178, 17226, 17353, 17357, 17395, 17396, 17453, 17490, 17517, 17573, 17620, 17633, 17948, 18073, 18102, 18105, 18133, 18192, 18203, 18215, 18218, 18298, 18302, 18306, 18315, 18386, 18406, 18436, 18505, 18508, 18545, 18605, 18657, 18680, 18694, 18710, 18735, 18745, 18763, 18765, 18831, 18849, 18854, 18893, 18940, 18953, 18955, 18979, 18999, 19004, 19009, 19011, 19066, 19116, 19173, 19196, 19210, 19277, 19282, 19332, 19386, 19409, 19480, 19492, 19493, 19503, 19527, 19554, 19632, 19633, 19634, 19682, 19740, 19741, 19749, 19778, 19814, 19860, 19884, 19942, 19945, 19988, 20014, 20023, 20180, 20205, 20256, 20262, 20265, 20275, 20319, 20379, 20383, 20398, 20404, 20452, 20471, 20473, 20523, 20537, 20566, 20584, 20611, 20622, 20658, 20708, 20710, 20759, 20817, 20824, 20852, 20862, 20973, 20976, 21012, 21023, 21044, 21071, 21074, 21087, 21119, 21143, 21227, 21248, 21259, 21272, 21275, 21310, 21440, 21469, 21522, 21539, 21594, 21634, 21758, 21774, 21825, 21865, 21869, 21874, 21878, 21930, 21974, 21975, 22080, 22109, 22112, 22123, 22142, 22189, 22238, 22257, 22276, 22293, 22329, 22350, 22449, 22506, 22609, 22645, 22648, 22674, 22690, 22796, 22800, 22904, 22924, 22962, 22967, 22973, 22997, 23002, 23004, 23021, 23043, 23163, 23171, 23175, 23182, 23352, 23386, 23446, 23462, 23481, 23485, 23581, 23644, 23684, 23767, 23776, 23797, 23848, 23854, 23891, 23899, 23952, 24111, 24158, 24163, 24179, 24258, 24285, 24291, 24325, 24333, 24361, 24365, 24387, 24395, 24404, 24420, 24445, 24447, 24488, 24491, 24534, 24557, 24581, 24587, 24605, 24639, 24677, 24681, 24690, 24700, 24750, 24764, 24793, 24834, 24859, 24887, 25037, 25066, 25189, 25243, 25275, 25288, 25422, 25462, 25502, 25532, 25538, 25546, 25574, 25605, 25609, 25615, 25624, 25644, 25668, 25696, 25712, 25719, 25748, 25763, 25807, 25820, 25862, 25891, 25905, 26000, 26018, 26045, 26081, 26083, 26164, 26200, 26207, 26286, 26322, 26332, 26341, 26427, 26493, 26499, 26505, 26522, 26571, 26693, 26708, 26724, 26776, 26815, 26840, 26842, 26922, 27026, 27042, 27048, 27075, 27080, 27104, 27147, 27176, 27179, 27278, 27312, 27315, 27324, 27375, 27425, 27431, 27571, 27609, 27639, 27681, 27706, 27777, 27850, 27855, 27908, 27931, 27940, 27944, 27961, 27986, 28003, 28009, 28025, 28052, 28080, 28140, 28178, 28179, 28208, 28273, 28300, 28320, 28354, 28408, 28487, 28512, 28548, 28558, 28570, 28699, 28716, 28817, 28917, 28921, 28966, 28978, 29039, 29060, 29173, 29174, 29190, 29219, 29225, 29244, 29274, 29280, 29289, 29336, 29341, 29348, 29364, 29380, 29400, 29412, 29487, 29492, 29505, 29593, 29666, 29717, 29724, 29729, 29748, 29754, 29783, 29803, 29837, 29856, 29860, 29880, 29888, 29927, 29941, 29977, 30029, 30048, 30141, 30158, 30200, 30233, 30272, 30297, 30324, 30378, 30429, 30487, 30535, 30597, 30695, 30743, 30820, 30837, 30924, 30979, 31029, 31048, 31119, 31164, 31165, 31207, 31246, 31286, 31369, 31450, 31488, 31648, 31654, 31674, 31726, 31837, 31855, 31863, 31896, 31904, 31947, 32173, 32188, 32206, 32217, 32218, 32220, 32247, 32283, 32309, 32318, 32346, 32363, 32403, 32411, 32484, 32522, 32592, 32602, 32613, 32670, 32721, 32744, 32830, 32884, 32885, 32905, 32967, 33000, 33003, 33058, 33062, 33117, 33128, 33130, 33249, 33325, 33360, 33363, 33380, 33386, 33419, 33451, 33471, 33489, 33509, 33514, 33589, 33647, 33662, 33728, 33767, 33797, 33831, 33857, 33864, 33895, 33919, 33923, 33934, 33960, 33996, 34002, 34009, 34012, 34019, 34106, 34150, 34190, 34201, 34270, 34279, 34280, 34313, 34381, 34459, 34601, 34607, 34627, 34693, 34705, 34745, 34780, 34831, 34917, 34944, 34998, 35089, 35132, 35279, 35317, 35343, 35354, 35369, 35411, 35456, 35475, 35551, 35553, 35554, 35599, 35633, 35713, 35731, 35761, 35796, 35820, 35846, 35858, 35929, 35952, 35973, 35996, 36055, 36106, 36148, 36228, 36252, 36322, 36363, 36370, 36374, 36389, 36393, 36491, 36506, 36530, 36531, 36545, 36574, 36621, 36698, 36763, 36786, 36819, 36862, 36886, 36909, 36924, 36955, 36981, 37022, 37032, 37035, 37039, 37041, 37063, 37066, 37068, 37181, 37199, 37233, 37279, 37322, 37330, 37334, 37358, 37377, 37432, 37493, 37517, 37519, 37532, 37566, 37674, 37693, 37728, 37729, 37738, 37747, 37758, 37772, 37788, 37806, 37843, 37867, 37905, 37944, 37950, 37955, 37978, 38000, 38003, 38039, 38051, 38052, 38185, 38190, 38198, 38205, 38222, 38233, 38312, 38321, 38335, 38387, 38419, 38478, 38479, 38566, 38681, 38716, 38748, 38772, 38796, 38828, 38921, 38948, 38970, 38977, 39006, 39056, 39059, 39076, 39121, 39138, 39201, 39241, 39431, 39530, 39531, 39553, 39619, 39650, 39725, 39739, 39763, 39780, 39815, 39819, 39863, 39875, 39966, 40104, 40113, 40245, 40320, 40349, 40401, 40420, 40482, 40525, 40526, 40535, 40548, 40556, 40612, 40618, 40621, 40639, 40644, 40733, 40851, 40861, 40867, 40873, 40906, 40928, 40984, 41055, 41118, 41121, 41131, 41146, 41167, 41179, 41242, 41324, 41355, 41414, 41456, 41524, 41557, 41574, 41588, 41613, 41677, 41740, 41745, 41756, 41762, 41848, 41851, 41868, 41879, 41907, 41932, 41971, 42019, 42103, 42105, 42148, 42190, 42201, 42204, 42231, 42241, 42272, 42283, 42288, 42320, 42332, 42361, 42376, 42379, 42435, 42493, 42519, 42566, 42569, 42572, 42576, 42621, 42678, 42786, 42804, 42808, 42829, 42867, 42883, 42931, 42984, 43002, 43012, 43037, 43076, 43138, 43160, 43211, 43220, 43266, 43288, 43292, 43342, 43454, 43475, 43483, 43508, 43525, 43649, 43670, 43777, 43909, 43924, 43951, 43967, 43980, 43992, 43993, 44031, 44037, 44067, 44116, 44175, 44307, 44426, 44494, 44498, 44609, 44618, 44645, 44668, 44680, 44715, 44719, 44746, 44749, 44771, 44778, 44794, 44806, 44820, 44866, 44875, 44940, 44967, 45035, 45064, 45096, 45106, 45143, 45163, 45166, 45232, 45233, 45242, 45262, 45270, 45313, 45357, 45364, 45373, 45384, 45387, 45391, 45412, 45438, 45484, 45509, 45615, 45679, 46041, 46046, 46287, 46294, 46303, 46324, 46343, 46362, 46434, 46439, 46458, 46480, 46513, 46585, 46593, 46614, 46632, 46655, 46678, 46725, 46740, 46831, 46864, 46876, 46910, 46922, 46945, 46949, 46964, 46969, 47017, 47042, 47050, 47061, 47068, 47207, 47215, 47220, 47227, 47271, 47320, 47326, 47329, 47332, 47336, 47355, 47428, 47458, 47550, 47557, 47560, 47579, 47581, 47599, 47617, 47676, 47678, 47685, 47726, 47740, 47805, 47931, 48009, 48119, 48174, 48209, 48254, 48289, 48318, 48355, 48415, 48419, 48430, 48470, 48485, 48508, 48514, 48557, 48560, 48580, 48587, 48748, 48792, 48842, 48847, 48861, 48869, 48939, 49018, 49050, 49091, 49092, 49128, 49164, 49219, 49236, 49245, 49255, 49339, 49340, 49344, 49346, 49375, 49387, 49410, 49420, 49490, 49511, 49555, 49557, 49633, 49651, 49656, 49671, 49711, 49734, 49761, 49856, 49863, 49869, 49891, 49921, 49992, 50003, 50027, 50098, 50154, 50179, 50189, 50206, 50264, 50284, 50287, 50297, 50313, 50359, 50382, 50406, 50423, 50473, 50477, 50489, 50499, 50526, 50560, 50638, 50675, 50689, 50742, 50912, 50919, 50929, 50982, 51022, 51023, 51052, 51078, 51197, 51295, 51409, 51440, 51446, 51461, 51463, 51555, 51573, 51651, 51686, 51694, 51714, 51718, 51726, 51728, 51735, 51739, 51796, 51819, 51823, 51835, 51875, 51879, 51902, 51949, 52041, 52058, 52085, 52087, 52098, 52110, 52215, 52324, 52344, 52368, 52370, 52463, 52473, 52490, 52548, 52594, 52614, 52628, 52672, 52674, 52679, 52715, 52749, 52782, 52857, 52913, 53048, 53050, 53087, 53117, 53184, 53211, 53302, 53335, 53336, 53342, 53412, 53425, 53426, 53429, 53441, 53445, 53467, 53499, 53651, 53680, 53740, 53754, 53761, 53765, 53823, 53866, 53897, 53955, 53965, 54104, 54167, 54192, 54226, 54228, 54270, 54328, 54374, 54387, 54426, 54450, 54453, 54470, 54490, 54548, 54557, 54666, 54701, 54759, 54792, 54802, 54809, 54901, 54937, 54953, 54968, 54991, 55013, 55037, 55043, 55055, 55124, 55126, 55190, 55224, 55255, 55259, 55260, 55278, 55293, 55295, 55310, 55339, 55357, 55454, 55544, 55571, 55584, 55585, 55618, 55679, 55703, 55722, 55806, 55891, 55948, 56001, 56036, 56057, 56061, 56091, 56105, 56146, 56157, 56221, 56241, 56261, 56306, 56363, 56408, 56418, 56434, 56480, 56544, 56574, 56588, 56601, 56623, 56660, 56729, 56772, 56797, 56815, 56821, 56824, 56872, 56877, 56884, 56966, 56970, 56985, 57018, 57031, 57103, 57116, 57139, 57246, 57289, 57315, 57347, 57373, 57419, 57453, 57513, 57533, 57594, 57648, 57681, 57748, 57754, 57800, 57803, 57811, 57838, 57861, 57869, 57900, 57960, 57987, 57994, 58007, 58024, 58026, 58047, 58048, 58063, 58073, 58197, 58210, 58230, 58267, 58397, 58476, 58554, 58592, 58743, 58761, 58800, 58828, 58862, 58884, 58894, 58895, 58909, 58925, 58993, 59008, 59017, 59021, 59024, 59031, 59045, 59065, 59086, 59182, 59196, 59235, 59248, 59272, 59326, 59356, 59459, 59515, 59558, 59565, 59590, 59700, 59724, 59749, 59772, 59818, 59826, 59876, 59912, 59921, 59931, 59954, 59980]\n",
            "1756\n",
            "\n",
            "cls= 1\n",
            "[5, 32, 45, 65, 79, 94, 97, 119, 134, 137, 140, 206, 301, 302, 323, 389, 461, 493, 506, 524, 536, 576, 599, 606, 617, 835, 841, 917, 936, 991, 997, 1006, 1020, 1029, 1064, 1068, 1079, 1287, 1301, 1320, 1421, 1520, 1551, 1559, 1574, 1611, 1631, 1694, 1724, 1731, 1820, 1946, 1985, 2023, 2180, 2184, 2185, 2186, 2200, 2227, 2283, 2289, 2445, 2511, 2570, 2582, 2587, 2615, 2656, 2771, 2775, 2828, 2837, 2841, 2887, 2910, 2928, 3034, 3062, 3072, 3085, 3120, 3131, 3142, 3183, 3273, 3378, 3386, 3404, 3415, 3467, 3483, 3555, 3601, 3605, 3659, 3743, 3744, 3822, 3830, 3836, 3851, 3871, 3886, 3922, 3924, 3934, 4013, 4047, 4084, 4250, 4332, 4363, 4379, 4390, 4443, 4444, 4458, 4464, 4496, 4500, 4557, 4560, 4562, 4565, 4609, 4625, 4661, 4764, 4775, 4803, 4858, 4932, 5052, 5070, 5084, 5099, 5197, 5207, 5236, 5261, 5301, 5356, 5438, 5459, 5460, 5512, 5559, 5568, 5627, 5663, 5683, 5709, 5747, 5769, 5811, 5822, 5831, 5834, 5971, 5975, 6031, 6040, 6074, 6120, 6130, 6141, 6161, 6191, 6196, 6269, 6318, 6366, 6371, 6420, 6446, 6515, 6534, 6589, 6673, 6709, 6725, 6731, 6765, 6786, 6819, 6820, 6851, 6899, 6915, 6933, 6967, 6969, 6971, 7005, 7148, 7238, 7297, 7300, 7338, 7342, 7352, 7370, 7371, 7374, 7375, 7408, 7430, 7495, 7529, 7579, 7600, 7673, 7707, 7740, 7821, 7913, 8090, 8094, 8107, 8119, 8124, 8135, 8191, 8216, 8232, 8294, 8346, 8563, 8573, 8607, 8690, 8796, 8809, 8855, 8856, 8965, 8995, 9048, 9056, 9210, 9216, 9232, 9251, 9252, 9266, 9318, 9327, 9392, 9407, 9439, 9442, 9459, 9494, 9509, 9534, 9549, 9565, 9584, 9595, 9602, 9658, 9668, 9717, 9781, 9849, 9894, 9898, 9918, 9946, 9988, 10039, 10054, 10074, 10090, 10133, 10190, 10236, 10248, 10249, 10298, 10352, 10377, 10450, 10491, 10531, 10544, 10571, 10576, 10614, 10630, 10644, 10711, 10714, 10748, 10771, 10795, 10797, 10868, 10912, 11082, 11109, 11130, 11134, 11196, 11361, 11407, 11444, 11470, 11522, 11579, 11585, 11614, 11645, 11646, 11683, 11696, 11787, 11824, 11831, 11890, 11971, 12027, 12038, 12047, 12100, 12150, 12158, 12167, 12170, 12247, 12264, 12283, 12306, 12311, 12360, 12373, 12384, 12470, 12494, 12516, 12575, 12732, 12741, 12849, 12865, 12917, 12929, 12949, 12964, 12981, 13010, 13056, 13099, 13118, 13158, 13166, 13242, 13262, 13296, 13317, 13332, 13402, 13422, 13444, 13462, 13468, 13523, 13543, 13555, 13558, 13608, 13615, 13740, 13742, 13821, 13845, 13849, 13968, 13973, 13994, 13997, 13999, 14048, 14067, 14068, 14092, 14117, 14238, 14339, 14358, 14378, 14381, 14384, 14417, 14448, 14455, 14470, 14481, 14524, 14546, 14549, 14598, 14643, 14716, 14721, 14722, 14859, 14874, 14890, 14900, 14966, 14978, 15069, 15261, 15281, 15295, 15308, 15315, 15381, 15394, 15423, 15456, 15462, 15496, 15506, 15518, 15559, 15577, 15610, 15646, 15692, 15738, 15779, 15814, 15832, 15855, 15867, 15885, 15966, 15984, 16023, 16036, 16063, 16087, 16128, 16258, 16275, 16299, 16310, 16331, 16338, 16365, 16400, 16412, 16437, 16471, 16490, 16576, 16594, 16629, 16679, 16710, 16723, 16766, 16774, 16800, 16813, 16850, 16853, 16882, 16925, 16937, 16958, 16964, 16990, 17017, 17031, 17111, 17128, 17219, 17244, 17255, 17269, 17279, 17294, 17334, 17384, 17397, 17409, 17461, 17471, 17515, 17534, 17553, 17558, 17580, 17609, 17626, 17694, 17700, 17701, 17750, 17755, 17760, 17771, 17772, 17781, 17860, 17867, 17893, 17924, 17950, 17995, 18063, 18097, 18117, 18134, 18178, 18181, 18206, 18247, 18331, 18377, 18413, 18456, 18480, 18495, 18526, 18551, 18562, 18583, 18594, 18639, 18654, 18716, 18744, 18844, 18859, 18879, 18932, 18994, 19002, 19063, 19095, 19125, 19143, 19166, 19185, 19202, 19301, 19310, 19313, 19324, 19341, 19351, 19363, 19457, 19481, 19484, 19490, 19581, 19594, 19626, 19667, 19760, 19862, 19939, 19971, 20047, 20107, 20114, 20214, 20244, 20245, 20311, 20351, 20368, 20442, 20494, 20546, 20554, 20592, 20619, 20731, 20752, 20761, 20774, 20796, 20811, 20829, 20835, 20840, 20857, 20914, 20937, 20988, 20994, 21003, 21014, 21027, 21056, 21073, 21080, 21104, 21118, 21142, 21154, 21180, 21206, 21245, 21270, 21283, 21293, 21328, 21331, 21333, 21397, 21398, 21416, 21422, 21429, 21437, 21498, 21563, 21651, 21653, 21662, 21685, 21808, 21813, 21850, 21877, 21971, 22013, 22054, 22060, 22070, 22072, 22165, 22217, 22221, 22292, 22303, 22306, 22314, 22358, 22365, 22372, 22379, 22388, 22395, 22396, 22419, 22422, 22450, 22522, 22545, 22552, 22564, 22659, 22710, 22762, 22790, 22816, 22829, 22867, 22938, 22943, 22982, 22984, 22998, 23006, 23088, 23107, 23156, 23160, 23164, 23198, 23210, 23213, 23260, 23275, 23311, 23313, 23345, 23361, 23379, 23391, 23423, 23489, 23500, 23514, 23564, 23709, 23752, 23812, 23832, 23850, 23897, 23936, 23959, 23982, 23983, 24003, 24008, 24010, 24041, 24157, 24194, 24219, 24220, 24228, 24247, 24255, 24263, 24268, 24284, 24288, 24292, 24342, 24425, 24450, 24484, 24512, 24528, 24540, 24541, 24566, 24579, 24602, 24620, 24654, 24665, 24746, 24762, 24767, 24863, 24932, 24965, 24968, 24999, 25071, 25105, 25117, 25135, 25137, 25150, 25201, 25245, 25306, 25377, 25428, 25463, 25534, 25600, 25718, 25731, 25827, 25881, 25926, 25961, 26008, 26065, 26074, 26077, 26080, 26127, 26141, 26168, 26180, 26230, 26294, 26295, 26310, 26344, 26465, 26471, 26491, 26509, 26519, 26601, 26636, 26729, 26741, 26787, 26818, 26877, 26994, 27037, 27099, 27132, 27178, 27194, 27262, 27273, 27330, 27382, 27404, 27447, 27465, 27510, 27538, 27601, 27607, 27627, 27709, 27716, 27769, 27792, 27809, 27814, 27829, 27942, 28005, 28018, 28024, 28041, 28064, 28089, 28096, 28105, 28175, 28183, 28187, 28248, 28268, 28288, 28298, 28362, 28394, 28420, 28434, 28476, 28526, 28530, 28541, 28580, 28622, 28623, 28626, 28634, 28655, 28685, 28694, 28790, 28805, 28810, 28858, 28882, 28926, 28975, 29007, 29120, 29121, 29133, 29149, 29209, 29226, 29230, 29275, 29299, 29308, 29314, 29315, 29325, 29430, 29447, 29494, 29545, 29576, 29633, 29675, 29699, 29703, 29716, 29777, 29791, 29801, 29806, 29813, 29829, 29875, 29959, 29974, 30047, 30062, 30104, 30165, 30198, 30208, 30227, 30238, 30244, 30269, 30293, 30316, 30374, 30445, 30446, 30458, 30486, 30492, 30650, 30696, 30712, 30714, 30738, 30804, 30821, 30840, 30851, 31019, 31079, 31107, 31126, 31147, 31151, 31193, 31203, 31208, 31241, 31251, 31268, 31274, 31282, 31323, 31352, 31407, 31523, 31587, 31599, 31604, 31634, 31645, 31657, 31694, 31761, 31776, 31786, 31854, 31890, 31969, 32011, 32099, 32135, 32189, 32202, 32258, 32295, 32348, 32410, 32453, 32488, 32564, 32580, 32584, 32601, 32623, 32624, 32736, 32771, 32860, 32886, 32959, 32983, 32988, 33050, 33063, 33112, 33122, 33164, 33181, 33230, 33241, 33261, 33271, 33285, 33327, 33351, 33390, 33440, 33452, 33561, 33598, 33640, 33643, 33646, 33705, 33718, 33751, 33762, 33772, 33832, 33838, 33847, 33859, 33897, 33939, 33963, 33985, 34063, 34064, 34065, 34069, 34128, 34145, 34153, 34176, 34179, 34194, 34206, 34238, 34246, 34347, 34349, 34375, 34376, 34420, 34429, 34445, 34489, 34530, 34540, 34548, 34554, 34595, 34690, 34697, 34723, 34778, 34802, 34810, 34850, 34862, 34909, 34911, 34913, 35004, 35037, 35134, 35145, 35174, 35188, 35291, 35322, 35339, 35399, 35404, 35453, 35530, 35550, 35613, 35635, 35649, 35666, 35688, 35694, 35803, 35810, 35861, 35863, 35884, 35914, 35948, 36033, 36040, 36058, 36102, 36158, 36237, 36251, 36258, 36298, 36334, 36359, 36445, 36473, 36483, 36485, 36490, 36550, 36568, 36578, 36594, 36686, 36715, 36732, 36736, 36751, 36791, 36853, 36891, 36975, 36991, 37007, 37012, 37098, 37153, 37179, 37183, 37239, 37253, 37257, 37264, 37301, 37303, 37320, 37385, 37418, 37422, 37455, 37461, 37468, 37476, 37506, 37512, 37590, 37592, 37616, 37650, 37666, 37702, 37727, 37743, 37801, 37844, 37849, 37981, 37995, 38031, 38075, 38152, 38175, 38192, 38204, 38211, 38231, 38260, 38261, 38262, 38266, 38271, 38448, 38452, 38484, 38487, 38493, 38542, 38562, 38579, 38610, 38642, 38658, 38710, 38725, 38799, 38816, 38818, 38841, 38892, 38908, 38919, 38946, 39023, 39058, 39097, 39195, 39218, 39240, 39250, 39256, 39277, 39349, 39363, 39373, 39484, 39490, 39549, 39749, 39792, 39800, 39818, 39843, 39848, 39902, 39940, 39948, 39987, 39990, 39996, 40003, 40046, 40060, 40081, 40138, 40172, 40173, 40184, 40207, 40218, 40250, 40279, 40290, 40341, 40386, 40431, 40449, 40475, 40484, 40505, 40518, 40520, 40554, 40573, 40576, 40582, 40594, 40602, 40615, 40656, 40678, 40758, 40814, 40815, 40838, 40935, 40958, 40967, 41010, 41015, 41026, 41051, 41061, 41133, 41138, 41153, 41189, 41241, 41248, 41257, 41259, 41262, 41279, 41289, 41322, 41336, 41368, 41392, 41398, 41519, 41550, 41643, 41666, 41733, 41739, 41794, 41807, 41859, 41888, 41922, 41948, 41964, 41966, 42053, 42060, 42065, 42085, 42113, 42124, 42130, 42171, 42211, 42221, 42276, 42341, 42410, 42413, 42424, 42437, 42438, 42443, 42448, 42464, 42475, 42531, 42606, 42625, 42652, 42658, 42666, 42669, 42673, 42726, 42735, 42761, 42805, 42879, 42899, 42913, 42921, 42927, 42976, 43015, 43050, 43064, 43085, 43089, 43102, 43145, 43148, 43167, 43178, 43195, 43232, 43280, 43290, 43356, 43369, 43372, 43398, 43413, 43416, 43417, 43514, 43518, 43519, 43547, 43602, 43608, 43641, 43710, 43804, 43806, 43853, 43861, 43865, 43893, 43948, 43954, 43972, 43988, 44019, 44051, 44097, 44109, 44117, 44168, 44198, 44217, 44220, 44272, 44309, 44359, 44412, 44415, 44423, 44475, 44499, 44524, 44537, 44571, 44598, 44613, 44620, 44647, 44671, 44726, 44767, 44824, 44835, 44886, 44954, 44991, 44997, 45001, 45014, 45070, 45084, 45097, 45105, 45194, 45195, 45212, 45228, 45258, 45283, 45291, 45316, 45332, 45370, 45483, 45485, 45567, 45569, 45672, 45821, 45866, 45910, 45979, 45988, 46060, 46078, 46135, 46140, 46162, 46207, 46219, 46240, 46323, 46357, 46358, 46461, 46547, 46717, 46718, 46732, 46748, 46786, 46865, 46914, 46920, 47026, 47035, 47136, 47151, 47213, 47254, 47264, 47279, 47349, 47362, 47377, 47519, 47532, 47535, 47633, 47686, 47772, 47824, 47863, 47968, 48000, 48003, 48021, 48115, 48234, 48263, 48275, 48294, 48358, 48441, 48667, 48740, 48746, 48799, 48820, 48898, 48899, 49021, 49040, 49060, 49066, 49085, 49121, 49230, 49232, 49239, 49283, 49286, 49314, 49326, 49409, 49426, 49436, 49447, 49469, 49509, 49554, 49569, 49590, 49604, 49652, 49733, 49769, 49777, 49787, 49795, 49871, 49873, 49886, 49919, 49973, 50009, 50081, 50104, 50105, 50131, 50134, 50204, 50241, 50261, 50286, 50363, 50369, 50407, 50439, 50462, 50604, 50659, 50736, 50781, 50796, 50830, 50844, 50865, 50869, 50871, 50895, 50915, 50961, 50962, 50987, 51005, 51016, 51020, 51021, 51061, 51131, 51141, 51182, 51185, 51191, 51212, 51238, 51335, 51408, 51437, 51457, 51458, 51464, 51480, 51500, 51504, 51509, 51549, 51569, 51621, 51631, 51706, 51711, 51743, 51747, 51751, 51810, 51811, 51882, 51907, 51925, 52009, 52063, 52080, 52112, 52142, 52164, 52176, 52274, 52334, 52351, 52357, 52378, 52396, 52484, 52504, 52601, 52616, 52634, 52645, 52701, 52740, 52773, 52814, 52906, 52924, 53012, 53020, 53074, 53091, 53122, 53144, 53162, 53215, 53239, 53246, 53372, 53449, 53517, 53527, 53579, 53611, 53619, 53629, 53632, 53647, 53701, 53702, 53715, 53730, 53764, 53768, 53814, 53828, 53857, 53895, 53988, 54030, 54059, 54129, 54134, 54164, 54189, 54212, 54245, 54314, 54320, 54337, 54371, 54378, 54437, 54476, 54506, 54531, 54598, 54607, 54721, 54741, 54822, 54831, 54850, 54875, 54890, 54895, 54897, 54930, 54948, 54978, 54999, 55019, 55024, 55048, 55056, 55058, 55061, 55071, 55079, 55201, 55386, 55422, 55431, 55439, 55449, 55483, 55517, 55624, 55697, 55783, 55875, 55909, 55971, 56010, 56104, 56117, 56166, 56182, 56195, 56399, 56405, 56410, 56445, 56550, 56555, 56585, 56643, 56688, 56742, 56788, 56789, 56805, 56806, 56841, 56886, 56940, 56984, 56991, 57005, 57053, 57114, 57136, 57151, 57199, 57215, 57225, 57272, 57280, 57309, 57316, 57329, 57450, 57472, 57532, 57555, 57570, 57577, 57584, 57595, 57604, 57704, 57749, 57819, 57873, 57876, 57889, 57893, 57943, 57946, 58005, 58028, 58049, 58056, 58097, 58107, 58123, 58139, 58214, 58215, 58238, 58260, 58333, 58372, 58389, 58395, 58438, 58449, 58489, 58495, 58502, 58503, 58504, 58536, 58559, 58579, 58584, 58595, 58623, 58645, 58663, 58741, 58744, 58772, 58775, 58811, 58907, 58938, 58945, 58955, 58959, 59066, 59079, 59126, 59145, 59169, 59178, 59179, 59211, 59229, 59265, 59345, 59352, 59455, 59591, 59618, 59626, 59629, 59763, 59800, 59803, 59808, 59813, 59830, 59843, 59865, 59866, 59905, 59935]\n",
            "1794\n",
            "\n",
            "cls= 2\n",
            "[6, 41, 47, 48, 54, 55, 63, 108, 121, 138, 283, 288, 300, 335, 383, 400, 402, 421, 423, 463, 538, 558, 586, 630, 648, 673, 689, 742, 775, 796, 803, 827, 864, 889, 907, 910, 912, 986, 990, 1107, 1122, 1129, 1139, 1184, 1207, 1209, 1285, 1291, 1409, 1501, 1523, 1533, 1620, 1677, 1787, 1789, 1792, 1800, 1844, 1850, 1852, 1861, 1867, 1883, 1884, 1971, 1990, 2138, 2163, 2177, 2191, 2193, 2202, 2217, 2230, 2291, 2315, 2343, 2377, 2408, 2476, 2491, 2514, 2535, 2561, 2610, 2619, 2641, 2678, 2704, 2737, 2741, 2742, 2760, 2764, 2789, 2812, 2833, 2860, 2867, 2868, 2894, 2957, 2966, 3012, 3019, 3068, 3119, 3161, 3164, 3181, 3331, 3338, 3368, 3440, 3455, 3474, 3480, 3484, 3506, 3511, 3517, 3558, 3583, 3608, 3663, 3708, 3760, 3769, 3791, 3814, 3847, 3901, 3944, 3961, 4008, 4012, 4014, 4017, 4038, 4091, 4113, 4138, 4168, 4183, 4198, 4237, 4257, 4293, 4306, 4351, 4356, 4367, 4375, 4426, 4453, 4526, 4549, 4604, 4616, 4633, 4677, 4727, 4755, 4771, 4777, 4811, 4819, 4853, 4880, 4888, 4930, 4931, 4971, 5016, 5064, 5150, 5165, 5219, 5240, 5290, 5299, 5343, 5384, 5417, 5550, 5603, 5639, 5660, 5746, 5762, 5781, 5862, 5867, 5889, 5901, 5933, 6018, 6041, 6063, 6126, 6146, 6156, 6209, 6230, 6315, 6317, 6323, 6341, 6461, 6477, 6484, 6520, 6547, 6626, 6638, 6648, 6685, 6691, 6744, 6772, 6802, 6856, 6886, 6901, 6963, 6976, 6996, 7037, 7056, 7068, 7166, 7279, 7330, 7332, 7380, 7465, 7521, 7522, 7525, 7552, 7586, 7596, 7616, 7633, 7653, 7662, 7688, 7696, 7739, 7741, 7745, 7766, 7840, 7844, 7850, 7853, 7877, 7882, 7890, 7897, 7942, 7951, 7952, 8010, 8016, 8025, 8032, 8043, 8100, 8121, 8148, 8157, 8172, 8322, 8340, 8366, 8411, 8440, 8585, 8641, 8682, 8740, 8767, 8844, 8862, 8865, 8871, 8888, 8967, 9001, 9011, 9053, 9101, 9114, 9137, 9151, 9162, 9175, 9194, 9199, 9203, 9215, 9217, 9240, 9249, 9255, 9272, 9297, 9299, 9330, 9341, 9348, 9354, 9404, 9408, 9424, 9455, 9519, 9520, 9526, 9558, 9588, 9597, 9639, 9716, 9733, 9734, 9763, 9790, 9802, 9903, 9917, 9954, 9979, 10018, 10057, 10152, 10160, 10180, 10217, 10263, 10389, 10396, 10428, 10438, 10457, 10505, 10616, 10624, 10671, 10683, 10767, 10933, 10940, 10944, 10968, 11015, 11017, 11035, 11084, 11099, 11156, 11171, 11175, 11193, 11197, 11198, 11220, 11295, 11326, 11335, 11362, 11420, 11443, 11452, 11455, 11548, 11606, 11630, 11666, 11713, 11746, 11779, 11825, 11885, 11891, 11936, 12021, 12074, 12200, 12212, 12219, 12267, 12398, 12399, 12421, 12455, 12465, 12471, 12472, 12506, 12533, 12574, 12583, 12703, 12710, 12724, 12748, 12753, 12847, 12877, 12892, 12924, 12978, 12992, 13042, 13047, 13130, 13141, 13195, 13232, 13243, 13273, 13314, 13340, 13362, 13398, 13408, 13418, 13433, 13437, 13438, 13492, 13506, 13559, 13567, 13585, 13639, 13655, 13752, 13770, 13777, 13820, 13848, 13853, 13891, 13901, 13955, 14085, 14146, 14157, 14195, 14199, 14280, 14294, 14296, 14327, 14404, 14426, 14496, 14595, 14602, 14620, 14655, 14658, 14675, 14697, 14752, 14785, 14814, 14834, 14839, 14840, 14842, 14988, 15034, 15088, 15176, 15189, 15214, 15285, 15297, 15314, 15419, 15464, 15477, 15560, 15565, 15621, 15697, 15731, 15788, 15820, 15837, 15913, 15944, 15972, 15981, 15982, 15995, 16030, 16041, 16057, 16080, 16099, 16102, 16165, 16274, 16288, 16303, 16306, 16314, 16319, 16402, 16416, 16441, 16462, 16472, 16569, 16609, 16616, 16660, 16690, 16691, 16742, 16757, 16761, 16790, 16867, 16875, 16900, 16974, 17016, 17057, 17064, 17089, 17114, 17188, 17206, 17249, 17267, 17273, 17291, 17302, 17325, 17329, 17347, 17362, 17363, 17373, 17379, 17380, 17421, 17481, 17512, 17695, 17745, 17761, 17779, 17786, 17817, 17892, 17954, 17955, 18027, 18086, 18092, 18101, 18162, 18164, 18184, 18191, 18198, 18239, 18275, 18287, 18296, 18360, 18372, 18375, 18485, 18510, 18529, 18564, 18588, 18612, 18650, 18652, 18753, 18756, 18788, 18837, 18863, 18872, 18880, 18901, 18952, 18964, 18995, 19052, 19056, 19070, 19091, 19110, 19213, 19223, 19231, 19241, 19364, 19425, 19428, 19453, 19504, 19536, 19576, 19579, 19611, 19615, 19637, 19694, 19695, 19734, 19785, 19845, 19914, 19964, 19985, 20009, 20055, 20102, 20130, 20212, 20220, 20260, 20266, 20272, 20317, 20468, 20526, 20538, 20547, 20551, 20558, 20560, 20563, 20579, 20651, 20660, 20671, 20754, 20793, 20842, 20850, 20864, 20941, 20959, 20990, 20996, 21031, 21057, 21090, 21099, 21102, 21115, 21162, 21167, 21205, 21208, 21247, 21284, 21285, 21392, 21403, 21452, 21486, 21521, 21526, 21654, 21656, 21668, 21778, 21841, 21849, 21885, 21940, 21981, 22012, 22032, 22035, 22074, 22228, 22248, 22287, 22331, 22373, 22446, 22448, 22495, 22570, 22603, 22667, 22676, 22734, 22770, 22780, 22781, 22803, 22835, 22841, 22874, 22903, 23062, 23069, 23070, 23118, 23128, 23147, 23158, 23209, 23241, 23264, 23289, 23395, 23414, 23450, 23492, 23493, 23495, 23519, 23552, 23653, 23656, 23670, 23677, 23696, 23716, 23788, 23911, 23918, 23950, 24019, 24033, 24061, 24136, 24165, 24210, 24218, 24322, 24373, 24403, 24409, 24437, 24467, 24496, 24533, 24617, 24739, 24789, 24805, 24902, 24904, 24919, 24927, 24962, 25022, 25049, 25086, 25115, 25130, 25148, 25149, 25161, 25192, 25195, 25276, 25282, 25295, 25296, 25302, 25381, 25440, 25478, 25495, 25536, 25587, 25593, 25602, 25626, 25650, 25695, 25830, 25887, 25911, 25928, 25929, 25939, 25982, 25998, 26019, 26034, 26058, 26070, 26148, 26155, 26169, 26181, 26215, 26263, 26265, 26266, 26299, 26396, 26398, 26400, 26425, 26442, 26449, 26500, 26536, 26568, 26570, 26572, 26577, 26605, 26648, 26695, 26757, 26765, 26773, 26807, 26855, 26864, 26891, 26956, 26960, 26992, 27072, 27091, 27110, 27149, 27163, 27169, 27186, 27191, 27192, 27204, 27266, 27308, 27325, 27393, 27399, 27430, 27476, 27477, 27482, 27557, 27676, 27684, 27705, 27743, 27744, 27980, 28057, 28112, 28161, 28164, 28224, 28345, 28348, 28399, 28403, 28422, 28458, 28611, 28618, 28628, 28641, 28648, 28664, 28686, 28708, 28849, 28867, 28878, 28933, 28935, 28948, 28970, 28994, 29005, 29033, 29076, 29079, 29090, 29162, 29198, 29229, 29243, 29297, 29303, 29379, 29483, 29531, 29532, 29541, 29548, 29594, 29612, 29658, 29681, 29682, 29709, 29714, 29715, 29779, 29814, 29853, 29906, 29907, 29943, 29988, 29989, 29995, 30025, 30040, 30045, 30102, 30108, 30111, 30139, 30145, 30229, 30241, 30246, 30251, 30312, 30377, 30402, 30403, 30437, 30475, 30478, 30480, 30531, 30532, 30596, 30612, 30632, 30700, 30731, 30765, 30836, 30849, 30858, 30969, 30974, 30980, 31026, 31045, 31058, 31191, 31223, 31230, 31231, 31269, 31307, 31343, 31374, 31401, 31410, 31418, 31454, 31486, 31493, 31496, 31532, 31572, 31623, 31636, 31677, 31691, 31743, 31821, 31823, 31887, 31897, 32030, 32067, 32103, 32127, 32136, 32151, 32153, 32278, 32291, 32299, 32308, 32321, 32353, 32420, 32430, 32457, 32470, 32477, 32482, 32544, 32582, 32642, 32678, 32693, 32723, 32791, 32807, 32850, 32899, 32916, 32943, 32951, 32981, 32991, 33032, 33042, 33051, 33054, 33083, 33090, 33103, 33137, 33263, 33270, 33291, 33395, 33403, 33445, 33448, 33457, 33493, 33535, 33544, 33564, 33580, 33649, 33708, 33776, 33777, 33836, 33842, 33854, 33899, 33901, 33911, 33977, 33987, 34023, 34053, 34115, 34222, 34256, 34262, 34266, 34305, 34377, 34393, 34414, 34482, 34499, 34503, 34597, 34609, 34620, 34624, 34651, 34663, 34735, 34866, 34896, 34925, 34930, 34974, 34981, 34996, 35010, 35065, 35069, 35104, 35107, 35191, 35216, 35226, 35230, 35255, 35310, 35320, 35337, 35347, 35348, 35353, 35360, 35420, 35460, 35488, 35569, 35575, 35638, 35643, 35645, 35656, 35686, 35721, 35722, 35734, 35765, 35771, 35800, 35833, 35841, 35880, 35947, 35955, 35958, 36011, 36070, 36092, 36125, 36137, 36141, 36162, 36185, 36242, 36268, 36316, 36330, 36339, 36349, 36367, 36408, 36436, 36447, 36469, 36496, 36598, 36635, 36658, 36682, 36726, 36778, 36832, 36835, 36845, 36863, 36885, 36919, 36994, 37129, 37185, 37247, 37336, 37337, 37339, 37343, 37361, 37374, 37502, 37503, 37511, 37515, 37560, 37581, 37645, 37663, 37828, 37925, 37932, 37943, 37947, 37969, 38016, 38030, 38054, 38060, 38063, 38182, 38186, 38244, 38287, 38291, 38349, 38365, 38398, 38434, 38457, 38459, 38476, 38531, 38535, 38546, 38560, 38563, 38573, 38594, 38605, 38622, 38664, 38766, 38813, 38861, 38905, 38907, 39001, 39008, 39062, 39096, 39112, 39128, 39145, 39222, 39273, 39324, 39368, 39407, 39412, 39426, 39466, 39528, 39535, 39540, 39693, 39744, 39753, 39834, 39861, 39935, 39952, 39960, 40126, 40189, 40213, 40236, 40288, 40327, 40342, 40371, 40372, 40444, 40463, 40527, 40566, 40716, 40720, 40727, 40736, 40786, 40791, 40900, 40960, 40961, 40965, 40966, 40975, 40980, 41007, 41018, 41071, 41198, 41199, 41208, 41236, 41325, 41333, 41459, 41470, 41551, 41556, 41591, 41604, 41667, 41767, 41790, 41834, 41890, 41933, 41995, 42062, 42098, 42120, 42144, 42147, 42158, 42172, 42193, 42200, 42269, 42271, 42302, 42412, 42427, 42523, 42542, 42568, 42605, 42743, 42839, 42854, 42856, 42988, 42995, 43057, 43059, 43106, 43118, 43154, 43190, 43244, 43261, 43286, 43287, 43331, 43421, 43422, 43450, 43484, 43503, 43545, 43569, 43574, 43631, 43672, 43692, 43738, 43763, 43823, 43826, 43930, 43959, 44005, 44053, 44181, 44193, 44195, 44218, 44288, 44305, 44328, 44335, 44340, 44392, 44491, 44495, 44539, 44584, 44797, 44861, 44885, 44905, 45005, 45006, 45015, 45021, 45074, 45131, 45203, 45277, 45303, 45306, 45334, 45342, 45346, 45367, 45404, 45424, 45428, 45522, 45533, 45606, 45639, 45654, 45660, 45662, 45738, 45761, 45795, 45847, 45852, 45855, 45875, 45951, 46088, 46118, 46179, 46183, 46202, 46214, 46235, 46284, 46291, 46299, 46365, 46405, 46410, 46451, 46478, 46522, 46564, 46575, 46584, 46589, 46633, 46642, 46673, 46724, 46784, 46800, 46832, 46837, 46877, 46879, 46887, 46931, 47034, 47074, 47123, 47133, 47171, 47172, 47194, 47195, 47224, 47309, 47316, 47392, 47449, 47450, 47481, 47500, 47565, 47584, 47589, 47593, 47594, 47668, 47719, 47730, 47803, 47826, 47846, 47872, 47904, 47910, 47932, 47957, 48015, 48025, 48089, 48101, 48117, 48169, 48222, 48242, 48244, 48250, 48270, 48287, 48344, 48348, 48364, 48365, 48370, 48384, 48391, 48414, 48493, 48499, 48504, 48518, 48545, 48547, 48553, 48594, 48598, 48608, 48628, 48651, 48676, 48692, 48739, 48745, 48800, 48885, 48893, 48944, 48951, 49008, 49093, 49099, 49101, 49104, 49156, 49224, 49268, 49274, 49275, 49328, 49342, 49395, 49449, 49458, 49573, 49693, 49755, 49756, 49784, 49817, 49858, 49877, 49881, 49956, 49987, 49995, 50035, 50065, 50067, 50075, 50118, 50135, 50182, 50219, 50270, 50307, 50322, 50374, 50384, 50387, 50391, 50393, 50409, 50430, 50537, 50559, 50592, 50603, 50623, 50630, 50692, 50697, 50701, 50731, 50754, 50758, 50765, 50832, 50837, 50839, 50843, 50848, 51148, 51150, 51151, 51196, 51278, 51321, 51330, 51352, 51367, 51450, 51479, 51495, 51507, 51528, 51539, 51673, 51746, 51768, 51802, 51868, 51929, 51960, 51963, 52011, 52065, 52073, 52078, 52170, 52171, 52199, 52212, 52226, 52235, 52287, 52315, 52321, 52331, 52332, 52339, 52443, 52448, 52452, 52509, 52557, 52566, 52576, 52691, 52735, 52746, 52751, 52774, 52841, 52856, 52883, 52901, 52978, 52984, 52985, 53025, 53032, 53146, 53147, 53159, 53322, 53328, 53386, 53468, 53473, 53495, 53525, 53573, 53595, 53596, 53598, 53694, 53713, 53721, 53725, 53781, 53801, 53875, 53887, 53905, 53922, 53934, 53947, 53978, 53998, 54035, 54101, 54110, 54146, 54163, 54203, 54208, 54244, 54264, 54290, 54302, 54331, 54359, 54369, 54414, 54429, 54438, 54462, 54522, 54565, 54630, 54753, 54775, 54782, 54833, 54858, 54873, 54950, 54955, 54970, 54995, 55057, 55165, 55169, 55219, 55331, 55362, 55404, 55405, 55442, 55477, 55492, 55514, 55537, 55753, 55789, 55837, 55960, 56002, 56033, 56046, 56066, 56085, 56093, 56106, 56109, 56121, 56170, 56177, 56189, 56215, 56220, 56240, 56248, 56260, 56312, 56341, 56353, 56427, 56515, 56516, 56529, 56546, 56593, 56675, 56699, 56719, 56768, 56778, 56901, 56939, 56969, 57000, 57019, 57082, 57090, 57230, 57235, 57319, 57366, 57375, 57427, 57457, 57463, 57488, 57494, 57517, 57519, 57562, 57617, 57646, 57666, 57676, 57721, 57746, 57761, 57771, 57812, 57829, 57928, 58062, 58087, 58129, 58166, 58205, 58232, 58252, 58384, 58404, 58412, 58454, 58493, 58631, 58684, 58730, 58734, 58747, 58765, 58820, 58859, 58956, 58988, 59007, 59033, 59038, 59059, 59088, 59192, 59267, 59297, 59322, 59327, 59341, 59358, 59381, 59419, 59503, 59525, 59548, 59579, 59632, 59638, 59767, 59776, 59779, 59782, 59825, 59836, 59848, 59870, 59915, 59959, 59964, 59982]\n",
            "1807\n",
            "\n",
            "cls= 3\n",
            "[26, 59, 80, 91, 142, 150, 159, 169, 174, 251, 258, 287, 384, 494, 603, 618, 740, 785, 806, 850, 922, 941, 1041, 1104, 1121, 1150, 1164, 1252, 1257, 1461, 1499, 1511, 1528, 1554, 1556, 1603, 1696, 1700, 1785, 1815, 1864, 1879, 1888, 1892, 1938, 1963, 2011, 2051, 2057, 2137, 2141, 2162, 2165, 2198, 2307, 2312, 2353, 2359, 2530, 2564, 2665, 2781, 2930, 2931, 2986, 3087, 3134, 3242, 3248, 3289, 3302, 3328, 3340, 3373, 3472, 3475, 3550, 3552, 3591, 3594, 3615, 3728, 3749, 3758, 3792, 3795, 3801, 3813, 3863, 4033, 4072, 4087, 4089, 4102, 4128, 4146, 4151, 4174, 4177, 4179, 4221, 4243, 4268, 4392, 4402, 4428, 4465, 4472, 4481, 4484, 4531, 4542, 4697, 4760, 4772, 4796, 4799, 4876, 4954, 5007, 5008, 5080, 5086, 5097, 5106, 5107, 5110, 5113, 5209, 5242, 5319, 5321, 5329, 5354, 5425, 5455, 5539, 5541, 5545, 5578, 5592, 5610, 5615, 5664, 5713, 5720, 5741, 5799, 5848, 5896, 5966, 5980, 6045, 6061, 6089, 6162, 6167, 6199, 6208, 6263, 6284, 6306, 6309, 6351, 6368, 6405, 6422, 6507, 6511, 6557, 6637, 6684, 6714, 6790, 6812, 6837, 6847, 6849, 6883, 6905, 6936, 7004, 7006, 7050, 7107, 7125, 7128, 7132, 7161, 7180, 7205, 7235, 7259, 7309, 7343, 7355, 7367, 7369, 7426, 7427, 7432, 7439, 7483, 7485, 7500, 7517, 7519, 7533, 7551, 7566, 7567, 7651, 7665, 7680, 7681, 7814, 7835, 7893, 7906, 7909, 7928, 7931, 7997, 8000, 8011, 8013, 8056, 8082, 8104, 8162, 8193, 8251, 8262, 8302, 8336, 8349, 8370, 8385, 8408, 8420, 8434, 8503, 8507, 8520, 8629, 8680, 8686, 8761, 8822, 8876, 8978, 9006, 9040, 9052, 9073, 9111, 9129, 9152, 9183, 9185, 9228, 9283, 9293, 9304, 9305, 9307, 9338, 9371, 9394, 9405, 9429, 9612, 9613, 9632, 9656, 9710, 9720, 9794, 9830, 9842, 9856, 9865, 9904, 9927, 9944, 10005, 10011, 10044, 10125, 10135, 10137, 10143, 10186, 10189, 10254, 10310, 10322, 10418, 10430, 10439, 10462, 10464, 10534, 10575, 10611, 10634, 10653, 10745, 10749, 10770, 10809, 10814, 10929, 10948, 10949, 10960, 11183, 11188, 11222, 11234, 11236, 11257, 11268, 11294, 11339, 11344, 11353, 11379, 11386, 11419, 11476, 11498, 11531, 11564, 11623, 11628, 11668, 11680, 11718, 11724, 11736, 11743, 11763, 11764, 11855, 11864, 11969, 11976, 12007, 12042, 12105, 12118, 12147, 12174, 12215, 12216, 12241, 12255, 12278, 12391, 12425, 12436, 12475, 12500, 12546, 12552, 12595, 12598, 12612, 12618, 12631, 12707, 12750, 12783, 12786, 12823, 12853, 12872, 12969, 12988, 13001, 13013, 13019, 13053, 13064, 13085, 13091, 13167, 13189, 13202, 13204, 13247, 13259, 13287, 13328, 13329, 13349, 13458, 13502, 13533, 13590, 13601, 13678, 13750, 13811, 13826, 13857, 13913, 13953, 14014, 14018, 14030, 14031, 14064, 14091, 14107, 14118, 14148, 14155, 14161, 14234, 14253, 14313, 14419, 14422, 14454, 14543, 14605, 14651, 14706, 14730, 14800, 14817, 15010, 15057, 15127, 15138, 15226, 15279, 15298, 15313, 15321, 15341, 15397, 15417, 15453, 15467, 15471, 15603, 15614, 15641, 15642, 15682, 15706, 15741, 15778, 15807, 15826, 15829, 15856, 15858, 15882, 15967, 16014, 16035, 16120, 16154, 16164, 16190, 16209, 16296, 16301, 16308, 16322, 16335, 16339, 16364, 16366, 16418, 16427, 16432, 16449, 16502, 16522, 16547, 16586, 16604, 16628, 16680, 16722, 16796, 16808, 16814, 16817, 16827, 16869, 16871, 16904, 16932, 17003, 17036, 17046, 17067, 17096, 17098, 17144, 17164, 17184, 17195, 17243, 17251, 17322, 17333, 17365, 17381, 17401, 17440, 17455, 17530, 17540, 17557, 17567, 17615, 17631, 17644, 17661, 17835, 17919, 17920, 18089, 18109, 18111, 18119, 18147, 18186, 18240, 18283, 18286, 18335, 18362, 18371, 18373, 18400, 18410, 18412, 18442, 18446, 18452, 18462, 18486, 18497, 18499, 18531, 18582, 18673, 18684, 18769, 18814, 18865, 18896, 18960, 18993, 18998, 19075, 19093, 19126, 19140, 19151, 19187, 19221, 19246, 19352, 19412, 19422, 19577, 19578, 19589, 19649, 19738, 19771, 19787, 19795, 19820, 19827, 19864, 19872, 19920, 20007, 20067, 20091, 20143, 20151, 20163, 20194, 20196, 20208, 20271, 20301, 20335, 20337, 20339, 20346, 20390, 20397, 20401, 20431, 20448, 20507, 20520, 20528, 20529, 20531, 20571, 20577, 20591, 20601, 20630, 20648, 20721, 20932, 20963, 20968, 21053, 21070, 21122, 21239, 21250, 21347, 21351, 21402, 21459, 21462, 21468, 21501, 21544, 21574, 21578, 21625, 21652, 21686, 21712, 21724, 21728, 21739, 21769, 21832, 21873, 21882, 21914, 21982, 22028, 22110, 22143, 22161, 22302, 22368, 22377, 22402, 22406, 22420, 22460, 22484, 22505, 22507, 22512, 22523, 22555, 22634, 22662, 22664, 22700, 22759, 22768, 22778, 22793, 22850, 22851, 22855, 22914, 22929, 23033, 23122, 23145, 23202, 23228, 23235, 23239, 23250, 23253, 23261, 23306, 23353, 23365, 23389, 23401, 23417, 23443, 23483, 23590, 23690, 23702, 23735, 23761, 23807, 23974, 24060, 24065, 24077, 24081, 24099, 24135, 24147, 24154, 24192, 24262, 24276, 24301, 24305, 24317, 24337, 24348, 24364, 24384, 24443, 24490, 24518, 24522, 24560, 24562, 24565, 24571, 24606, 24618, 24634, 24696, 24704, 24705, 24727, 24779, 24803, 24817, 24871, 24906, 25006, 25028, 25058, 25062, 25074, 25077, 25103, 25184, 25218, 25219, 25246, 25254, 25256, 25259, 25273, 25376, 25380, 25384, 25492, 25509, 25535, 25570, 25633, 25639, 25640, 25642, 25663, 25706, 25726, 25738, 25771, 25772, 25953, 25983, 25986, 25997, 26005, 26009, 26043, 26064, 26106, 26111, 26126, 26132, 26154, 26160, 26183, 26189, 26210, 26244, 26283, 26453, 26539, 26556, 26557, 26558, 26573, 26575, 26613, 26657, 26688, 26726, 26813, 26849, 26859, 26912, 26939, 26964, 26974, 27013, 27021, 27064, 27069, 27077, 27090, 27118, 27212, 27222, 27235, 27246, 27263, 27275, 27297, 27304, 27317, 27407, 27432, 27441, 27467, 27525, 27620, 27658, 27683, 27698, 27702, 27714, 27766, 27779, 27786, 27876, 28028, 28055, 28083, 28190, 28214, 28242, 28437, 28447, 28477, 28529, 28556, 28592, 28631, 28698, 28731, 28786, 28792, 28819, 28824, 28880, 28891, 28942, 28964, 29004, 29074, 29082, 29113, 29177, 29200, 29201, 29215, 29260, 29273, 29498, 29567, 29638, 29662, 29780, 29865, 29960, 30058, 30059, 30097, 30192, 30386, 30459, 30479, 30490, 30541, 30571, 30606, 30687, 30777, 30779, 30784, 30806, 30809, 30848, 30933, 30986, 31050, 31065, 31078, 31134, 31148, 31194, 31204, 31242, 31260, 31337, 31346, 31400, 31406, 31415, 31440, 31479, 31535, 31584, 31606, 31610, 31626, 31649, 31676, 31698, 31712, 31731, 31754, 31797, 31900, 31908, 31923, 31940, 32075, 32139, 32155, 32172, 32219, 32222, 32250, 32264, 32293, 32371, 32372, 32392, 32404, 32405, 32504, 32524, 32682, 32808, 32826, 32846, 32881, 32998, 33007, 33031, 33033, 33092, 33098, 33132, 33168, 33169, 33177, 33267, 33280, 33301, 33329, 33337, 33346, 33355, 33463, 33484, 33511, 33709, 33876, 33882, 33917, 33952, 33956, 33972, 34011, 34016, 34099, 34155, 34170, 34236, 34294, 34297, 34317, 34361, 34397, 34439, 34479, 34486, 34496, 34501, 34510, 34581, 34590, 34647, 34658, 34710, 34771, 34801, 34835, 34858, 34952, 34984, 34999, 35016, 35026, 35083, 35124, 35130, 35163, 35215, 35229, 35272, 35293, 35296, 35359, 35380, 35437, 35442, 35532, 35541, 35581, 35582, 35669, 35715, 35790, 35836, 35913, 35919, 35960, 35994, 36043, 36051, 36054, 36066, 36087, 36157, 36159, 36211, 36230, 36249, 36275, 36414, 36422, 36477, 36527, 36543, 36601, 36624, 36707, 36745, 36772, 36781, 36800, 36822, 36828, 36930, 36948, 36970, 36980, 37038, 37162, 37175, 37180, 37187, 37215, 37217, 37251, 37271, 37367, 37410, 37414, 37510, 37513, 37554, 37584, 37631, 37640, 37697, 37756, 37776, 37861, 37951, 37965, 37967, 37983, 38006, 38012, 38066, 38095, 38126, 38127, 38147, 38171, 38200, 38209, 38246, 38364, 38377, 38423, 38472, 38485, 38557, 38626, 38654, 38673, 38702, 38811, 38829, 38887, 38894, 38903, 38992, 39033, 39045, 39108, 39130, 39152, 39158, 39175, 39187, 39194, 39211, 39272, 39366, 39375, 39384, 39410, 39428, 39500, 39526, 39575, 39651, 39665, 39751, 39789, 39850, 39862, 39868, 39972, 39979, 40129, 40226, 40232, 40263, 40354, 40362, 40378, 40400, 40404, 40446, 40511, 40546, 40668, 40690, 40732, 40737, 40756, 40775, 40826, 40839, 40852, 40869, 40914, 40922, 40973, 40985, 41016, 41027, 41057, 41060, 41102, 41117, 41154, 41159, 41213, 41349, 41384, 41389, 41511, 41545, 41569, 41639, 41658, 41673, 41694, 41747, 41782, 41845, 41874, 41918, 41945, 41989, 42012, 42023, 42029, 42071, 42074, 42086, 42153, 42192, 42195, 42206, 42223, 42258, 42336, 42351, 42370, 42417, 42455, 42474, 42492, 42508, 42545, 42633, 42654, 42657, 42682, 42708, 42766, 42779, 42783, 42827, 42845, 42880, 42999, 43017, 43018, 43043, 43084, 43105, 43262, 43295, 43313, 43318, 43328, 43339, 43352, 43428, 43456, 43464, 43497, 43576, 43626, 43630, 43633, 43685, 43701, 43720, 43735, 43749, 43776, 43799, 43827, 43850, 43922, 43955, 43971, 44029, 44120, 44139, 44152, 44191, 44232, 44263, 44313, 44376, 44383, 44390, 44408, 44429, 44481, 44507, 44513, 44530, 44631, 44635, 44636, 44802, 44808, 44852, 44865, 44943, 44957, 44980, 45012, 45038, 45082, 45151, 45175, 45191, 45216, 45249, 45251, 45282, 45330, 45439, 45458, 45502, 45542, 45552, 45631, 45634, 45641, 45646, 45732, 45752, 45757, 45789, 45854, 45857, 45914, 45931, 46056, 46085, 46094, 46136, 46141, 46157, 46160, 46204, 46230, 46262, 46265, 46308, 46325, 46347, 46354, 46374, 46402, 46433, 46459, 46496, 46512, 46515, 46555, 46561, 46596, 46742, 46805, 46815, 46841, 46882, 46919, 46950, 47014, 47044, 47075, 47132, 47196, 47204, 47250, 47284, 47322, 47410, 47413, 47462, 47478, 47490, 47494, 47539, 47554, 47603, 47643, 47666, 47681, 47702, 47737, 47775, 47812, 47892, 47897, 47901, 47915, 47918, 47973, 47998, 48019, 48040, 48088, 48131, 48144, 48157, 48170, 48183, 48186, 48200, 48243, 48262, 48285, 48331, 48368, 48376, 48377, 48426, 48572, 48592, 48599, 48601, 48629, 48638, 48686, 48758, 48761, 48849, 48907, 48928, 48933, 48976, 48993, 49083, 49117, 49142, 49143, 49146, 49227, 49233, 49299, 49325, 49336, 49368, 49408, 49443, 49444, 49463, 49492, 49544, 49582, 49599, 49600, 49626, 49668, 49691, 49692, 49741, 49742, 49762, 49790, 49819, 49918, 49970, 50000, 50046, 50061, 50106, 50115, 50184, 50245, 50256, 50273, 50279, 50336, 50367, 50397, 50399, 50418, 50426, 50432, 50467, 50470, 50515, 50586, 50673, 50676, 50688, 50715, 50716, 50739, 50829, 50862, 50863, 50866, 50896, 50898, 50911, 50916, 50995, 51030, 51031, 51050, 51065, 51070, 51088, 51112, 51121, 51124, 51129, 51168, 51179, 51208, 51219, 51227, 51274, 51275, 51280, 51334, 51373, 51386, 51395, 51416, 51454, 51538, 51552, 51593, 51594, 51603, 51625, 51660, 51715, 51779, 51787, 51794, 51830, 51861, 51871, 51933, 51957, 52018, 52034, 52046, 52054, 52107, 52144, 52178, 52181, 52230, 52231, 52233, 52243, 52252, 52253, 52269, 52286, 52300, 52362, 52405, 52410, 52422, 52444, 52453, 52524, 52529, 52565, 52585, 52632, 52646, 52706, 52787, 52822, 52831, 52836, 52840, 52871, 52900, 52963, 53011, 53049, 53067, 53183, 53194, 53220, 53249, 53267, 53298, 53315, 53329, 53343, 53353, 53354, 53387, 53413, 53414, 53463, 53572, 53575, 53633, 53654, 53674, 53700, 53810, 53900, 53923, 54093, 54097, 54106, 54147, 54148, 54155, 54210, 54266, 54277, 54346, 54391, 54442, 54458, 54495, 54500, 54520, 54526, 54542, 54545, 54561, 54581, 54614, 54617, 54618, 54637, 54643, 54665, 54674, 54710, 54760, 54776, 54814, 54818, 54826, 54862, 54864, 54886, 54918, 54962, 54982, 54996, 54997, 55086, 55128, 55147, 55161, 55191, 55343, 55381, 55410, 55478, 55490, 55497, 55529, 55532, 55535, 55565, 55578, 55592, 55620, 55656, 55681, 55689, 55752, 55754, 55825, 55852, 55856, 55881, 55934, 55943, 55986, 56060, 56079, 56138, 56163, 56200, 56202, 56299, 56311, 56339, 56406, 56460, 56514, 56575, 56647, 56705, 56709, 56722, 56732, 56827, 56842, 56859, 56865, 56873, 56893, 56900, 56912, 56913, 56938, 56990, 57004, 57014, 57051, 57105, 57202, 57210, 57211, 57214, 57221, 57291, 57313, 57352, 57400, 57420, 57440, 57489, 57509, 57574, 57596, 57644, 57717, 57723, 57747, 57783, 57797, 57807, 57813, 57879, 57952, 57979, 58019, 58072, 58183, 58200, 58216, 58241, 58279, 58281, 58295, 58302, 58337, 58386, 58433, 58467, 58490, 58532, 58548, 58577, 58580, 58594, 58620, 58642, 58662, 58668, 58735, 58736, 58739, 58774, 58778, 58824, 58996, 59003, 59022, 59080, 59109, 59120, 59141, 59190, 59191, 59201, 59218, 59226, 59250, 59255, 59295, 59316, 59375, 59422, 59497, 59498, 59505, 59522, 59562, 59576, 59584, 59676, 59678, 59745, 59753, 59778, 59781, 59947, 59949, 59950]\n",
            "1785\n",
            "\n",
            "cls= 4\n",
            "[3, 66, 82, 254, 268, 272, 336, 345, 378, 381, 399, 420, 477, 484, 490, 505, 520, 543, 549, 563, 572, 621, 622, 693, 711, 725, 780, 816, 876, 887, 904, 945, 982, 1001, 1004, 1007, 1018, 1143, 1158, 1182, 1203, 1225, 1268, 1269, 1284, 1297, 1303, 1310, 1313, 1315, 1333, 1339, 1366, 1385, 1406, 1407, 1425, 1471, 1509, 1516, 1657, 1659, 1692, 1817, 1863, 1866, 1889, 1910, 1925, 1952, 1984, 2116, 2123, 2144, 2190, 2216, 2257, 2297, 2300, 2304, 2327, 2444, 2450, 2461, 2515, 2520, 2528, 2629, 2725, 2779, 2792, 2821, 2856, 2900, 2911, 2913, 2926, 2999, 3036, 3044, 3089, 3141, 3166, 3283, 3288, 3300, 3306, 3308, 3314, 3360, 3383, 3393, 3397, 3408, 3445, 3464, 3509, 3519, 3538, 3540, 3556, 3587, 3599, 3695, 3750, 3759, 3797, 3802, 3868, 3872, 3879, 3948, 3970, 3973, 4043, 4053, 4055, 4195, 4199, 4212, 4224, 4232, 4290, 4297, 4301, 4305, 4323, 4395, 4413, 4438, 4497, 4573, 4614, 4642, 4660, 4681, 4695, 4709, 4710, 4738, 4750, 4773, 4839, 4846, 4910, 4943, 4978, 5051, 5074, 5075, 5119, 5179, 5193, 5212, 5214, 5486, 5490, 5491, 5581, 5607, 5624, 5625, 5633, 5704, 5742, 5756, 5768, 5894, 5931, 5940, 5944, 6021, 6049, 6103, 6203, 6206, 6234, 6249, 6270, 6281, 6303, 6339, 6389, 6421, 6432, 6437, 6450, 6472, 6475, 6562, 6569, 6603, 6611, 6654, 6838, 6840, 6852, 6875, 6897, 6950, 6983, 6990, 7059, 7207, 7301, 7356, 7365, 7368, 7383, 7386, 7395, 7424, 7557, 7574, 7585, 7636, 7656, 7676, 7787, 7822, 7855, 7954, 7963, 7984, 8114, 8137, 8177, 8208, 8331, 8378, 8405, 8456, 8472, 8554, 8630, 8639, 8677, 8688, 8705, 8765, 8823, 8834, 8860, 8970, 8997, 9010, 9019, 9061, 9102, 9141, 9149, 9153, 9155, 9176, 9250, 9259, 9260, 9285, 9352, 9389, 9441, 9497, 9506, 9546, 9618, 9633, 9638, 9655, 9661, 9685, 9695, 9761, 9782, 9824, 9845, 9907, 9915, 9931, 9963, 10051, 10055, 10067, 10076, 10105, 10136, 10167, 10179, 10210, 10222, 10224, 10247, 10299, 10372, 10447, 10472, 10561, 10593, 10640, 10641, 10697, 10699, 10707, 10720, 10808, 10834, 10851, 10861, 10877, 10900, 10904, 10913, 10947, 10950, 10979, 11020, 11021, 11033, 11036, 11118, 11138, 11209, 11254, 11282, 11315, 11384, 11521, 11550, 11586, 11862, 11869, 11927, 11930, 11952, 11967, 12006, 12059, 12075, 12106, 12132, 12134, 12204, 12213, 12224, 12253, 12261, 12285, 12408, 12444, 12511, 12591, 12636, 12663, 12672, 12843, 12859, 12862, 12959, 12997, 13012, 13038, 13134, 13145, 13164, 13212, 13292, 13303, 13307, 13319, 13363, 13464, 13466, 13510, 13681, 13691, 13764, 13787, 13815, 13832, 13846, 13871, 13875, 13896, 13909, 13927, 13943, 13972, 13978, 13993, 13995, 14036, 14051, 14073, 14090, 14181, 14256, 14388, 14415, 14516, 14521, 14532, 14557, 14600, 14607, 14612, 14618, 14667, 14690, 14744, 14747, 14786, 14789, 14853, 14858, 14869, 14907, 14914, 14921, 14923, 14933, 14943, 14974, 14996, 15004, 15009, 15018, 15095, 15126, 15131, 15140, 15254, 15267, 15377, 15399, 15482, 15508, 15526, 15587, 15645, 15683, 15718, 15760, 15777, 15938, 15963, 16033, 16058, 16085, 16101, 16105, 16135, 16139, 16179, 16181, 16194, 16241, 16323, 16328, 16384, 16481, 16605, 16640, 16674, 16689, 16702, 16709, 16842, 16845, 16858, 16878, 16880, 16889, 16890, 16893, 16922, 16936, 16948, 16959, 16967, 17083, 17145, 17146, 17179, 17260, 17266, 17412, 17450, 17498, 17507, 17513, 17556, 17613, 17634, 17635, 17674, 17719, 17727, 17728, 17770, 17777, 17800, 17839, 17877, 17958, 18008, 18028, 18032, 18043, 18044, 18052, 18099, 18114, 18197, 18264, 18293, 18300, 18341, 18363, 18365, 18374, 18409, 18490, 18493, 18507, 18544, 18553, 18592, 18622, 18637, 18705, 18730, 18739, 18818, 18829, 18876, 18918, 19006, 19014, 19032, 19043, 19098, 19112, 19142, 19161, 19168, 19215, 19261, 19285, 19315, 19340, 19360, 19378, 19458, 19460, 19516, 19528, 19543, 19614, 19650, 19657, 19711, 19742, 19790, 19803, 19852, 19882, 19897, 19903, 19917, 19943, 19980, 20044, 20049, 20085, 20116, 20136, 20154, 20192, 20253, 20294, 20321, 20341, 20343, 20409, 20450, 20485, 20511, 20585, 20588, 20608, 20629, 20642, 20654, 20655, 20698, 20782, 20823, 20828, 20833, 20904, 20906, 20948, 20966, 21033, 21041, 21066, 21081, 21117, 21171, 21187, 21191, 21201, 21229, 21252, 21260, 21304, 21391, 21454, 21460, 21480, 21492, 21566, 21582, 21603, 21659, 21684, 21693, 21694, 21771, 21781, 21845, 21868, 21896, 21929, 21946, 21949, 21951, 21966, 21978, 22050, 22185, 22192, 22195, 22202, 22210, 22230, 22241, 22246, 22259, 22274, 22284, 22288, 22369, 22371, 22386, 22417, 22509, 22575, 22621, 22673, 22677, 22750, 22783, 22820, 22944, 22969, 22972, 22981, 22985, 23013, 23022, 23029, 23161, 23231, 23252, 23255, 23279, 23350, 23367, 23393, 23424, 23447, 23455, 23460, 23511, 23603, 23637, 23638, 23790, 23816, 23853, 23943, 23968, 23989, 24035, 24040, 24067, 24108, 24205, 24222, 24230, 24308, 24419, 24430, 24448, 24653, 24658, 24686, 24776, 24785, 24804, 24830, 24884, 24900, 24933, 24967, 25003, 25017, 25099, 25114, 25250, 25286, 25355, 25434, 25441, 25444, 25458, 25474, 25480, 25498, 25525, 25620, 25672, 25690, 25715, 25753, 25768, 25863, 25931, 25941, 25949, 25977, 25992, 26023, 26048, 26068, 26118, 26212, 26233, 26273, 26346, 26353, 26378, 26423, 26477, 26497, 26512, 26540, 26555, 26602, 26653, 26710, 26717, 26781, 26850, 26854, 26865, 26882, 26886, 26890, 26892, 26894, 26924, 26953, 27003, 27017, 27063, 27135, 27173, 27193, 27199, 27206, 27213, 27214, 27236, 27303, 27391, 27409, 27429, 27446, 27453, 27455, 27466, 27468, 27469, 27479, 27518, 27531, 27547, 27558, 27596, 27624, 27649, 27718, 27723, 27725, 27754, 27757, 27762, 27787, 27789, 27812, 27847, 27882, 27891, 27898, 27935, 28013, 28039, 28040, 28072, 28074, 28097, 28167, 28170, 28174, 28186, 28191, 28200, 28219, 28250, 28255, 28271, 28290, 28375, 28414, 28555, 28576, 28583, 28603, 28613, 28614, 28647, 28729, 28739, 28751, 28766, 28796, 28803, 28809, 28823, 28837, 28939, 29034, 29041, 29052, 29071, 29111, 29163, 29183, 29291, 29368, 29377, 29404, 29419, 29528, 29539, 29582, 29610, 29629, 29632, 29635, 29663, 29679, 29723, 29743, 29756, 29770, 29787, 29849, 29939, 30020, 30156, 30226, 30228, 30243, 30268, 30282, 30291, 30326, 30345, 30353, 30414, 30442, 30449, 30468, 30507, 30518, 30522, 30559, 30593, 30600, 30614, 30630, 30790, 30794, 30801, 30802, 30826, 30841, 30915, 30921, 30942, 30950, 31084, 31167, 31239, 31306, 31310, 31349, 31464, 31476, 31514, 31515, 31547, 31549, 31609, 31679, 31775, 31840, 31848, 31916, 31932, 32018, 32029, 32088, 32095, 32100, 32214, 32225, 32244, 32260, 32280, 32285, 32302, 32373, 32415, 32446, 32494, 32525, 32620, 32650, 32654, 32657, 32731, 32842, 32854, 32930, 32960, 32961, 33020, 33038, 33066, 33080, 33115, 33171, 33223, 33253, 33279, 33288, 33296, 33373, 33378, 33383, 33401, 33408, 33465, 33473, 33479, 33499, 33501, 33507, 33610, 33674, 33688, 33692, 33697, 33719, 33744, 33803, 33906, 33979, 33998, 34051, 34060, 34087, 34114, 34144, 34193, 34227, 34255, 34316, 34328, 34344, 34350, 34365, 34418, 34425, 34464, 34477, 34504, 34589, 34617, 34692, 34699, 34727, 34760, 34776, 34793, 34808, 34819, 34895, 34994, 35023, 35066, 35113, 35180, 35185, 35187, 35198, 35228, 35242, 35250, 35276, 35304, 35378, 35415, 35431, 35443, 35484, 35494, 35515, 35526, 35538, 35598, 35648, 35760, 35806, 35854, 35877, 35907, 35925, 35946, 35968, 36096, 36160, 36178, 36199, 36225, 36272, 36294, 36326, 36336, 36361, 36372, 36406, 36420, 36488, 36514, 36572, 36646, 36655, 36731, 36740, 36793, 36867, 36960, 36976, 36989, 37018, 37073, 37093, 37154, 37168, 37171, 37172, 37193, 37234, 37288, 37313, 37342, 37388, 37389, 37431, 37530, 37553, 37569, 37731, 37741, 37805, 37850, 37854, 37923, 37928, 37960, 37996, 38015, 38033, 38090, 38101, 38103, 38115, 38119, 38135, 38188, 38228, 38248, 38259, 38269, 38281, 38293, 38294, 38316, 38455, 38492, 38578, 38640, 38685, 38708, 38776, 38787, 38794, 38810, 38824, 38895, 38906, 38910, 38930, 38940, 38983, 38995, 39005, 39009, 39047, 39061, 39126, 39143, 39162, 39169, 39182, 39221, 39292, 39296, 39302, 39344, 39356, 39369, 39388, 39430, 39451, 39488, 39505, 39509, 39573, 39576, 39588, 39596, 39626, 39656, 39740, 39866, 39947, 39958, 40065, 40071, 40098, 40099, 40108, 40111, 40116, 40121, 40135, 40156, 40162, 40286, 40299, 40301, 40309, 40397, 40522, 40523, 40553, 40560, 40562, 40591, 40597, 40610, 40629, 40642, 40663, 40682, 40705, 40793, 40835, 40846, 40848, 41003, 41005, 41043, 41056, 41086, 41097, 41100, 41103, 41120, 41127, 41136, 41162, 41171, 41178, 41186, 41191, 41252, 41268, 41301, 41305, 41554, 41582, 41595, 41648, 41659, 41688, 41737, 41766, 41770, 41777, 41819, 41836, 41852, 41878, 41955, 41958, 41961, 42080, 42096, 42104, 42138, 42146, 42164, 42225, 42296, 42312, 42313, 42315, 42342, 42375, 42403, 42431, 42434, 42535, 42629, 42664, 42769, 42863, 42903, 42904, 42910, 42967, 42977, 42985, 43030, 43033, 43044, 43139, 43188, 43196, 43202, 43222, 43231, 43238, 43239, 43241, 43304, 43374, 43410, 43486, 43524, 43529, 43557, 43563, 43595, 43632, 43637, 43650, 43682, 43741, 43914, 43925, 43927, 43950, 43957, 43983, 44007, 44032, 44040, 44061, 44071, 44095, 44147, 44171, 44172, 44400, 44446, 44450, 44519, 44587, 44641, 44780, 44803, 44834, 44840, 44844, 44846, 44857, 44863, 44900, 44962, 44963, 44978, 44994, 45002, 45100, 45114, 45121, 45124, 45132, 45139, 45196, 45221, 45239, 45274, 45286, 45293, 45323, 45363, 45441, 45515, 45517, 45586, 45591, 45598, 45605, 45609, 45611, 45618, 45665, 45683, 45701, 45712, 45767, 45801, 45820, 45869, 45873, 45938, 45965, 46011, 46036, 46133, 46218, 46250, 46253, 46319, 46333, 46382, 46490, 46497, 46521, 46570, 46578, 46591, 46618, 46650, 46663, 46753, 46773, 46814, 46891, 46968, 47064, 47126, 47144, 47244, 47295, 47300, 47385, 47436, 47441, 47482, 47487, 47738, 47795, 47796, 47798, 47861, 47972, 48211, 48216, 48360, 48394, 48425, 48478, 48484, 48533, 48563, 48591, 48605, 48689, 48780, 48781, 48812, 48825, 48860, 48879, 48881, 48892, 48902, 48950, 48985, 49023, 49055, 49154, 49207, 49213, 49292, 49365, 49475, 49506, 49518, 49586, 49598, 49622, 49687, 49690, 49699, 49719, 49751, 49758, 49806, 49812, 49895, 49951, 49984, 50032, 50040, 50094, 50100, 50110, 50165, 50167, 50227, 50236, 50295, 50314, 50346, 50405, 50455, 50466, 50479, 50509, 50528, 50606, 50628, 50714, 50735, 50737, 50773, 50797, 50802, 50805, 50971, 50983, 51015, 51049, 51063, 51085, 51128, 51167, 51207, 51217, 51249, 51255, 51267, 51303, 51315, 51345, 51350, 51393, 51425, 51431, 51448, 51462, 51491, 51535, 51541, 51544, 51554, 51558, 51590, 51609, 51622, 51624, 51674, 51710, 51765, 51777, 51799, 51800, 51842, 51919, 51952, 51971, 52015, 52183, 52195, 52208, 52213, 52218, 52280, 52329, 52409, 52419, 52442, 52449, 52523, 52562, 52638, 52653, 52699, 52708, 52719, 52762, 52763, 52786, 52805, 52809, 52834, 52917, 52933, 52971, 52981, 52982, 53004, 53056, 53136, 53242, 53276, 53356, 53378, 53402, 53436, 53447, 53478, 53526, 53545, 53576, 53618, 53621, 53635, 53696, 53706, 53708, 53780, 53822, 53862, 53914, 53915, 53935, 53952, 54002, 54023, 54027, 54132, 54211, 54227, 54268, 54322, 54350, 54368, 54383, 54443, 54484, 54513, 54554, 54562, 54576, 54584, 54600, 54645, 54675, 54683, 54685, 54783, 54798, 54821, 54832, 54847, 55031, 55066, 55145, 55158, 55172, 55183, 55187, 55195, 55208, 55239, 55283, 55288, 55296, 55369, 55389, 55393, 55407, 55417, 55557, 55562, 55582, 55590, 55633, 55646, 55651, 55658, 55757, 55786, 55812, 55863, 55897, 55900, 55903, 55924, 55931, 55956, 56005, 56051, 56053, 56074, 56087, 56148, 56171, 56197, 56228, 56242, 56308, 56322, 56382, 56396, 56422, 56505, 56531, 56567, 56572, 56582, 56606, 56617, 56624, 56654, 56661, 56664, 56665, 56682, 56822, 56836, 56849, 56855, 56866, 56902, 56916, 56918, 57109, 57132, 57134, 57140, 57188, 57200, 57238, 57248, 57277, 57306, 57365, 57381, 57408, 57410, 57422, 57481, 57482, 57490, 57520, 57628, 57651, 57726, 57744, 57848, 57867, 57921, 57957, 58016, 58092, 58118, 58126, 58180, 58190, 58233, 58243, 58277, 58280, 58305, 58321, 58322, 58349, 58354, 58369, 58370, 58374, 58381, 58429, 58487, 58599, 58711, 58784, 58886, 58887, 58889, 58899, 58911, 58926, 58944, 58947, 58989, 59036, 59056, 59073, 59074, 59116, 59163, 59165, 59173, 59187, 59318, 59330, 59377, 59393, 59447, 59486, 59509, 59541, 59549, 59555, 59597, 59612, 59613, 59620, 59659, 59690, 59701, 59715, 59780, 59821, 59858, 59895, 59910, 59972]\n",
            "1791\n",
            "\n",
            "cls= 5\n",
            "[51, 56, 157, 173, 183, 195, 239, 337, 339, 359, 450, 471, 491, 653, 670, 681, 732, 784, 908, 919, 944, 984, 993, 1066, 1081, 1091, 1133, 1134, 1157, 1193, 1198, 1204, 1206, 1244, 1274, 1298, 1545, 1567, 1600, 1662, 1713, 1779, 1848, 1928, 1943, 1979, 1983, 2009, 2026, 2064, 2071, 2117, 2120, 2125, 2182, 2231, 2261, 2266, 2305, 2314, 2334, 2371, 2398, 2410, 2457, 2500, 2604, 2657, 2686, 2688, 2722, 2763, 2877, 2884, 2901, 3015, 3022, 3069, 3124, 3148, 3162, 3163, 3171, 3174, 3206, 3221, 3271, 3278, 3388, 3410, 3420, 3426, 3451, 3456, 3491, 3496, 3547, 3557, 3653, 3660, 3751, 3803, 3837, 3853, 3867, 3960, 3993, 4002, 4019, 4044, 4127, 4153, 4160, 4161, 4188, 4255, 4319, 4355, 4406, 4448, 4467, 4512, 4532, 4534, 4535, 4626, 4632, 4692, 4694, 4699, 4740, 4808, 4822, 4838, 4844, 4850, 4862, 4890, 4893, 4956, 4997, 5036, 5100, 5135, 5152, 5201, 5233, 5270, 5305, 5369, 5431, 5505, 5544, 5606, 5645, 5681, 5698, 5734, 5780, 5830, 5899, 5981, 5993, 6001, 6024, 6047, 6058, 6065, 6131, 6155, 6184, 6232, 6248, 6259, 6338, 6358, 6436, 6455, 6519, 6530, 6561, 6604, 6694, 6853, 6878, 6965, 7021, 7032, 7094, 7103, 7117, 7139, 7164, 7189, 7192, 7266, 7293, 7305, 7319, 7351, 7398, 7476, 7620, 7724, 7750, 7776, 7780, 7846, 7908, 7921, 7978, 8020, 8134, 8140, 8154, 8156, 8167, 8204, 8261, 8269, 8274, 8353, 8400, 8412, 8464, 8496, 8511, 8579, 8584, 8621, 8674, 8756, 8824, 8866, 8894, 8929, 8948, 8993, 9035, 9178, 9196, 9264, 9286, 9288, 9377, 9433, 9450, 9460, 9491, 9537, 9586, 9605, 9641, 9703, 9707, 9729, 9770, 9811, 9867, 9871, 9875, 9879, 9999, 10014, 10119, 10194, 10201, 10223, 10315, 10319, 10382, 10410, 10471, 10484, 10541, 10556, 10668, 10724, 10726, 10744, 10758, 10800, 10803, 10897, 10921, 10978, 10995, 11004, 11024, 11083, 11094, 11121, 11164, 11165, 11166, 11245, 11285, 11317, 11396, 11405, 11437, 11450, 11462, 11513, 11536, 11575, 11610, 11622, 11624, 11662, 11701, 11712, 11740, 11790, 11854, 11893, 11899, 11928, 11988, 11995, 12051, 12053, 12068, 12144, 12177, 12256, 12274, 12330, 12371, 12480, 12485, 12567, 12571, 12573, 12630, 12687, 12728, 12791, 12829, 12839, 12931, 13057, 13087, 13103, 13111, 13112, 13121, 13173, 13187, 13246, 13252, 13256, 13288, 13352, 13375, 13411, 13461, 13517, 13548, 13551, 13604, 13618, 13676, 13679, 13685, 13721, 13980, 13983, 13990, 13998, 14026, 14033, 14034, 14076, 14140, 14298, 14320, 14322, 14331, 14337, 14408, 14432, 14504, 14522, 14530, 14533, 14627, 14677, 14682, 14797, 14881, 14961, 14965, 14975, 14987, 15019, 15133, 15177, 15229, 15233, 15242, 15293, 15312, 15378, 15393, 15408, 15431, 15475, 15488, 15510, 15549, 15556, 15575, 15686, 15701, 15728, 15736, 15764, 15774, 15845, 15898, 15908, 15939, 15943, 15980, 15987, 15989, 16047, 16110, 16150, 16185, 16204, 16291, 16377, 16419, 16444, 16459, 16469, 16496, 16578, 16610, 16623, 16701, 16741, 16798, 16835, 16859, 16873, 16896, 16969, 17094, 17102, 17121, 17190, 17236, 17259, 17278, 17297, 17343, 17358, 17368, 17375, 17392, 17399, 17431, 17547, 17591, 17599, 17619, 17642, 17656, 17665, 17670, 17708, 17710, 17721, 17740, 17794, 17797, 17889, 17898, 17931, 18061, 18074, 18096, 18137, 18150, 18174, 18267, 18277, 18280, 18319, 18347, 18440, 18478, 18563, 18581, 18600, 18613, 18687, 18729, 18743, 18764, 18772, 18799, 18815, 18845, 18883, 18913, 18915, 18958, 18966, 19024, 19201, 19209, 19240, 19252, 19293, 19335, 19350, 19362, 19404, 19434, 19524, 19602, 19610, 19635, 19652, 19690, 19735, 19756, 19825, 19889, 19965, 20059, 20092, 20101, 20156, 20164, 20171, 20200, 20320, 20394, 20451, 20484, 20493, 20562, 20603, 20627, 20672, 20715, 20776, 20807, 20836, 20899, 20952, 20982, 21029, 21148, 21214, 21220, 21356, 21428, 21502, 21554, 21561, 21677, 21767, 21809, 21839, 21920, 21928, 22003, 22021, 22047, 22061, 22119, 22184, 22225, 22229, 22336, 22342, 22357, 22390, 22407, 22424, 22430, 22436, 22469, 22487, 22493, 22650, 22671, 22679, 22715, 22731, 22737, 22757, 22830, 22834, 22870, 22893, 22895, 22932, 22978, 22999, 23039, 23092, 23121, 23162, 23174, 23185, 23234, 23249, 23273, 23318, 23335, 23369, 23432, 23459, 23482, 23488, 23503, 23510, 23515, 23518, 23523, 23619, 23641, 23663, 23689, 23724, 23733, 23941, 24006, 24015, 24023, 24028, 24130, 24160, 24243, 24274, 24295, 24302, 24309, 24326, 24344, 24415, 24452, 24495, 24503, 24546, 24575, 24637, 24651, 24702, 24703, 24741, 24744, 24763, 24822, 24838, 24867, 24877, 24937, 24951, 25012, 25015, 25087, 25157, 25240, 25252, 25260, 25284, 25394, 25432, 25452, 25505, 25588, 25589, 25606, 25607, 25610, 25698, 25699, 25720, 25821, 25840, 25875, 25903, 25925, 26014, 26024, 26030, 26052, 26102, 26167, 26171, 26194, 26221, 26237, 26281, 26303, 26354, 26388, 26418, 26443, 26529, 26545, 26548, 26591, 26700, 26735, 26747, 26751, 26753, 26775, 26827, 26845, 26867, 26958, 26987, 27032, 27053, 27093, 27109, 27125, 27141, 27150, 27159, 27219, 27223, 27225, 27283, 27290, 27347, 27359, 27445, 27462, 27495, 27514, 27520, 27530, 27633, 27666, 27690, 27691, 27713, 27770, 27804, 27805, 27833, 27838, 27844, 27859, 27869, 27879, 27941, 27945, 27956, 27974, 27991, 27999, 28062, 28070, 28079, 28090, 28144, 28241, 28282, 28342, 28389, 28411, 28442, 28475, 28531, 28602, 28612, 28629, 28632, 28652, 28677, 28679, 28691, 28741, 28746, 28757, 28779, 28900, 28947, 28967, 28973, 28997, 29006, 29144, 29302, 29304, 29321, 29358, 29373, 29392, 29398, 29432, 29454, 29463, 29509, 29554, 29575, 29577, 29624, 29649, 29683, 29713, 29760, 29774, 29795, 29816, 29818, 29836, 29857, 29858, 29896, 30046, 30063, 30099, 30107, 30126, 30133, 30137, 30189, 30248, 30301, 30310, 30356, 30372, 30381, 30441, 30506, 30519, 30567, 30642, 30662, 30703, 30723, 30766, 30819, 30889, 30927, 30994, 31055, 31062, 31111, 31129, 31132, 31137, 31149, 31155, 31190, 31218, 31234, 31309, 31409, 31439, 31474, 31485, 31555, 31557, 31559, 31582, 31631, 31646, 31716, 31791, 31793, 31833, 31836, 31883, 31892, 31901, 31922, 31949, 31960, 32001, 32015, 32031, 32044, 32048, 32122, 32196, 32255, 32342, 32431, 32468, 32481, 32625, 32641, 32677, 32719, 32785, 32798, 32801, 32817, 32824, 32862, 32895, 32900, 32906, 32910, 32912, 32919, 32926, 32942, 32944, 32978, 32999, 33001, 33039, 33056, 33116, 33154, 33161, 33246, 33283, 33304, 33333, 33338, 33354, 33429, 33435, 33494, 33609, 33631, 33682, 33702, 33710, 33720, 33765, 33768, 33795, 33800, 33820, 33837, 33931, 33962, 33965, 34007, 34008, 34059, 34074, 34084, 34105, 34111, 34112, 34122, 34186, 34207, 34221, 34323, 34391, 34403, 34424, 34444, 34451, 34472, 34494, 34524, 34531, 34565, 34687, 34736, 34797, 34803, 34841, 34854, 34859, 34880, 34884, 34931, 34954, 35034, 35052, 35053, 35165, 35166, 35194, 35200, 35232, 35247, 35265, 35334, 35389, 35438, 35445, 35543, 35552, 35609, 35640, 35652, 35660, 35712, 35735, 35762, 35775, 35801, 35879, 35902, 35905, 35918, 35964, 36002, 36035, 36048, 36075, 36082, 36103, 36121, 36127, 36139, 36191, 36196, 36207, 36217, 36227, 36347, 36362, 36378, 36421, 36528, 36532, 36556, 36603, 36660, 36796, 36851, 36958, 37011, 37056, 37086, 37096, 37099, 37125, 37151, 37152, 37174, 37184, 37210, 37252, 37282, 37291, 37310, 37317, 37359, 37369, 37375, 37396, 37419, 37436, 37441, 37451, 37462, 37470, 37486, 37498, 37501, 37541, 37598, 37610, 37676, 37708, 37732, 37740, 37746, 37750, 37768, 37790, 37860, 37880, 37885, 37946, 37986, 38079, 38108, 38140, 38165, 38199, 38202, 38241, 38253, 38258, 38272, 38303, 38305, 38359, 38373, 38411, 38424, 38427, 38582, 38636, 38672, 38680, 38790, 38792, 38819, 38839, 38882, 38924, 38966, 38975, 38990, 39004, 39029, 39116, 39147, 39157, 39160, 39167, 39214, 39346, 39347, 39475, 39487, 39497, 39525, 39706, 39779, 39817, 39880, 39920, 39923, 39929, 39967, 39975, 40044, 40069, 40224, 40247, 40382, 40456, 40471, 40477, 40481, 40503, 40536, 40543, 40697, 40717, 40721, 40783, 40799, 40813, 40871, 40904, 40905, 41081, 41113, 41115, 41119, 41141, 41175, 41176, 41318, 41339, 41376, 41400, 41501, 41587, 41680, 41687, 41692, 41697, 41703, 41718, 41720, 41789, 41798, 41812, 41828, 41886, 41938, 41942, 42033, 42076, 42089, 42170, 42174, 42177, 42194, 42243, 42256, 42273, 42286, 42293, 42363, 42377, 42384, 42393, 42397, 42513, 42530, 42731, 42745, 42862, 42943, 42950, 42987, 42989, 43000, 43025, 43038, 43053, 43088, 43107, 43120, 43153, 43181, 43208, 43221, 43225, 43330, 43347, 43387, 43404, 43425, 43433, 43446, 43468, 43613, 43686, 43852, 43879, 43920, 43956, 43979, 43999, 44033, 44046, 44087, 44106, 44179, 44196, 44214, 44229, 44265, 44268, 44312, 44345, 44361, 44371, 44377, 44388, 44434, 44437, 44445, 44532, 44551, 44665, 44667, 44781, 44788, 44791, 44792, 44832, 44853, 44899, 44990, 45018, 45043, 45051, 45125, 45129, 45178, 45215, 45222, 45260, 45269, 45271, 45278, 45290, 45312, 45448, 45473, 45501, 45503, 45531, 45553, 45557, 45583, 45587, 45627, 45728, 45746, 45772, 45915, 45942, 45963, 45983, 45986, 45992, 46010, 46017, 46057, 46063, 46083, 46087, 46095, 46201, 46239, 46246, 46264, 46267, 46288, 46422, 46440, 46441, 46532, 46606, 46608, 46628, 46734, 46780, 46811, 46901, 46918, 46925, 46927, 46930, 47029, 47037, 47043, 47057, 47070, 47095, 47103, 47111, 47157, 47160, 47221, 47223, 47386, 47463, 47485, 47489, 47493, 47509, 47524, 47602, 47621, 47629, 47672, 47714, 47725, 47729, 47773, 47815, 47884, 47938, 47964, 48011, 48048, 48193, 48207, 48220, 48302, 48362, 48398, 48412, 48418, 48444, 48454, 48495, 48624, 48625, 48645, 48673, 48750, 48775, 48785, 48786, 48828, 48832, 48910, 49005, 49033, 49118, 49120, 49172, 49242, 49288, 49294, 49304, 49315, 49327, 49334, 49474, 49493, 49495, 49519, 49522, 49547, 49552, 49577, 49638, 49644, 49665, 49703, 49714, 49715, 49797, 49810, 49848, 49859, 49938, 50012, 50016, 50039, 50101, 50141, 50168, 50190, 50207, 50250, 50321, 50389, 50446, 50518, 50551, 50579, 50598, 50601, 50631, 50639, 50729, 50768, 50925, 51097, 51117, 51138, 51193, 51214, 51230, 51235, 51290, 51308, 51318, 51329, 51355, 51388, 51389, 51498, 51506, 51561, 51577, 51586, 51620, 51642, 51700, 51701, 51773, 51854, 51855, 51863, 51922, 52003, 52036, 52037, 52056, 52057, 52060, 52061, 52106, 52115, 52201, 52236, 52247, 52281, 52317, 52459, 52487, 52536, 52538, 52654, 52731, 52755, 52767, 52801, 52803, 52850, 52861, 52936, 52942, 52969, 52970, 53006, 53204, 53221, 53264, 53369, 53379, 53381, 53424, 53451, 53518, 53535, 53571, 53623, 53666, 53669, 53735, 53774, 53784, 53798, 53831, 53849, 53878, 53931, 53949, 53959, 53981, 54005, 54078, 54089, 54139, 54143, 54152, 54232, 54303, 54321, 54390, 54406, 54463, 54501, 54552, 54623, 54631, 54632, 54738, 54795, 54805, 54888, 54925, 54935, 54942, 54998, 55044, 55047, 55062, 55081, 55102, 55130, 55156, 55312, 55376, 55377, 55447, 55459, 55469, 55504, 55540, 55549, 55553, 55570, 55591, 55603, 55615, 55625, 55645, 55673, 55692, 55776, 55808, 55830, 55867, 55915, 55947, 55969, 56018, 56031, 56065, 56068, 56072, 56097, 56142, 56165, 56185, 56216, 56226, 56257, 56287, 56344, 56386, 56389, 56441, 56513, 56527, 56535, 56609, 56614, 56671, 56677, 56723, 56733, 56760, 56761, 56771, 56787, 56835, 56837, 56862, 56904, 56924, 56927, 56929, 56979, 56986, 57064, 57127, 57258, 57263, 57279, 57334, 57338, 57346, 57411, 57429, 57446, 57460, 57476, 57538, 57545, 57620, 57668, 57671, 57673, 57697, 57756, 57781, 57787, 57798, 57834, 57958, 57972, 57985, 58045, 58070, 58115, 58147, 58268, 58317, 58340, 58352, 58378, 58399, 58410, 58432, 58436, 58444, 58477, 58597, 58697, 58723, 58729, 58776, 58789, 58844, 58869, 58901, 58904, 58997, 59025, 59058, 59164, 59188, 59215, 59264, 59311, 59353, 59364, 59406, 59523, 59616, 59657, 59707, 59712, 59756, 59759, 59761, 59815, 59838, 59922, 59985, 59993, 59997]\n",
            "1693\n",
            "\n",
            "cls= 6\n",
            "[22, 25, 95, 117, 187, 200, 204, 243, 248, 292, 298, 327, 350, 437, 529, 588, 625, 633, 645, 651, 655, 680, 692, 710, 718, 720, 738, 755, 818, 819, 862, 903, 920, 985, 1017, 1035, 1051, 1126, 1154, 1159, 1161, 1175, 1192, 1210, 1228, 1342, 1360, 1362, 1367, 1436, 1485, 1531, 1550, 1552, 1584, 1627, 1646, 1678, 1730, 1733, 1741, 1766, 1876, 1948, 1956, 2043, 2099, 2115, 2124, 2134, 2146, 2150, 2159, 2241, 2274, 2295, 2356, 2409, 2503, 2510, 2517, 2542, 2596, 2602, 2618, 2623, 2631, 2690, 2729, 2751, 2774, 2810, 2888, 2898, 2915, 2939, 2970, 2978, 3018, 3070, 3122, 3139, 3192, 3200, 3207, 3223, 3241, 3262, 3266, 3311, 3369, 3401, 3403, 3411, 3521, 3525, 3528, 3530, 3532, 3593, 3603, 3682, 3683, 3724, 3775, 3783, 3805, 3841, 3865, 3892, 3991, 3994, 4015, 4026, 4035, 4064, 4086, 4118, 4130, 4148, 4234, 4276, 4278, 4415, 4417, 4421, 4434, 4452, 4550, 4663, 4682, 4693, 4734, 4752, 4766, 4770, 4831, 4911, 4937, 4947, 4948, 4966, 5000, 5022, 5059, 5081, 5122, 5176, 5182, 5292, 5338, 5353, 5419, 5435, 5443, 5489, 5497, 5582, 5583, 5588, 5636, 5661, 5680, 5682, 5689, 5694, 5723, 5763, 5879, 5900, 5907, 5921, 6005, 6025, 6095, 6118, 6125, 6145, 6148, 6172, 6179, 6213, 6254, 6262, 6297, 6391, 6406, 6416, 6447, 6451, 6454, 6486, 6517, 6523, 6536, 6537, 6545, 6551, 6645, 6745, 6777, 6859, 6888, 6925, 6935, 6938, 6962, 7020, 7025, 7036, 7041, 7044, 7070, 7143, 7159, 7172, 7190, 7232, 7335, 7388, 7392, 7473, 7481, 7538, 7575, 7701, 7710, 7754, 7825, 7964, 7975, 8002, 8008, 8009, 8015, 8206, 8220, 8474, 8527, 8538, 8617, 8647, 8651, 8697, 8703, 8704, 8816, 8832, 8867, 8873, 8877, 8891, 8937, 9084, 9130, 9142, 9158, 9161, 9180, 9197, 9198, 9241, 9256, 9275, 9303, 9406, 9414, 9481, 9543, 9551, 9554, 9625, 9679, 9732, 9736, 9785, 9814, 9820, 9838, 9924, 9974, 9977, 9978, 9980, 10013, 10029, 10063, 10097, 10108, 10113, 10128, 10173, 10176, 10200, 10211, 10256, 10311, 10327, 10349, 10356, 10400, 10510, 10550, 10563, 10579, 10600, 10631, 10635, 10704, 10733, 10738, 10783, 10786, 10837, 10841, 10922, 10946, 10961, 10984, 11098, 11101, 11113, 11212, 11215, 11239, 11287, 11290, 11310, 11331, 11371, 11394, 11404, 11438, 11466, 11489, 11508, 11537, 11634, 11672, 11675, 11690, 11699, 11719, 11726, 11733, 11792, 11800, 11833, 11911, 11964, 11999, 12048, 12081, 12101, 12122, 12151, 12214, 12218, 12221, 12238, 12254, 12305, 12339, 12411, 12441, 12447, 12458, 12561, 12587, 12596, 12597, 12641, 12679, 12765, 12781, 12788, 12796, 12824, 12831, 12939, 12996, 13046, 13213, 13291, 13331, 13354, 13410, 13432, 13455, 13495, 13511, 13515, 13683, 13734, 13754, 13756, 13796, 13825, 13866, 13920, 13939, 13949, 14024, 14027, 14178, 14231, 14267, 14342, 14345, 14352, 14392, 14395, 14414, 14428, 14443, 14513, 14547, 14608, 14631, 14639, 14660, 14679, 14719, 14746, 14772, 14824, 14889, 14894, 14906, 14916, 14940, 14951, 14999, 15035, 15039, 15052, 15110, 15163, 15179, 15185, 15193, 15232, 15272, 15291, 15294, 15338, 15351, 15360, 15440, 15442, 15457, 15458, 15489, 15497, 15498, 15631, 15719, 15726, 15875, 15971, 15983, 15991, 16106, 16124, 16153, 16201, 16242, 16285, 16337, 16389, 16390, 16393, 16424, 16429, 16440, 16442, 16451, 16478, 16539, 16574, 16603, 16663, 16670, 16687, 16696, 16713, 16778, 16784, 16822, 16841, 16862, 16940, 16945, 16970, 17025, 17075, 17118, 17143, 17172, 17272, 17282, 17287, 17342, 17370, 17424, 17426, 17448, 17480, 17484, 17536, 17554, 17555, 17574, 17675, 17724, 17738, 17744, 17759, 17810, 17858, 17957, 17996, 18005, 18021, 18029, 18046, 18050, 18085, 18129, 18173, 18179, 18208, 18282, 18308, 18330, 18334, 18342, 18353, 18396, 18426, 18543, 18554, 18585, 18596, 18618, 18736, 18820, 18910, 18936, 18965, 19272, 19308, 19366, 19545, 19552, 19559, 19604, 19645, 19653, 19675, 19715, 19732, 19762, 19823, 19941, 19970, 19984, 20008, 20012, 20022, 20036, 20115, 20135, 20148, 20160, 20193, 20238, 20263, 20268, 20310, 20316, 20324, 20333, 20377, 20386, 20408, 20432, 20535, 20541, 20561, 20582, 20586, 20623, 20663, 20687, 20689, 20706, 20755, 20771, 20878, 20919, 20926, 20927, 20934, 20945, 20981, 20986, 20993, 21030, 21032, 21038, 21097, 21146, 21183, 21192, 21264, 21292, 21313, 21349, 21438, 21497, 21514, 21581, 21644, 21747, 21756, 21790, 21800, 21806, 21807, 21934, 21956, 21965, 22004, 22027, 22092, 22157, 22236, 22242, 22266, 22283, 22290, 22332, 22351, 22404, 22428, 22439, 22525, 22528, 22534, 22631, 22670, 22686, 22801, 22828, 22910, 22968, 22986, 23030, 23036, 23051, 23066, 23193, 23208, 23216, 23230, 23244, 23269, 23323, 23328, 23370, 23406, 23527, 23539, 23582, 23592, 23596, 23605, 23686, 23704, 23706, 23745, 23764, 23821, 23881, 23896, 23927, 23945, 23956, 23987, 24049, 24145, 24186, 24187, 24198, 24225, 24232, 24249, 24275, 24298, 24307, 24394, 24397, 24423, 24424, 24478, 24497, 24717, 24743, 24800, 24870, 24895, 24921, 24928, 24950, 24992, 25000, 25025, 25032, 25039, 25067, 25076, 25085, 25121, 25139, 25152, 25168, 25293, 25298, 25321, 25357, 25358, 25382, 25397, 25448, 25482, 25500, 25511, 25622, 25681, 25761, 25795, 25844, 25850, 25904, 25935, 25940, 25967, 26020, 26025, 26054, 26084, 26089, 26122, 26139, 26157, 26197, 26205, 26333, 26364, 26366, 26395, 26403, 26415, 26461, 26478, 26513, 26566, 26569, 26611, 26618, 26619, 26725, 26885, 26919, 27008, 27082, 27088, 27117, 27127, 27164, 27177, 27218, 27229, 27367, 27414, 27437, 27473, 27478, 27486, 27504, 27526, 27554, 27595, 27602, 27610, 27611, 27651, 27660, 27667, 27739, 27767, 27803, 27830, 27872, 27881, 27927, 27928, 27933, 27992, 28042, 28061, 28088, 28169, 28171, 28258, 28277, 28325, 28367, 28374, 28454, 28490, 28504, 28542, 28588, 28606, 28610, 28630, 28690, 28732, 28776, 28925, 28980, 28986, 28990, 29009, 29106, 29108, 29119, 29279, 29284, 29310, 29381, 29391, 29408, 29426, 29560, 29572, 29627, 29640, 29696, 29731, 29752, 29767, 29798, 29815, 29831, 29833, 29838, 29847, 29889, 29965, 29971, 29976, 30057, 30249, 30259, 30292, 30302, 30350, 30394, 30469, 30485, 30512, 30563, 30576, 30621, 30812, 30816, 30877, 30906, 30982, 31025, 31071, 31108, 31139, 31142, 31197, 31235, 31257, 31301, 31312, 31342, 31398, 31448, 31455, 31487, 31558, 31570, 31575, 31580, 31639, 31656, 31660, 31672, 31706, 31727, 31792, 31808, 31826, 31852, 31889, 31942, 31963, 32010, 32060, 32074, 32125, 32126, 32193, 32197, 32240, 32314, 32334, 32339, 32385, 32396, 32454, 32537, 32565, 32581, 32599, 32606, 32699, 32709, 32812, 32868, 32871, 32894, 32922, 33044, 33065, 33091, 33123, 33141, 33251, 33260, 33278, 33298, 33400, 33402, 33405, 33436, 33466, 33468, 33488, 33541, 33566, 33663, 33715, 33726, 33733, 33738, 33785, 33799, 33885, 33924, 33967, 33973, 34013, 34033, 34039, 34045, 34058, 34142, 34156, 34230, 34245, 34265, 34272, 34288, 34304, 34338, 34388, 34430, 34447, 34505, 34539, 34542, 34543, 34552, 34603, 34612, 34621, 34643, 34678, 34679, 34694, 34696, 34716, 34762, 34775, 34798, 34804, 34817, 34823, 34874, 34912, 34942, 34961, 34976, 35091, 35094, 35103, 35131, 35208, 35213, 35278, 35340, 35351, 35396, 35412, 35444, 35480, 35492, 35499, 35535, 35620, 35672, 35703, 35739, 35747, 35781, 35903, 35904, 35921, 35928, 35971, 35977, 35983, 36044, 36060, 36061, 36089, 36111, 36188, 36232, 36243, 36257, 36263, 36274, 36310, 36313, 36348, 36368, 36380, 36396, 36462, 36472, 36486, 36493, 36544, 36561, 36564, 36576, 36586, 36596, 36607, 36613, 36620, 36638, 36642, 36656, 36702, 36720, 36790, 36808, 36821, 36841, 36881, 36903, 36906, 36922, 36943, 36986, 37033, 37119, 37140, 37206, 37221, 37238, 37256, 37344, 37372, 37378, 37380, 37404, 37479, 37518, 37603, 37609, 37682, 37699, 37705, 37725, 37748, 37764, 37818, 37825, 37846, 37865, 37890, 37917, 37974, 38020, 38026, 38088, 38141, 38151, 38181, 38337, 38397, 38401, 38462, 38475, 38537, 38548, 38583, 38588, 38665, 38671, 38674, 38707, 38723, 38773, 38786, 38844, 38845, 38853, 38936, 39000, 39028, 39054, 39057, 39087, 39091, 39122, 39190, 39203, 39224, 39258, 39295, 39457, 39464, 39562, 39617, 39657, 39756, 39858, 39867, 39900, 39909, 39954, 39963, 39994, 40035, 40041, 40142, 40170, 40206, 40274, 40278, 40364, 40425, 40437, 40501, 40519, 40557, 40568, 40617, 40640, 40653, 40664, 40675, 40725, 40782, 40811, 40823, 40836, 40850, 40921, 40946, 40959, 41009, 41045, 41064, 41090, 41106, 41184, 41196, 41275, 41309, 41311, 41327, 41328, 41350, 41374, 41387, 41431, 41476, 41491, 41549, 41553, 41621, 41632, 41641, 41650, 41668, 41672, 41707, 41778, 41801, 41873, 41924, 41936, 41981, 42015, 42067, 42093, 42099, 42108, 42291, 42297, 42436, 42447, 42509, 42527, 42540, 42552, 42565, 42610, 42679, 42748, 42777, 42790, 42819, 42850, 42859, 42872, 42881, 42896, 42901, 42923, 42968, 42975, 42980, 43023, 43026, 43028, 43069, 43157, 43174, 43308, 43353, 43407, 43434, 43439, 43459, 43546, 43561, 43661, 43663, 43666, 43761, 43888, 43912, 43937, 44012, 44015, 44018, 44055, 44068, 44194, 44239, 44244, 44251, 44258, 44274, 44402, 44417, 44422, 44478, 44492, 44533, 44536, 44611, 44675, 44684, 44695, 44712, 44795, 44817, 44872, 44972, 44989, 45009, 45019, 45072, 45098, 45155, 45164, 45169, 45208, 45295, 45350, 45420, 45453, 45592, 45676, 45686, 45770, 45793, 45796, 45799, 45806, 45895, 45944, 45971, 45976, 46042, 46050, 46052, 46075, 46105, 46123, 46124, 46144, 46156, 46208, 46256, 46263, 46317, 46407, 46418, 46473, 46533, 46539, 46587, 46721, 46765, 46804, 46835, 46868, 46885, 46912, 46951, 46970, 46974, 47047, 47135, 47150, 47161, 47240, 47276, 47354, 47451, 47465, 47479, 47552, 47567, 47627, 47634, 47650, 47671, 47707, 47756, 47790, 47821, 47833, 47858, 47870, 47914, 47934, 47953, 48079, 48103, 48142, 48201, 48267, 48373, 48396, 48401, 48406, 48448, 48483, 48497, 48526, 48582, 48600, 48619, 48665, 48723, 48789, 48795, 48802, 48895, 48904, 48940, 48942, 48974, 48983, 49028, 49061, 49076, 49088, 49119, 49129, 49145, 49200, 49212, 49214, 49305, 49312, 49364, 49382, 49404, 49433, 49440, 49462, 49533, 49537, 49607, 49636, 49667, 49698, 49704, 49747, 49776, 49808, 49813, 49818, 49836, 49854, 49948, 49966, 50004, 50043, 50049, 50062, 50071, 50112, 50140, 50221, 50226, 50292, 50299, 50300, 50301, 50304, 50309, 50333, 50334, 50379, 50459, 50481, 50534, 50536, 50575, 50605, 50610, 50670, 50681, 50685, 50687, 50746, 50770, 50788, 50861, 50901, 50902, 50976, 50994, 51032, 51069, 51079, 51087, 51092, 51094, 51178, 51245, 51312, 51326, 51338, 51394, 51429, 51452, 51460, 51483, 51519, 51572, 51578, 51580, 51589, 51663, 51722, 51737, 51817, 51890, 51892, 51958, 51978, 51982, 51985, 52013, 52093, 52101, 52149, 52251, 52263, 52267, 52313, 52333, 52343, 52364, 52377, 52457, 52475, 52508, 52556, 52561, 52602, 52637, 52662, 52666, 52669, 52671, 52797, 52846, 52848, 52863, 52865, 52934, 53030, 53057, 53075, 53118, 53198, 53201, 53214, 53349, 53400, 53442, 53446, 53448, 53477, 53486, 53563, 53567, 53597, 53703, 53711, 53717, 53731, 53889, 53984, 53996, 54016, 54073, 54082, 54122, 54179, 54188, 54230, 54243, 54257, 54263, 54265, 54283, 54291, 54325, 54353, 54386, 54423, 54519, 54575, 54668, 54671, 54733, 54743, 54774, 54788, 54816, 54857, 54877, 54943, 55072, 55075, 55082, 55111, 55116, 55131, 55388, 55399, 55420, 55423, 55471, 55536, 55561, 55581, 55629, 55683, 55710, 55734, 55750, 55784, 55802, 55841, 55865, 55876, 55889, 55911, 55927, 55935, 55949, 55973, 56019, 56123, 56192, 56239, 56292, 56309, 56315, 56330, 56421, 56443, 56487, 56503, 56520, 56523, 56560, 56563, 56598, 56605, 56645, 56662, 56668, 56693, 56785, 56813, 56826, 56911, 56946, 57025, 57066, 57101, 57152, 57290, 57301, 57302, 57345, 57389, 57466, 57471, 57534, 57647, 57672, 57690, 57764, 57856, 57866, 57890, 57917, 57992, 58060, 58081, 58113, 58119, 58167, 58176, 58184, 58274, 58314, 58346, 58368, 58403, 58416, 58423, 58442, 58533, 58552, 58591, 58605, 58609, 58657, 58687, 58689, 58691, 58698, 58721, 58748, 58781, 58791, 58807, 58832, 58893, 58902, 58942, 58963, 58984, 58986, 59150, 59161, 59166, 59194, 59195, 59224, 59317, 59325, 59425, 59450, 59456, 59488, 59489, 59502, 59504, 59527, 59531, 59534, 59550, 59556, 59606, 59621, 59677, 59683, 59691, 59730, 59758, 59762, 59789, 59851, 59966]\n",
            "1761\n",
            "\n",
            "cls= 7\n",
            "[7, 12, 37, 43, 113, 133, 191, 329, 386, 391, 412, 413, 469, 514, 531, 589, 595, 611, 652, 662, 722, 754, 789, 797, 847, 898, 913, 926, 1019, 1054, 1071, 1113, 1167, 1197, 1226, 1442, 1490, 1498, 1577, 1581, 1582, 1583, 1698, 1729, 1825, 1854, 1900, 1902, 1908, 1930, 1945, 1997, 2000, 2015, 2063, 2119, 2139, 2207, 2211, 2256, 2263, 2331, 2397, 2449, 2472, 2474, 2481, 2493, 2502, 2553, 2554, 2608, 2611, 2616, 2651, 2669, 2715, 2746, 2750, 2776, 2790, 2889, 2973, 3054, 3083, 3138, 3157, 3186, 3191, 3261, 3275, 3358, 3364, 3389, 3398, 3434, 3450, 3543, 3637, 3649, 3651, 3699, 3715, 3782, 3806, 3835, 3890, 3920, 3933, 3939, 3946, 3955, 4016, 4054, 4059, 4112, 4114, 4119, 4218, 4251, 4253, 4325, 4331, 4333, 4357, 4369, 4399, 4441, 4442, 4460, 4478, 4510, 4513, 4589, 4686, 4747, 4795, 4833, 4886, 4898, 4903, 4939, 5027, 5058, 5116, 5121, 5158, 5160, 5239, 5254, 5313, 5317, 5325, 5385, 5403, 5447, 5498, 5543, 5577, 5608, 5628, 5652, 5766, 5779, 5784, 5792, 5802, 5812, 5821, 5927, 5930, 5934, 5936, 5958, 6010, 6032, 6072, 6119, 6235, 6320, 6321, 6386, 6423, 6460, 6481, 6497, 6522, 6552, 6653, 6655, 6676, 6677, 6680, 6734, 6748, 6759, 6763, 6776, 6821, 6822, 6953, 6979, 6999, 7011, 7027, 7030, 7076, 7085, 7088, 7141, 7152, 7182, 7186, 7197, 7325, 7333, 7372, 7400, 7488, 7544, 7546, 7564, 7606, 7621, 7637, 7641, 7684, 7809, 7817, 7955, 7986, 8052, 8064, 8106, 8277, 8299, 8343, 8369, 8409, 8469, 8481, 8499, 8537, 8546, 8572, 8595, 8608, 8615, 8620, 8659, 8687, 8708, 8744, 8818, 8885, 8887, 8895, 8897, 8901, 8914, 8924, 8976, 9207, 9239, 9310, 9451, 9453, 9456, 9462, 9492, 9571, 9587, 9621, 9640, 9672, 9711, 9719, 9726, 9735, 9778, 9795, 9805, 9836, 9939, 9958, 9964, 10040, 10041, 10045, 10084, 10114, 10127, 10184, 10214, 10232, 10269, 10278, 10295, 10347, 10348, 10384, 10435, 10466, 10507, 10528, 10529, 10538, 10540, 10546, 10547, 10562, 10573, 10583, 10643, 10666, 10730, 10735, 10754, 10772, 10789, 10858, 10873, 10879, 10887, 10905, 10916, 10927, 10932, 11046, 11059, 11065, 11068, 11088, 11136, 11203, 11214, 11278, 11281, 11300, 11426, 11460, 11502, 11527, 11553, 11570, 11605, 11608, 11621, 11656, 11697, 11781, 11837, 11846, 11867, 11996, 12018, 12023, 12229, 12320, 12394, 12432, 12437, 12466, 12474, 12476, 12527, 12529, 12566, 12625, 12627, 12695, 12705, 12714, 12759, 12787, 12794, 12838, 12845, 12869, 12900, 12901, 12925, 12984, 13014, 13124, 13132, 13146, 13171, 13178, 13185, 13192, 13268, 13272, 13276, 13295, 13304, 13351, 13353, 13372, 13376, 13378, 13430, 13450, 13482, 13494, 13514, 13516, 13540, 13628, 13632, 13732, 13737, 13749, 13775, 13942, 13974, 14050, 14066, 14095, 14130, 14218, 14233, 14254, 14272, 14290, 14333, 14363, 14430, 14431, 14517, 14614, 14636, 14671, 14680, 14686, 14733, 14771, 14801, 14837, 15013, 15020, 15047, 15055, 15079, 15098, 15157, 15167, 15216, 15270, 15271, 15282, 15327, 15355, 15358, 15391, 15427, 15459, 15543, 15579, 15732, 15796, 15806, 15853, 15878, 15889, 15933, 15999, 16005, 16021, 16025, 16026, 16052, 16095, 16096, 16109, 16122, 16144, 16227, 16229, 16265, 16300, 16348, 16399, 16464, 16537, 16557, 16565, 16589, 16618, 16824, 16881, 16921, 16996, 17005, 17037, 17050, 17081, 17110, 17181, 17242, 17324, 17411, 17443, 17463, 17532, 17587, 17589, 17622, 17627, 17668, 17714, 17804, 17807, 17822, 17837, 17840, 17910, 17956, 17979, 17985, 17989, 18031, 18091, 18139, 18144, 18195, 18219, 18258, 18268, 18339, 18350, 18411, 18431, 18448, 18517, 18524, 18556, 18601, 18667, 18688, 18791, 18802, 18869, 18911, 18916, 18922, 18923, 18956, 19010, 19026, 19037, 19058, 19064, 19119, 19121, 19155, 19159, 19198, 19259, 19263, 19278, 19300, 19304, 19348, 19372, 19383, 19408, 19461, 19467, 19478, 19553, 19560, 19591, 19599, 19636, 19638, 19691, 19772, 19816, 19844, 19879, 19909, 19931, 19986, 20010, 20018, 20028, 20062, 20063, 20094, 20099, 20158, 20166, 20170, 20186, 20191, 20202, 20223, 20230, 20251, 20291, 20309, 20356, 20364, 20389, 20392, 20436, 20489, 20576, 20590, 20607, 20614, 20646, 20707, 20744, 20791, 20792, 20819, 20893, 20900, 20989, 21007, 21051, 21083, 21109, 21302, 21317, 21324, 21329, 21335, 21344, 21367, 21371, 21378, 21394, 21409, 21557, 21589, 21617, 21735, 21784, 21814, 21816, 21820, 21857, 21875, 21876, 21891, 22031, 22046, 22069, 22120, 22130, 22138, 22179, 22201, 22204, 22324, 22327, 22381, 22398, 22405, 22520, 22566, 22574, 22595, 22599, 22625, 22669, 22704, 22725, 22789, 22812, 22846, 22883, 22887, 22894, 23000, 23186, 23212, 23259, 23290, 23292, 23298, 23356, 23484, 23486, 23576, 23609, 23699, 23753, 23784, 23835, 23867, 23925, 23966, 24014, 24025, 24050, 24052, 24054, 24088, 24091, 24141, 24159, 24172, 24181, 24311, 24368, 24370, 24427, 24468, 24536, 24545, 24568, 24574, 24593, 24596, 24599, 24613, 24682, 24782, 24786, 24856, 24862, 24898, 24908, 24917, 24940, 24941, 24982, 24988, 24995, 25079, 25108, 25122, 25132, 25154, 25164, 25182, 25197, 25227, 25228, 25269, 25283, 25310, 25328, 25329, 25349, 25369, 25454, 25485, 25553, 25554, 25568, 25572, 25575, 25584, 25594, 25617, 25701, 25741, 25804, 25836, 25848, 25865, 25873, 25927, 25937, 25948, 26006, 26037, 26056, 26104, 26165, 26193, 26256, 26318, 26401, 26420, 26444, 26451, 26464, 26515, 26553, 26628, 26633, 26661, 26683, 26687, 26692, 26749, 26752, 26767, 26788, 26816, 26858, 26901, 26903, 26931, 26973, 27006, 27054, 27098, 27182, 27244, 27255, 27335, 27363, 27381, 27411, 27452, 27511, 27529, 27568, 27574, 27600, 27635, 27657, 27682, 27697, 27756, 27774, 27775, 27782, 27824, 27894, 27915, 27916, 28082, 28102, 28111, 28117, 28150, 28182, 28197, 28206, 28240, 28328, 28392, 28446, 28455, 28468, 28496, 28498, 28502, 28524, 28573, 28638, 28695, 28735, 28801, 28836, 28905, 28914, 28923, 28945, 28951, 28965, 28969, 29016, 29035, 29036, 29047, 29236, 29245, 29320, 29323, 29355, 29453, 29499, 29526, 29534, 29619, 29644, 29648, 29667, 29671, 29688, 29702, 29741, 29840, 29872, 29900, 29904, 29916, 29993, 30065, 30075, 30167, 30184, 30190, 30199, 30216, 30255, 30278, 30296, 30319, 30340, 30348, 30385, 30498, 30548, 30549, 30581, 30599, 30651, 30670, 30720, 30761, 30781, 30824, 30845, 30883, 30897, 30925, 30972, 30987, 30993, 31049, 31082, 31117, 31156, 31192, 31316, 31320, 31336, 31341, 31357, 31360, 31389, 31432, 31482, 31597, 31624, 31719, 31739, 31789, 31839, 31871, 31876, 31914, 31924, 31944, 31965, 31967, 32097, 32162, 32177, 32185, 32187, 32208, 32241, 32269, 32329, 32374, 32382, 32399, 32417, 32490, 32503, 32514, 32528, 32531, 32610, 32640, 32668, 32696, 32750, 32779, 32898, 32948, 33019, 33026, 33036, 33045, 33074, 33102, 33191, 33308, 33324, 33330, 33340, 33374, 33382, 33496, 33553, 33585, 33591, 33618, 33648, 33684, 33689, 33843, 33844, 33850, 33860, 33904, 33908, 33995, 34113, 34126, 34226, 34253, 34257, 34260, 34273, 34275, 34308, 34380, 34401, 34438, 34440, 34528, 34559, 34613, 34708, 34826, 34844, 34847, 34868, 34904, 34915, 34918, 34929, 35067, 35108, 35120, 35137, 35153, 35239, 35241, 35253, 35277, 35284, 35333, 35336, 35376, 35383, 35385, 35400, 35407, 35483, 35632, 35650, 35682, 35689, 35767, 35793, 35812, 35815, 35818, 35890, 35908, 35922, 35975, 35988, 36034, 36037, 36065, 36078, 36189, 36203, 36239, 36248, 36260, 36270, 36338, 36417, 36452, 36499, 36535, 36538, 36565, 36580, 36619, 36729, 36775, 36784, 36815, 36829, 36831, 36833, 36936, 36959, 36971, 36977, 36987, 37037, 37266, 37267, 37286, 37306, 37423, 37449, 37496, 37520, 37525, 37529, 37556, 37595, 37679, 37787, 37836, 37892, 37896, 37897, 37908, 37919, 37971, 38042, 38057, 38062, 38104, 38109, 38131, 38145, 38176, 38232, 38243, 38279, 38308, 38394, 38422, 38468, 38486, 38550, 38667, 38678, 38703, 38713, 38732, 38803, 38826, 38833, 38915, 38920, 38962, 38965, 39077, 39144, 39155, 39168, 39172, 39215, 39262, 39270, 39303, 39307, 39314, 39351, 39354, 39400, 39408, 39421, 39425, 39429, 39472, 39498, 39529, 39536, 39582, 39595, 39633, 39667, 39717, 39720, 39726, 39782, 39796, 39797, 39810, 39835, 39985, 40010, 40021, 40025, 40106, 40107, 40141, 40325, 40330, 40356, 40360, 40374, 40426, 40439, 40440, 40454, 40461, 40464, 40465, 40478, 40517, 40570, 40579, 40630, 40689, 40692, 40723, 40743, 40820, 40853, 40866, 40912, 40942, 40986, 40998, 41039, 41065, 41111, 41129, 41205, 41317, 41344, 41381, 41390, 41393, 41418, 41430, 41506, 41624, 41700, 41704, 41724, 41758, 41780, 41795, 41803, 41816, 41841, 41883, 41898, 41949, 41956, 41959, 41968, 41985, 42003, 42018, 42082, 42097, 42255, 42268, 42290, 42330, 42339, 42355, 42360, 42366, 42378, 42390, 42440, 42514, 42596, 42659, 42685, 42751, 42771, 42831, 42939, 42951, 42996, 43051, 43066, 43128, 43144, 43168, 43246, 43247, 43255, 43260, 43293, 43316, 43320, 43512, 43531, 43537, 43587, 43629, 43724, 43768, 43774, 43902, 43952, 44000, 44006, 44025, 44076, 44086, 44130, 44166, 44261, 44286, 44295, 44326, 44348, 44353, 44356, 44363, 44366, 44424, 44471, 44493, 44505, 44607, 44617, 44661, 44664, 44815, 44826, 44874, 44892, 44922, 44986, 45000, 45054, 45061, 45069, 45112, 45224, 45292, 45336, 45352, 45394, 45407, 45468, 45506, 45540, 45549, 45561, 45610, 45682, 45808, 45843, 45851, 45888, 45950, 45955, 46018, 46027, 46032, 46034, 46040, 46067, 46103, 46129, 46167, 46172, 46211, 46228, 46454, 46508, 46517, 46518, 46524, 46549, 46581, 46583, 46601, 46640, 46641, 46672, 46691, 46694, 46726, 46792, 46834, 46849, 46857, 46875, 46941, 46942, 46946, 47046, 47056, 47110, 47153, 47170, 47185, 47197, 47241, 47249, 47275, 47321, 47323, 47325, 47382, 47406, 47417, 47438, 47460, 47514, 47522, 47551, 47556, 47575, 47598, 47657, 47673, 47724, 47748, 47794, 47856, 47864, 47880, 47890, 47941, 48020, 48204, 48258, 48349, 48357, 48436, 48456, 48486, 48490, 48527, 48567, 48578, 48579, 48620, 48695, 48714, 48741, 48823, 48826, 48829, 48857, 48865, 48923, 49051, 49071, 49109, 49116, 49133, 49202, 49226, 49262, 49270, 49281, 49341, 49350, 49396, 49407, 49476, 49578, 49606, 49610, 49630, 49659, 49728, 49731, 49745, 49796, 49843, 49893, 49903, 49925, 49939, 50013, 50048, 50087, 50137, 50208, 50210, 50216, 50263, 50268, 50316, 50317, 50371, 50375, 50419, 50452, 50471, 50475, 50543, 50571, 50620, 50643, 50741, 50766, 50782, 50824, 50840, 50856, 50892, 50897, 50974, 50984, 51040, 51073, 51157, 51162, 51198, 51209, 51296, 51342, 51391, 51402, 51426, 51470, 51472, 51477, 51521, 51531, 51560, 51566, 51584, 51635, 51640, 51699, 51708, 51754, 51770, 51790, 51822, 51864, 51941, 51956, 51961, 51984, 52010, 52062, 52131, 52152, 52163, 52225, 52358, 52365, 52376, 52395, 52430, 52440, 52583, 52586, 52658, 52710, 52732, 52791, 52796, 52816, 52842, 52889, 52895, 52930, 52959, 53044, 53060, 53131, 53176, 53186, 53209, 53217, 53245, 53257, 53266, 53269, 53272, 53327, 53330, 53332, 53416, 53470, 53482, 53566, 53578, 53589, 53592, 53657, 53689, 53739, 53777, 53788, 53811, 53832, 53836, 53883, 53890, 53913, 53917, 53919, 53944, 53986, 53995, 54019, 54039, 54054, 54063, 54076, 54311, 54326, 54382, 54395, 54432, 54479, 54502, 54503, 54544, 54644, 54657, 54660, 54676, 54694, 54728, 54803, 54837, 54871, 54878, 54896, 54905, 54994, 55006, 55017, 55070, 55117, 55209, 55299, 55305, 55320, 55333, 55403, 55444, 55465, 55481, 55538, 55574, 55593, 55635, 55675, 55684, 55695, 55696, 55706, 55767, 55775, 55782, 55811, 55842, 55858, 55870, 55913, 55928, 55929, 56011, 56071, 56149, 56164, 56227, 56266, 56269, 56319, 56325, 56358, 56388, 56420, 56500, 56539, 56573, 56600, 56612, 56630, 56631, 56657, 56745, 56780, 56818, 56870, 56883, 56926, 56954, 56977, 57079, 57086, 57120, 57175, 57195, 57223, 57226, 57227, 57271, 57281, 57293, 57342, 57426, 57432, 57443, 57456, 57507, 57554, 57587, 57610, 57612, 57658, 57703, 57722, 57758, 57784, 57814, 57859, 57888, 57899, 57976, 58074, 58078, 58124, 58128, 58240, 58335, 58514, 58535, 58611, 58628, 58629, 58639, 58660, 58672, 58683, 58685, 58706, 58718, 58779, 58821, 58865, 58874, 58976, 58981, 59013, 59061, 59071, 59103, 59167, 59186, 59231, 59237, 59282, 59286, 59331, 59372, 59379, 59385, 59390, 59411, 59434, 59438, 59570, 59595, 59607, 59671, 59672, 59684, 59698, 59757, 59833, 59899, 59933, 59945, 59999]\n",
            "1759\n",
            "\n",
            "cls= 8\n",
            "[8, 62, 100, 111, 190, 246, 397, 418, 459, 475, 518, 554, 592, 601, 602, 610, 627, 766, 777, 793, 888, 967, 1036, 1060, 1087, 1174, 1181, 1183, 1250, 1261, 1282, 1300, 1314, 1325, 1375, 1392, 1404, 1431, 1439, 1468, 1479, 1506, 1617, 1643, 1673, 1680, 1683, 1686, 1688, 1699, 1720, 1751, 1770, 1797, 1924, 1970, 2031, 2096, 2166, 2232, 2255, 2284, 2298, 2323, 2325, 2333, 2368, 2388, 2426, 2434, 2438, 2441, 2523, 2534, 2552, 2558, 2577, 2590, 2593, 2635, 2797, 2803, 2805, 2815, 2819, 3039, 3093, 3159, 3240, 3268, 3303, 3305, 3310, 3324, 3405, 3419, 3516, 3518, 3541, 3614, 3638, 3680, 3770, 3777, 3812, 3860, 3881, 3931, 3967, 3978, 3998, 4001, 4003, 4066, 4093, 4180, 4207, 4283, 4287, 4303, 4408, 4432, 4469, 4501, 4575, 4602, 4611, 4723, 4743, 4780, 4800, 4815, 4823, 4828, 4860, 4863, 4914, 4936, 4955, 4965, 5073, 5091, 5092, 5155, 5251, 5262, 5272, 5273, 5283, 5284, 5304, 5348, 5416, 5452, 5469, 5487, 5523, 5600, 5630, 5641, 5658, 5667, 5675, 5701, 5730, 5750, 5752, 5835, 5932, 5949, 5953, 5977, 5999, 6044, 6099, 6134, 6139, 6225, 6250, 6342, 6435, 6468, 6470, 6478, 6541, 6646, 6679, 6718, 6740, 6756, 6762, 6775, 6789, 6791, 6796, 6806, 6825, 6880, 6898, 6948, 7012, 7126, 7131, 7149, 7222, 7248, 7281, 7310, 7366, 7376, 7384, 7413, 7433, 7443, 7447, 7484, 7496, 7523, 7534, 7561, 7580, 7614, 7695, 7702, 7790, 7834, 7871, 7934, 7996, 8031, 8042, 8048, 8120, 8123, 8138, 8214, 8229, 8235, 8248, 8270, 8278, 8301, 8337, 8399, 8406, 8468, 8495, 8512, 8531, 8588, 8668, 8689, 8723, 8769, 8831, 8854, 8952, 8961, 8972, 8982, 8998, 9032, 9055, 9109, 9117, 9188, 9226, 9258, 9268, 9269, 9366, 9378, 9387, 9469, 9527, 9540, 9572, 9599, 9617, 9630, 9651, 9664, 9684, 9723, 9743, 9866, 9913, 9935, 9951, 9960, 10003, 10069, 10098, 10099, 10102, 10103, 10171, 10279, 10302, 10336, 10344, 10381, 10442, 10483, 10572, 10646, 10677, 10773, 10785, 10805, 10810, 10840, 10848, 10864, 10876, 10903, 10917, 10928, 10986, 10997, 11001, 11027, 11049, 11086, 11095, 11117, 11141, 11200, 11206, 11253, 11261, 11277, 11345, 11378, 11488, 11503, 11566, 11598, 11613, 11616, 11627, 11673, 11676, 11693, 11832, 11866, 11907, 11948, 11965, 12024, 12087, 12092, 12093, 12115, 12125, 12126, 12176, 12189, 12236, 12249, 12251, 12319, 12401, 12452, 12457, 12481, 12503, 12544, 12646, 12688, 12830, 12834, 12866, 12867, 12868, 12891, 12905, 12918, 12932, 12935, 12938, 13072, 13131, 13169, 13197, 13227, 13233, 13266, 13315, 13322, 13350, 13406, 13425, 13501, 13535, 13553, 13606, 13616, 13623, 13672, 13693, 13695, 13702, 13728, 13731, 13743, 13744, 13836, 13854, 13886, 13893, 13982, 14010, 14011, 14058, 14141, 14149, 14166, 14183, 14208, 14281, 14306, 14318, 14328, 14369, 14438, 14442, 14497, 14539, 14565, 14581, 14684, 14693, 14710, 14714, 14718, 14729, 14767, 14790, 14854, 14876, 14922, 14969, 14971, 14982, 15025, 15046, 15135, 15206, 15223, 15237, 15250, 15268, 15322, 15323, 15328, 15329, 15416, 15418, 15422, 15429, 15455, 15491, 15520, 15615, 15671, 15698, 15727, 15745, 15746, 15835, 15865, 15951, 16044, 16141, 16147, 16156, 16161, 16167, 16178, 16330, 16414, 16466, 16520, 16532, 16620, 16630, 16657, 16676, 16697, 16700, 16716, 16727, 16775, 16792, 16861, 16902, 16930, 16942, 17007, 17020, 17034, 17063, 17116, 17225, 17252, 17281, 17290, 17327, 17335, 17386, 17394, 17442, 17459, 17482, 17516, 17519, 17588, 17601, 17624, 17625, 17628, 17683, 17736, 17783, 17894, 17922, 17923, 18036, 18045, 18055, 18067, 18076, 18104, 18159, 18171, 18193, 18201, 18236, 18266, 18274, 18395, 18397, 18421, 18444, 18514, 18515, 18530, 18548, 18558, 18565, 18607, 18623, 18631, 18660, 18691, 18812, 18853, 18892, 18933, 19016, 19090, 19123, 19124, 19131, 19132, 19167, 19175, 19219, 19251, 19253, 19283, 19342, 19402, 19415, 19472, 19479, 19502, 19531, 19547, 19557, 19587, 19618, 19622, 19658, 19718, 19733, 19768, 19843, 19887, 19937, 19948, 19954, 20040, 20100, 20128, 20227, 20237, 20239, 20300, 20352, 20370, 20375, 20455, 20479, 20502, 20540, 20594, 20612, 20620, 20650, 20652, 20677, 20702, 20719, 20727, 20740, 20749, 20762, 20822, 20867, 20942, 20949, 20954, 20958, 20999, 21036, 21164, 21175, 21246, 21296, 21312, 21377, 21432, 21479, 21484, 21499, 21505, 21579, 21596, 21646, 21667, 21681, 21710, 21759, 21770, 21802, 21812, 21842, 21844, 21862, 21884, 21936, 22010, 22022, 22056, 22064, 22094, 22147, 22214, 22234, 22255, 22340, 22400, 22455, 22465, 22471, 22477, 22492, 22514, 22551, 22581, 22583, 22597, 22635, 22649, 22736, 22758, 22849, 22888, 22920, 23049, 23125, 23148, 23153, 23183, 23215, 23282, 23307, 23312, 23319, 23342, 23355, 23405, 23434, 23440, 23466, 23509, 23567, 23573, 23583, 23640, 23666, 23669, 23728, 23765, 23838, 23839, 23845, 23855, 23871, 23890, 23960, 24039, 24045, 24093, 24127, 24131, 24139, 24140, 24150, 24277, 24438, 24444, 24471, 24563, 24588, 24608, 24631, 24716, 24740, 24761, 24787, 24825, 24855, 24878, 24894, 24929, 24984, 25002, 25111, 25118, 25124, 25126, 25225, 25320, 25348, 25399, 25412, 25472, 25501, 25521, 25524, 25660, 25669, 25691, 25749, 25758, 25780, 25888, 25908, 25944, 25987, 26035, 26038, 26055, 26108, 26109, 26140, 26170, 26182, 26191, 26220, 26239, 26337, 26381, 26438, 26440, 26481, 26484, 26643, 26666, 26671, 26694, 26944, 26951, 26967, 26993, 27067, 27153, 27243, 27310, 27364, 27386, 27410, 27496, 27536, 27541, 27561, 27612, 27621, 27727, 27808, 27842, 27846, 27864, 27887, 27896, 27932, 27955, 27958, 28066, 28115, 28266, 28323, 28431, 28435, 28436, 28450, 28461, 28499, 28507, 28537, 28706, 28800, 28841, 28855, 28928, 29014, 29051, 29075, 29078, 29170, 29239, 29262, 29287, 29319, 29421, 29437, 29479, 29500, 29537, 29598, 29600, 29647, 29661, 29690, 29708, 29722, 29725, 29734, 29747, 29773, 29781, 29811, 29873, 29877, 29882, 29895, 29919, 29929, 29934, 29951, 29954, 29968, 29981, 30026, 30035, 30106, 30142, 30164, 30252, 30261, 30294, 30299, 30303, 30329, 30335, 30411, 30443, 30488, 30515, 30529, 30544, 30557, 30640, 30664, 30745, 30755, 30788, 30807, 30835, 30859, 30872, 30882, 30926, 30955, 30990, 31018, 31032, 31051, 31097, 31168, 31182, 31183, 31188, 31202, 31220, 31313, 31332, 31367, 31372, 31423, 31425, 31537, 31541, 31565, 31581, 31596, 31608, 31628, 31663, 31680, 31695, 31714, 31725, 31814, 31879, 31917, 31919, 31929, 31938, 32019, 32038, 32051, 32077, 32086, 32092, 32171, 32178, 32183, 32207, 32213, 32246, 32271, 32275, 32306, 32357, 32426, 32447, 32448, 32464, 32465, 32475, 32501, 32532, 32551, 32611, 32644, 32671, 32676, 32691, 32738, 32800, 32819, 32832, 32834, 32840, 32861, 32896, 32897, 32987, 33022, 33072, 33104, 33111, 33124, 33145, 33225, 33317, 33322, 33385, 33398, 33406, 33446, 33537, 33549, 33626, 33651, 33661, 33716, 33761, 33815, 33817, 33852, 33888, 33942, 33954, 33969, 33992, 34021, 34041, 34096, 34135, 34140, 34319, 34387, 34404, 34462, 34491, 34514, 34522, 34546, 34560, 34636, 34641, 34657, 34749, 34759, 34785, 34814, 34815, 34977, 35013, 35036, 35109, 35139, 35142, 35150, 35210, 35224, 35266, 35274, 35300, 35315, 35352, 35361, 35365, 35388, 35441, 35491, 35505, 35540, 35588, 35617, 35621, 35628, 35678, 35687, 35727, 35766, 35808, 35828, 35864, 35876, 35881, 35909, 35912, 35938, 35985, 35992, 35999, 36024, 36108, 36131, 36214, 36297, 36299, 36375, 36424, 36451, 36484, 36498, 36505, 36547, 36551, 36553, 36555, 36579, 36584, 36628, 36644, 36670, 36742, 36780, 36799, 36802, 36803, 36874, 36876, 36882, 36931, 36940, 36953, 36985, 37002, 37060, 37072, 37148, 37207, 37329, 37393, 37406, 37416, 37420, 37534, 37583, 37642, 37722, 37808, 37832, 38002, 38008, 38065, 38081, 38089, 38105, 38138, 38158, 38184, 38214, 38255, 38274, 38323, 38412, 38441, 38443, 38467, 38469, 38477, 38567, 38589, 38607, 38625, 38631, 38689, 38694, 38700, 38724, 38734, 38743, 38815, 38870, 38899, 38904, 38925, 38927, 38952, 38969, 39035, 39079, 39098, 39142, 39198, 39239, 39254, 39317, 39362, 39365, 39383, 39424, 39448, 39454, 39502, 39507, 39534, 39545, 39563, 39577, 39590, 39592, 39613, 39627, 39658, 39766, 39770, 39776, 39787, 39864, 39895, 39896, 40062, 40093, 40110, 40124, 40136, 40179, 40191, 40255, 40368, 40389, 40391, 40402, 40435, 40458, 40470, 40493, 40575, 40581, 40592, 40636, 40641, 40645, 40669, 40671, 40691, 40695, 40728, 40784, 40805, 40883, 40886, 40939, 40947, 40988, 41048, 41059, 41109, 41122, 41201, 41247, 41281, 41315, 41440, 41570, 41572, 41612, 41629, 41689, 41730, 41744, 41753, 41757, 41833, 41835, 41864, 41889, 42017, 42162, 42203, 42220, 42270, 42275, 42324, 42367, 42389, 42449, 42488, 42497, 42521, 42574, 42607, 42683, 42693, 42720, 42730, 42749, 42847, 42870, 42897, 42898, 42917, 42963, 43035, 43086, 43096, 43212, 43278, 43291, 43409, 43423, 43444, 43492, 43534, 43612, 43622, 43623, 43662, 43674, 43675, 43678, 43713, 43772, 43794, 43805, 43807, 43883, 43899, 43916, 43982, 44022, 44054, 44060, 44083, 44213, 44271, 44285, 44317, 44331, 44414, 44420, 44438, 44442, 44458, 44490, 44504, 44615, 44633, 44701, 44711, 44724, 44807, 44833, 44877, 44888, 44927, 45045, 45047, 45073, 45094, 45318, 45371, 45372, 45375, 45386, 45442, 45462, 45478, 45486, 45537, 45617, 45649, 45650, 45659, 45680, 45697, 45717, 45733, 45743, 45788, 45830, 45853, 45890, 45892, 45898, 45912, 45917, 45954, 45985, 46008, 46012, 46038, 46068, 46101, 46102, 46120, 46139, 46151, 46176, 46197, 46210, 46260, 46386, 46387, 46413, 46435, 46442, 46444, 46449, 46477, 46488, 46505, 46538, 46551, 46617, 46626, 46668, 46714, 46735, 46821, 46888, 46892, 46944, 46975, 47094, 47114, 47181, 47202, 47214, 47245, 47265, 47376, 47378, 47391, 47430, 47445, 47543, 47635, 47655, 47708, 47713, 47744, 47751, 47758, 47784, 47814, 47818, 47827, 47829, 47854, 47879, 47886, 47947, 47960, 48042, 48044, 48120, 48168, 48225, 48247, 48249, 48253, 48271, 48281, 48311, 48333, 48335, 48342, 48445, 48457, 48475, 48491, 48541, 48562, 48583, 48604, 48611, 48725, 48737, 48744, 48755, 48757, 48774, 48794, 48821, 48836, 48936, 48990, 49090, 49108, 49115, 49134, 49161, 49180, 49184, 49216, 49257, 49258, 49347, 49374, 49393, 49445, 49479, 49532, 49543, 49553, 49654, 49657, 49679, 49681, 49696, 49744, 49778, 49828, 49830, 49838, 49852, 49857, 49968, 49985, 50015, 50054, 50055, 50079, 50088, 50092, 50126, 50144, 50150, 50166, 50173, 50191, 50218, 50234, 50306, 50312, 50337, 50344, 50401, 50552, 50576, 50588, 50600, 50633, 50665, 50683, 50694, 50711, 50712, 50722, 50757, 50875, 50908, 50917, 50926, 50985, 51002, 51111, 51153, 51159, 51160, 51164, 51205, 51223, 51253, 51262, 51263, 51279, 51347, 51349, 51358, 51447, 51488, 51632, 51671, 51687, 51691, 51713, 51721, 51772, 51778, 51809, 51860, 51874, 51895, 51900, 51968, 52043, 52064, 52153, 52227, 52284, 52354, 52356, 52374, 52399, 52418, 52424, 52476, 52527, 52539, 52591, 52593, 52644, 52687, 52721, 52790, 52898, 52919, 52921, 52953, 52962, 52996, 53042, 53046, 53078, 53079, 53108, 53138, 53140, 53151, 53182, 53189, 53205, 53206, 53226, 53265, 53270, 53331, 53350, 53423, 53430, 53476, 53515, 53531, 53643, 53749, 53763, 53807, 53829, 53834, 53854, 53912, 53950, 54083, 54096, 54125, 54145, 54223, 54260, 54409, 54455, 54459, 54492, 54497, 54517, 54533, 54539, 54566, 54568, 54582, 54649, 54869, 54870, 55095, 55142, 55197, 55205, 55207, 55230, 55249, 55257, 55263, 55383, 55418, 55457, 55466, 55531, 55619, 55648, 55662, 55748, 55770, 55814, 55892, 55898, 55990, 56000, 56028, 56030, 56052, 56070, 56115, 56124, 56141, 56181, 56231, 56342, 56343, 56366, 56379, 56402, 56411, 56412, 56432, 56463, 56466, 56486, 56490, 56524, 56526, 56540, 56569, 56613, 56689, 56702, 56730, 56734, 56747, 56758, 56766, 56798, 56810, 56914, 56947, 56950, 56987, 57072, 57088, 57142, 57144, 57231, 57247, 57252, 57261, 57358, 57361, 57414, 57418, 57464, 57468, 57510, 57515, 57536, 57564, 57601, 57643, 57682, 57707, 57765, 57768, 57796, 57868, 57913, 57984, 58018, 58041, 58067, 58117, 58133, 58137, 58146, 58151, 58158, 58177, 58186, 58226, 58228, 58229, 58239, 58259, 58278, 58361, 58407, 58409, 58515, 58530, 58546, 58583, 58655, 58679, 58701, 58717, 58838, 58867, 58872, 58878, 58892, 58905, 58921, 58939, 59000, 59023, 59028, 59115, 59130, 59175, 59203, 59239, 59274, 59275, 59343, 59418, 59451, 59491, 59604, 59617, 59697, 59713, 59769, 59790, 59792, 59814, 59834, 59930, 59936]\n",
            "1776\n",
            "\n",
            "cls= 9\n",
            "[1, 53, 71, 109, 202, 205, 208, 273, 278, 419, 428, 443, 480, 612, 613, 615, 634, 643, 664, 666, 706, 769, 867, 883, 950, 953, 970, 1000, 1026, 1028, 1043, 1062, 1099, 1115, 1217, 1223, 1231, 1247, 1262, 1277, 1279, 1326, 1378, 1379, 1390, 1433, 1456, 1467, 1472, 1504, 1505, 1572, 1587, 1610, 1619, 1622, 1638, 1652, 1706, 1774, 1906, 1987, 2001, 2016, 2032, 2047, 2055, 2086, 2215, 2313, 2332, 2352, 2379, 2437, 2448, 2468, 2495, 2497, 2526, 2529, 2572, 2609, 2624, 2632, 2637, 2664, 2757, 2767, 2853, 2880, 2985, 3032, 3088, 3090, 3129, 3179, 3202, 3232, 3234, 3316, 3342, 3363, 3381, 3392, 3424, 3510, 3537, 3597, 3602, 3613, 3657, 3706, 3788, 3811, 3887, 3915, 3928, 3983, 4049, 4071, 4150, 4223, 4246, 4252, 4256, 4340, 4344, 4364, 4371, 4407, 4473, 4520, 4536, 4541, 4587, 4643, 4649, 4665, 4680, 4701, 4708, 4749, 4784, 4818, 4842, 4913, 4964, 5002, 5011, 5031, 5040, 5045, 5104, 5133, 5140, 5203, 5213, 5231, 5275, 5300, 5315, 5320, 5395, 5397, 5408, 5418, 5453, 5511, 5591, 5602, 5654, 5688, 5691, 5776, 5801, 5851, 5884, 5937, 5968, 6016, 6111, 6129, 6149, 6174, 6275, 6310, 6360, 6381, 6413, 6525, 6587, 6625, 6644, 6671, 6834, 6835, 6870, 6887, 6934, 6951, 7071, 7170, 7276, 7391, 7399, 7456, 7457, 7461, 7479, 7556, 7645, 7652, 7694, 7708, 7944, 7990, 8012, 8061, 8089, 8110, 8141, 8145, 8213, 8245, 8317, 8318, 8364, 8402, 8413, 8428, 8458, 8493, 8501, 8506, 8539, 8561, 8568, 8575, 8587, 8613, 8725, 8758, 8773, 8826, 8835, 8841, 8896, 8945, 9026, 9028, 9106, 9139, 9187, 9213, 9229, 9244, 9261, 9270, 9308, 9425, 9432, 9461, 9466, 9487, 9626, 9676, 9704, 9705, 9715, 9721, 9825, 9843, 9869, 9886, 9911, 9936, 9955, 9961, 10078, 10138, 10149, 10285, 10291, 10309, 10312, 10316, 10331, 10388, 10520, 10523, 10581, 10698, 10743, 10751, 10793, 10799, 10850, 10853, 10881, 10972, 11096, 11128, 11139, 11225, 11227, 11258, 11275, 11311, 11383, 11399, 11430, 11485, 11547, 11549, 11555, 11685, 11703, 11717, 11720, 11747, 11797, 11883, 11889, 11918, 11984, 12011, 12061, 12086, 12187, 12245, 12248, 12383, 12404, 12467, 12483, 12486, 12541, 12608, 12653, 12654, 12680, 12700, 12706, 12712, 12718, 12745, 12775, 12955, 12957, 12970, 12986, 13034, 13096, 13148, 13294, 13337, 13342, 13364, 13384, 13407, 13421, 13512, 13538, 13588, 13599, 13625, 13642, 13662, 13690, 13717, 13745, 13767, 13779, 13807, 13809, 13870, 13881, 13910, 13919, 14020, 14071, 14112, 14173, 14177, 14197, 14205, 14217, 14265, 14279, 14338, 14357, 14433, 14436, 14458, 14467, 14506, 14510, 14562, 14599, 14609, 14616, 14661, 14784, 14809, 14868, 14880, 14990, 15005, 15027, 15056, 15062, 15082, 15104, 15119, 15142, 15159, 15190, 15204, 15209, 15221, 15249, 15280, 15302, 15331, 15368, 15373, 15566, 15570, 15588, 15597, 15690, 15758, 15782, 15817, 15838, 15901, 15924, 15965, 15976, 16016, 16046, 16142, 16143, 16302, 16317, 16382, 16396, 16413, 16491, 16519, 16523, 16551, 16568, 16595, 16612, 16617, 16684, 16688, 16708, 16809, 16901, 16909, 16910, 16911, 16966, 16999, 17068, 17090, 17108, 17158, 17228, 17241, 17270, 17289, 17359, 17371, 17404, 17406, 17429, 17433, 17447, 17579, 17590, 17600, 17679, 17706, 17784, 17798, 17816, 17869, 17907, 17927, 17941, 17961, 17982, 18019, 18071, 18113, 18205, 18209, 18297, 18337, 18355, 18369, 18394, 18429, 18453, 18488, 18539, 18580, 18681, 18750, 18759, 18778, 18779, 18846, 18878, 18963, 18967, 18982, 19034, 19050, 19055, 19073, 19076, 19122, 19174, 19190, 19193, 19203, 19279, 19290, 19299, 19377, 19410, 19424, 19534, 19590, 19597, 19601, 19660, 19669, 19680, 19709, 19719, 19776, 19796, 19826, 19840, 19842, 19876, 19893, 19934, 19953, 19992, 20069, 20095, 20129, 20172, 20187, 20264, 20305, 20427, 20428, 20430, 20517, 20518, 20552, 20578, 20599, 20613, 20634, 20693, 20718, 20827, 20855, 20894, 20901, 20944, 20955, 20974, 21010, 21045, 21065, 21098, 21129, 21133, 21159, 21170, 21213, 21219, 21242, 21282, 21334, 21336, 21350, 21375, 21390, 21406, 21408, 21445, 21470, 21471, 21496, 21518, 21520, 21583, 21609, 21632, 21680, 21688, 21738, 21745, 21766, 21775, 21786, 21793, 21887, 21894, 21923, 21939, 22009, 22016, 22033, 22038, 22075, 22102, 22166, 22181, 22187, 22206, 22252, 22285, 22333, 22346, 22366, 22442, 22447, 22475, 22494, 22614, 22629, 22685, 22694, 22718, 22802, 22925, 22935, 22959, 23089, 23111, 23166, 23229, 23271, 23287, 23302, 23303, 23305, 23336, 23359, 23397, 23400, 23410, 23427, 23467, 23471, 23555, 23569, 23575, 23615, 23624, 23645, 23679, 23687, 23722, 23726, 23749, 23751, 23770, 23783, 23813, 23875, 23877, 23990, 24009, 24011, 24032, 24042, 24055, 24066, 24076, 24087, 24116, 24125, 24173, 24182, 24211, 24234, 24248, 24278, 24299, 24324, 24345, 24388, 24410, 24436, 24542, 24604, 24609, 24614, 24615, 24619, 24683, 24731, 24788, 24924, 24985, 25001, 25091, 25129, 25143, 25317, 25325, 25338, 25361, 25476, 25483, 25506, 25542, 25548, 25590, 25631, 25837, 25965, 25988, 25991, 26013, 26050, 26061, 26117, 26227, 26229, 26348, 26439, 26447, 26483, 26530, 26531, 26600, 26610, 26620, 26647, 26654, 26655, 26668, 26674, 26677, 26756, 26763, 26832, 26847, 26869, 26888, 26932, 26941, 26955, 26972, 26989, 27011, 27025, 27030, 27085, 27111, 27160, 27196, 27198, 27237, 27249, 27287, 27299, 27307, 27336, 27340, 27471, 27548, 27569, 27588, 27622, 27693, 27717, 27899, 27907, 27949, 27959, 27995, 27997, 28019, 28046, 28053, 28071, 28119, 28120, 28123, 28189, 28215, 28233, 28285, 28304, 28318, 28337, 28353, 28358, 28379, 28451, 28534, 28543, 28544, 28547, 28567, 28601, 28624, 28702, 28709, 28753, 28783, 28863, 28871, 28879, 28908, 28915, 28988, 29000, 29002, 29043, 29059, 29091, 29112, 29157, 29179, 29186, 29197, 29207, 29224, 29258, 29418, 29440, 29458, 29472, 29495, 29504, 29507, 29565, 29590, 29609, 29628, 29739, 29776, 29784, 29825, 29843, 29851, 29909, 29938, 30038, 30064, 30127, 30194, 30263, 30276, 30351, 30364, 30369, 30392, 30462, 30503, 30555, 30578, 30619, 30658, 30678, 30697, 30733, 30736, 30771, 30796, 30823, 30850, 30853, 30861, 30932, 30946, 30973, 31010, 31039, 31056, 31068, 31095, 31162, 31174, 31176, 31186, 31216, 31233, 31388, 31403, 31422, 31441, 31453, 31458, 31533, 31571, 31630, 31638, 31722, 31742, 31760, 31772, 31790, 31805, 31827, 31829, 31862, 31878, 31881, 31909, 31918, 31920, 31937, 31956, 31983, 32008, 32041, 32146, 32163, 32175, 32249, 32254, 32273, 32407, 32466, 32476, 32552, 32575, 32591, 32595, 32600, 32605, 32635, 32717, 32838, 32851, 32962, 33010, 33025, 33028, 33088, 33110, 33149, 33182, 33208, 33219, 33248, 33326, 33404, 33431, 33588, 33668, 33676, 33679, 33736, 33739, 33766, 33782, 33786, 33790, 33794, 33806, 33813, 33858, 33886, 33893, 33896, 33898, 33991, 33994, 34024, 34034, 34049, 34085, 34134, 34154, 34175, 34177, 34309, 34348, 34355, 34366, 34390, 34395, 34399, 34427, 34435, 34456, 34474, 34481, 34483, 34485, 34526, 34535, 34538, 34557, 34586, 34628, 34726, 34731, 34800, 34883, 34908, 34916, 34943, 34958, 34970, 34995, 35019, 35047, 35057, 35167, 35183, 35184, 35233, 35251, 35262, 35280, 35305, 35372, 35498, 35636, 35642, 35654, 35670, 35676, 35702, 35741, 35749, 35795, 35852, 35893, 35943, 36031, 36045, 36050, 36059, 36088, 36109, 36115, 36143, 36165, 36179, 36218, 36315, 36504, 36549, 36559, 36649, 36668, 36683, 36684, 36697, 36713, 36748, 36787, 36827, 36834, 36846, 36865, 36866, 36878, 36887, 36888, 36918, 36928, 37017, 37020, 37031, 37088, 37090, 37094, 37157, 37170, 37195, 37220, 37242, 37249, 37326, 37363, 37383, 37387, 37392, 37400, 37407, 37433, 37452, 37454, 37535, 37539, 37552, 37600, 37604, 37607, 37739, 37780, 37782, 37833, 37968, 37993, 38005, 38024, 38132, 38139, 38153, 38191, 38267, 38328, 38331, 38379, 38402, 38430, 38483, 38569, 38602, 38651, 38742, 38777, 38848, 38871, 38873, 38916, 38985, 39014, 39016, 39043, 39048, 39050, 39084, 39137, 39183, 39238, 39274, 39359, 39361, 39450, 39546, 39564, 39597, 39672, 39685, 39721, 39741, 39775, 39801, 39813, 39816, 39830, 39831, 39837, 39839, 39860, 39872, 39884, 39930, 39934, 40015, 40029, 40043, 40059, 40100, 40102, 40166, 40168, 40222, 40237, 40291, 40293, 40338, 40387, 40393, 40450, 40451, 40474, 40508, 40596, 40599, 40638, 40676, 40699, 40711, 40750, 40774, 40777, 40781, 40790, 40795, 40801, 40812, 40845, 40895, 40898, 40902, 40903, 40923, 41079, 41149, 41156, 41173, 41244, 41313, 41316, 41354, 41383, 41436, 41494, 41495, 41504, 41508, 41541, 41560, 41765, 41776, 41901, 41906, 41967, 41994, 42000, 42025, 42101, 42123, 42128, 42149, 42159, 42173, 42244, 42263, 42278, 42289, 42369, 42385, 42406, 42414, 42441, 42471, 42554, 42556, 42591, 42624, 42638, 42681, 42704, 42739, 42851, 42855, 42885, 42890, 42941, 42981, 43131, 43141, 43176, 43218, 43226, 43281, 43329, 43332, 43377, 43384, 43405, 43437, 43474, 43496, 43522, 43559, 43591, 43604, 43616, 43719, 43721, 43739, 43787, 43803, 43821, 43900, 43910, 43921, 43938, 43942, 43943, 44010, 44036, 44065, 44066, 44132, 44157, 44182, 44206, 44212, 44240, 44352, 44372, 44469, 44502, 44515, 44640, 44646, 44678, 44692, 44699, 44710, 44714, 44723, 44812, 44881, 44901, 44912, 44996, 45008, 45044, 45055, 45093, 45116, 45160, 45231, 45307, 45356, 45388, 45418, 45464, 45472, 45497, 45498, 45528, 45539, 45671, 45707, 45755, 45791, 45802, 45860, 45876, 45905, 45906, 45922, 45961, 45996, 46024, 46059, 46131, 46171, 46221, 46278, 46280, 46345, 46356, 46401, 46426, 46438, 46537, 46599, 46623, 46629, 46651, 46654, 46664, 46685, 46687, 46713, 46752, 46774, 46788, 46833, 46878, 46959, 46978, 46986, 47002, 47020, 47025, 47076, 47081, 47084, 47085, 47175, 47187, 47247, 47262, 47278, 47303, 47338, 47363, 47412, 47427, 47429, 47461, 47504, 47515, 47537, 47569, 47574, 47577, 47583, 47660, 47690, 47692, 47700, 47895, 47959, 47967, 48017, 48031, 48033, 48116, 48231, 48329, 48353, 48434, 48435, 48455, 48468, 48606, 48648, 48654, 48662, 48705, 48827, 48887, 48916, 48919, 48949, 48998, 49012, 49026, 49035, 49057, 49065, 49074, 49147, 49211, 49217, 49228, 49238, 49249, 49278, 49300, 49385, 49405, 49461, 49546, 49688, 49694, 49750, 49780, 49783, 49823, 49833, 49963, 49971, 50076, 50133, 50157, 50170, 50172, 50174, 50209, 50222, 50252, 50253, 50259, 50331, 50349, 50360, 50381, 50415, 50443, 50454, 50504, 50507, 50508, 50545, 50568, 50577, 50585, 50611, 50651, 50654, 50660, 50680, 50684, 50719, 50733, 50734, 50787, 50853, 50979, 50981, 51064, 51104, 51155, 51171, 51199, 51261, 51282, 51314, 51344, 51357, 51359, 51387, 51465, 51492, 51582, 51626, 51627, 51629, 51653, 51654, 51689, 51697, 51727, 51732, 51792, 51808, 51814, 51914, 52071, 52116, 52126, 52143, 52148, 52186, 52278, 52279, 52282, 52336, 52355, 52407, 52446, 52467, 52469, 52493, 52521, 52568, 52571, 52596, 52743, 52744, 52754, 52789, 52807, 52817, 52868, 52873, 52876, 52907, 52931, 53036, 53062, 53081, 53141, 53169, 53170, 53172, 53288, 53295, 53305, 53314, 53339, 53358, 53395, 53501, 53564, 53569, 53609, 53638, 53644, 53655, 53687, 53699, 53732, 53747, 53755, 53789, 53812, 53916, 53958, 53964, 53979, 53999, 54021, 54026, 54070, 54098, 54191, 54235, 54252, 54253, 54255, 54338, 54365, 54396, 54439, 54481, 54536, 54550, 54681, 54715, 54727, 54737, 54761, 54791, 54800, 54827, 54835, 54851, 54852, 54867, 54874, 54929, 54931, 54932, 54952, 55063, 55069, 55120, 55137, 55143, 55152, 55180, 55276, 55300, 55308, 55311, 55315, 55350, 55455, 55484, 55498, 55579, 55596, 55736, 55765, 55790, 55938, 55939, 55950, 55958, 55967, 55980, 56017, 56059, 56095, 56107, 56110, 56136, 56139, 56140, 56147, 56176, 56188, 56207, 56289, 56313, 56317, 56369, 56409, 56419, 56435, 56509, 56522, 56561, 56642, 56649, 56681, 56804, 56814, 56852, 56871, 56897, 56903, 56936, 56951, 57007, 57024, 57073, 57076, 57122, 57170, 57179, 57220, 57232, 57270, 57382, 57407, 57451, 57470, 57522, 57547, 57640, 57686, 57729, 57752, 57792, 57844, 57884, 57931, 57942, 57954, 58034, 58057, 58065, 58083, 58143, 58149, 58292, 58312, 58355, 58459, 58488, 58518, 58585, 58624, 58727, 58742, 58830, 58871, 58879, 58922, 58946, 58953, 58972, 58985, 58995, 58998, 59026, 59069, 59199, 59217, 59236, 59247, 59249, 59287, 59299, 59303, 59367, 59382, 59391, 59492, 59516, 59518, 59545, 59560, 59564, 59566, 59583, 59598, 59706, 59732, 59760, 59773, 59775, 59796, 59845, 59868, 59881, 59938, 59958]\n",
            "1772\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create shadow models\n",
        "mia.create_shadow_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ1ueXg7h3q7",
        "outputId": "268c5af1-7f3f-4692-d590-15e2e1347312"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "shadow model: 66  epoch: 134  loss= 0.07946252077817917\n",
            "shadow model: 66  epoch: 135  loss= 0.06084258854389191\n",
            "shadow model: 66  epoch: 136  loss= 0.0999685600399971\n",
            "shadow model: 66  epoch: 137  loss= 0.03805400803685188\n",
            "shadow model: 66  epoch: 138  loss= 0.11594831198453903\n",
            "shadow model: 66  epoch: 139  loss= 0.08413083106279373\n",
            "shadow model: 66  epoch: 140  loss= 0.01948338933289051\n",
            "shadow model: 66  epoch: 141  loss= 0.03186839446425438\n",
            "shadow model: 66  epoch: 142  loss= 0.07341291755437851\n",
            "shadow model: 66  epoch: 143  loss= 0.04923814535140991\n",
            "shadow model: 66  epoch: 144  loss= 0.0317959226667881\n",
            "shadow model: 66  epoch: 145  loss= 0.034276895225048065\n",
            "shadow model: 66  epoch: 146  loss= 0.036259643733501434\n",
            "shadow model: 66  epoch: 147  loss= 0.06272894889116287\n",
            "shadow model: 66  epoch: 148  loss= 0.013573209755122662\n",
            "shadow model: 66  epoch: 149  loss= 0.012011725455522537\n",
            "\n",
            "shadow model: 67  epoch: 0  loss= 2.3089098930358887\n",
            "shadow model: 67  epoch: 1  loss= 2.239839792251587\n",
            "shadow model: 67  epoch: 2  loss= 2.2233834266662598\n",
            "shadow model: 67  epoch: 3  loss= 2.0587868690490723\n",
            "shadow model: 67  epoch: 4  loss= 2.043483018875122\n",
            "shadow model: 67  epoch: 5  loss= 1.9696670770645142\n",
            "shadow model: 67  epoch: 6  loss= 2.0044822692871094\n",
            "shadow model: 67  epoch: 7  loss= 1.82671058177948\n",
            "shadow model: 67  epoch: 8  loss= 1.8368827104568481\n",
            "shadow model: 67  epoch: 9  loss= 1.7183669805526733\n",
            "shadow model: 67  epoch: 10  loss= 1.6257233619689941\n",
            "shadow model: 67  epoch: 11  loss= 1.6565178632736206\n",
            "shadow model: 67  epoch: 12  loss= 1.233152985572815\n",
            "shadow model: 67  epoch: 13  loss= 1.2977858781814575\n",
            "shadow model: 67  epoch: 14  loss= 1.358604073524475\n",
            "shadow model: 67  epoch: 15  loss= 1.2650611400604248\n",
            "shadow model: 67  epoch: 16  loss= 1.1175867319107056\n",
            "shadow model: 67  epoch: 17  loss= 1.1412314176559448\n",
            "shadow model: 67  epoch: 18  loss= 0.8910285830497742\n",
            "shadow model: 67  epoch: 19  loss= 0.9721394181251526\n",
            "shadow model: 67  epoch: 20  loss= 0.8681526184082031\n",
            "shadow model: 67  epoch: 21  loss= 0.8346074223518372\n",
            "shadow model: 67  epoch: 22  loss= 0.7928619980812073\n",
            "shadow model: 67  epoch: 23  loss= 0.8131083846092224\n",
            "shadow model: 67  epoch: 24  loss= 0.781407356262207\n",
            "shadow model: 67  epoch: 25  loss= 0.6710894107818604\n",
            "shadow model: 67  epoch: 26  loss= 0.4665508270263672\n",
            "shadow model: 67  epoch: 27  loss= 0.6159524321556091\n",
            "shadow model: 67  epoch: 28  loss= 0.527032196521759\n",
            "shadow model: 67  epoch: 29  loss= 0.5612080097198486\n",
            "shadow model: 67  epoch: 30  loss= 0.6186895370483398\n",
            "shadow model: 67  epoch: 31  loss= 0.47648534178733826\n",
            "shadow model: 67  epoch: 32  loss= 0.39713338017463684\n",
            "shadow model: 67  epoch: 33  loss= 0.3182579576969147\n",
            "shadow model: 67  epoch: 34  loss= 0.3082464337348938\n",
            "shadow model: 67  epoch: 35  loss= 0.27773723006248474\n",
            "shadow model: 67  epoch: 36  loss= 0.3424423933029175\n",
            "shadow model: 67  epoch: 37  loss= 0.2300153225660324\n",
            "shadow model: 67  epoch: 38  loss= 0.2890576124191284\n",
            "shadow model: 67  epoch: 39  loss= 0.20998893678188324\n",
            "shadow model: 67  epoch: 40  loss= 0.24396707117557526\n",
            "shadow model: 67  epoch: 41  loss= 0.3446180522441864\n",
            "shadow model: 67  epoch: 42  loss= 0.3005106747150421\n",
            "shadow model: 67  epoch: 43  loss= 0.1375044882297516\n",
            "shadow model: 67  epoch: 44  loss= 0.2830284535884857\n",
            "shadow model: 67  epoch: 45  loss= 0.3358476161956787\n",
            "shadow model: 67  epoch: 46  loss= 0.2060871124267578\n",
            "shadow model: 67  epoch: 47  loss= 0.118733249604702\n",
            "shadow model: 67  epoch: 48  loss= 0.13780377805233002\n",
            "shadow model: 67  epoch: 49  loss= 0.4463011920452118\n",
            "shadow model: 67  epoch: 50  loss= 0.20608460903167725\n",
            "shadow model: 67  epoch: 51  loss= 0.2675801217556\n",
            "shadow model: 67  epoch: 52  loss= 0.12599517405033112\n",
            "shadow model: 67  epoch: 53  loss= 0.18085569143295288\n",
            "shadow model: 67  epoch: 54  loss= 0.20323139429092407\n",
            "shadow model: 67  epoch: 55  loss= 0.1848849207162857\n",
            "shadow model: 67  epoch: 56  loss= 0.2010083943605423\n",
            "shadow model: 67  epoch: 57  loss= 0.13061432540416718\n",
            "shadow model: 67  epoch: 58  loss= 0.16212435066699982\n",
            "shadow model: 67  epoch: 59  loss= 0.18669843673706055\n",
            "shadow model: 67  epoch: 60  loss= 0.07664023339748383\n",
            "shadow model: 67  epoch: 61  loss= 0.13797114789485931\n",
            "shadow model: 67  epoch: 62  loss= 0.09722435474395752\n",
            "shadow model: 67  epoch: 63  loss= 0.060972411185503006\n",
            "shadow model: 67  epoch: 64  loss= 0.09473776817321777\n",
            "shadow model: 67  epoch: 65  loss= 0.12755946815013885\n",
            "shadow model: 67  epoch: 66  loss= 0.15699274837970734\n",
            "shadow model: 67  epoch: 67  loss= 0.19903694093227386\n",
            "shadow model: 67  epoch: 68  loss= 0.04704393446445465\n",
            "shadow model: 67  epoch: 69  loss= 0.1543566733598709\n",
            "shadow model: 67  epoch: 70  loss= 0.12030274420976639\n",
            "shadow model: 67  epoch: 71  loss= 0.14369162917137146\n",
            "shadow model: 67  epoch: 72  loss= 0.11594405025243759\n",
            "shadow model: 67  epoch: 73  loss= 0.1080511286854744\n",
            "shadow model: 67  epoch: 74  loss= 0.0731109008193016\n",
            "shadow model: 67  epoch: 75  loss= 0.07640969008207321\n",
            "shadow model: 67  epoch: 76  loss= 0.12943893671035767\n",
            "shadow model: 67  epoch: 77  loss= 0.1753823161125183\n",
            "shadow model: 67  epoch: 78  loss= 0.17553971707820892\n",
            "shadow model: 67  epoch: 79  loss= 0.16901814937591553\n",
            "shadow model: 67  epoch: 80  loss= 0.11335570365190506\n",
            "shadow model: 67  epoch: 81  loss= 0.031018344685435295\n",
            "shadow model: 67  epoch: 82  loss= 0.10882049053907394\n",
            "shadow model: 67  epoch: 83  loss= 0.0975203588604927\n",
            "shadow model: 67  epoch: 84  loss= 0.07292919605970383\n",
            "shadow model: 67  epoch: 85  loss= 0.06944622844457626\n",
            "shadow model: 67  epoch: 86  loss= 0.14591316878795624\n",
            "shadow model: 67  epoch: 87  loss= 0.05686178803443909\n",
            "shadow model: 67  epoch: 88  loss= 0.1384115070104599\n",
            "shadow model: 67  epoch: 89  loss= 0.052289869636297226\n",
            "shadow model: 67  epoch: 90  loss= 0.11132708191871643\n",
            "shadow model: 67  epoch: 91  loss= 0.06855598837137222\n",
            "shadow model: 67  epoch: 92  loss= 0.1664583683013916\n",
            "shadow model: 67  epoch: 93  loss= 0.028032178059220314\n",
            "shadow model: 67  epoch: 94  loss= 0.08792921900749207\n",
            "shadow model: 67  epoch: 95  loss= 0.07959292083978653\n",
            "shadow model: 67  epoch: 96  loss= 0.022799082100391388\n",
            "shadow model: 67  epoch: 97  loss= 0.08364465832710266\n",
            "shadow model: 67  epoch: 98  loss= 0.062008023262023926\n",
            "shadow model: 67  epoch: 99  loss= 0.1589638739824295\n",
            "shadow model: 67  epoch: 100  loss= 0.06218630447983742\n",
            "shadow model: 67  epoch: 101  loss= 0.04055923968553543\n",
            "shadow model: 67  epoch: 102  loss= 0.10512915998697281\n",
            "shadow model: 67  epoch: 103  loss= 0.12685789167881012\n",
            "shadow model: 67  epoch: 104  loss= 0.07224384695291519\n",
            "shadow model: 67  epoch: 105  loss= 0.08425023406744003\n",
            "shadow model: 67  epoch: 106  loss= 0.02284199744462967\n",
            "shadow model: 67  epoch: 107  loss= 0.044190406799316406\n",
            "shadow model: 67  epoch: 108  loss= 0.10509636253118515\n",
            "shadow model: 67  epoch: 109  loss= 0.0916532650589943\n",
            "shadow model: 67  epoch: 110  loss= 0.03436854109168053\n",
            "shadow model: 67  epoch: 111  loss= 0.15941226482391357\n",
            "shadow model: 67  epoch: 112  loss= 0.023573020473122597\n",
            "shadow model: 67  epoch: 113  loss= 0.0636526420712471\n",
            "shadow model: 67  epoch: 114  loss= 0.06979918479919434\n",
            "shadow model: 67  epoch: 115  loss= 0.0292043536901474\n",
            "shadow model: 67  epoch: 116  loss= 0.022013476118445396\n",
            "shadow model: 67  epoch: 117  loss= 0.10914304852485657\n",
            "shadow model: 67  epoch: 118  loss= 0.07025130093097687\n",
            "shadow model: 67  epoch: 119  loss= 0.04494728520512581\n",
            "shadow model: 67  epoch: 120  loss= 0.059603285044431686\n",
            "shadow model: 67  epoch: 121  loss= 0.15220357477664948\n",
            "shadow model: 67  epoch: 122  loss= 0.03413799777626991\n",
            "shadow model: 67  epoch: 123  loss= 0.17535953223705292\n",
            "shadow model: 67  epoch: 124  loss= 0.04046154394745827\n",
            "shadow model: 67  epoch: 125  loss= 0.06171521171927452\n",
            "shadow model: 67  epoch: 126  loss= 0.07145238667726517\n",
            "shadow model: 67  epoch: 127  loss= 0.10368045419454575\n",
            "shadow model: 67  epoch: 128  loss= 0.037507314234972\n",
            "shadow model: 67  epoch: 129  loss= 0.019377628341317177\n",
            "shadow model: 67  epoch: 130  loss= 0.17954230308532715\n",
            "shadow model: 67  epoch: 131  loss= 0.11907307058572769\n",
            "shadow model: 67  epoch: 132  loss= 0.025862373411655426\n",
            "shadow model: 67  epoch: 133  loss= 0.03625677153468132\n",
            "shadow model: 67  epoch: 134  loss= 0.052547771483659744\n",
            "shadow model: 67  epoch: 135  loss= 0.1198582649230957\n",
            "shadow model: 67  epoch: 136  loss= 0.09339898824691772\n",
            "shadow model: 67  epoch: 137  loss= 0.027720166370272636\n",
            "shadow model: 67  epoch: 138  loss= 0.14424709975719452\n",
            "shadow model: 67  epoch: 139  loss= 0.1046200767159462\n",
            "shadow model: 67  epoch: 140  loss= 0.026579594239592552\n",
            "shadow model: 67  epoch: 141  loss= 0.0230565145611763\n",
            "shadow model: 67  epoch: 142  loss= 0.10341355949640274\n",
            "shadow model: 67  epoch: 143  loss= 0.1449125111103058\n",
            "shadow model: 67  epoch: 144  loss= 0.08967989683151245\n",
            "shadow model: 67  epoch: 145  loss= 0.008580717258155346\n",
            "shadow model: 67  epoch: 146  loss= 0.05061717331409454\n",
            "shadow model: 67  epoch: 147  loss= 0.020439745858311653\n",
            "shadow model: 67  epoch: 148  loss= 0.05333161726593971\n",
            "shadow model: 67  epoch: 149  loss= 0.020744500681757927\n",
            "\n",
            "shadow model: 68  epoch: 0  loss= 2.305959701538086\n",
            "shadow model: 68  epoch: 1  loss= 2.3074707984924316\n",
            "shadow model: 68  epoch: 2  loss= 2.1917831897735596\n",
            "shadow model: 68  epoch: 3  loss= 2.1559689044952393\n",
            "shadow model: 68  epoch: 4  loss= 1.965063452720642\n",
            "shadow model: 68  epoch: 5  loss= 2.0175209045410156\n",
            "shadow model: 68  epoch: 6  loss= 1.854905128479004\n",
            "shadow model: 68  epoch: 7  loss= 1.8351517915725708\n",
            "shadow model: 68  epoch: 8  loss= 1.7687300443649292\n",
            "shadow model: 68  epoch: 9  loss= 1.739956259727478\n",
            "shadow model: 68  epoch: 10  loss= 1.6245192289352417\n",
            "shadow model: 68  epoch: 11  loss= 1.697590947151184\n",
            "shadow model: 68  epoch: 12  loss= 1.533423900604248\n",
            "shadow model: 68  epoch: 13  loss= 1.3524646759033203\n",
            "shadow model: 68  epoch: 14  loss= 1.4820398092269897\n",
            "shadow model: 68  epoch: 15  loss= 1.406312346458435\n",
            "shadow model: 68  epoch: 16  loss= 1.0815752744674683\n",
            "shadow model: 68  epoch: 17  loss= 1.2209819555282593\n",
            "shadow model: 68  epoch: 18  loss= 1.0700604915618896\n",
            "shadow model: 68  epoch: 19  loss= 1.052704095840454\n",
            "shadow model: 68  epoch: 20  loss= 0.9334672093391418\n",
            "shadow model: 68  epoch: 21  loss= 0.7628262042999268\n",
            "shadow model: 68  epoch: 22  loss= 0.6405559778213501\n",
            "shadow model: 68  epoch: 23  loss= 0.8409362435340881\n",
            "shadow model: 68  epoch: 24  loss= 0.8065316081047058\n",
            "shadow model: 68  epoch: 25  loss= 0.5943356156349182\n",
            "shadow model: 68  epoch: 26  loss= 0.7176814079284668\n",
            "shadow model: 68  epoch: 27  loss= 0.5474381446838379\n",
            "shadow model: 68  epoch: 28  loss= 0.400566428899765\n",
            "shadow model: 68  epoch: 29  loss= 0.4665532112121582\n",
            "shadow model: 68  epoch: 30  loss= 0.5840266346931458\n",
            "shadow model: 68  epoch: 31  loss= 0.47603917121887207\n",
            "shadow model: 68  epoch: 32  loss= 0.44676825404167175\n",
            "shadow model: 68  epoch: 33  loss= 0.3784022033214569\n",
            "shadow model: 68  epoch: 34  loss= 0.38363876938819885\n",
            "shadow model: 68  epoch: 35  loss= 0.39459362626075745\n",
            "shadow model: 68  epoch: 36  loss= 0.34900549054145813\n",
            "shadow model: 68  epoch: 37  loss= 0.30514979362487793\n",
            "shadow model: 68  epoch: 38  loss= 0.32998940348625183\n",
            "shadow model: 68  epoch: 39  loss= 0.3669179677963257\n",
            "shadow model: 68  epoch: 40  loss= 0.19274170696735382\n",
            "shadow model: 68  epoch: 41  loss= 0.16405220329761505\n",
            "shadow model: 68  epoch: 42  loss= 0.4566372334957123\n",
            "shadow model: 68  epoch: 43  loss= 0.21487979590892792\n",
            "shadow model: 68  epoch: 44  loss= 0.2307741641998291\n",
            "shadow model: 68  epoch: 45  loss= 0.20858706533908844\n",
            "shadow model: 68  epoch: 46  loss= 0.22832047939300537\n",
            "shadow model: 68  epoch: 47  loss= 0.32066839933395386\n",
            "shadow model: 68  epoch: 48  loss= 0.09858983010053635\n",
            "shadow model: 68  epoch: 49  loss= 0.14469243586063385\n",
            "shadow model: 68  epoch: 50  loss= 0.16462770104408264\n",
            "shadow model: 68  epoch: 51  loss= 0.12142551690340042\n",
            "shadow model: 68  epoch: 52  loss= 0.12737898528575897\n",
            "shadow model: 68  epoch: 53  loss= 0.12238594144582748\n",
            "shadow model: 68  epoch: 54  loss= 0.1764369159936905\n",
            "shadow model: 68  epoch: 55  loss= 0.21448145806789398\n",
            "shadow model: 68  epoch: 56  loss= 0.09504785388708115\n",
            "shadow model: 68  epoch: 57  loss= 0.07343333214521408\n",
            "shadow model: 68  epoch: 58  loss= 0.1649029701948166\n",
            "shadow model: 68  epoch: 59  loss= 0.16864828765392303\n",
            "shadow model: 68  epoch: 60  loss= 0.18216468393802643\n",
            "shadow model: 68  epoch: 61  loss= 0.11185667663812637\n",
            "shadow model: 68  epoch: 62  loss= 0.07354062050580978\n",
            "shadow model: 68  epoch: 63  loss= 0.06350890547037125\n",
            "shadow model: 68  epoch: 64  loss= 0.17921729385852814\n",
            "shadow model: 68  epoch: 65  loss= 0.20001213252544403\n",
            "shadow model: 68  epoch: 66  loss= 0.060942068696022034\n",
            "shadow model: 68  epoch: 67  loss= 0.19239085912704468\n",
            "shadow model: 68  epoch: 68  loss= 0.10992424935102463\n",
            "shadow model: 68  epoch: 69  loss= 0.03912123665213585\n",
            "shadow model: 68  epoch: 70  loss= 0.09353595227003098\n",
            "shadow model: 68  epoch: 71  loss= 0.06938964873552322\n",
            "shadow model: 68  epoch: 72  loss= 0.10799498111009598\n",
            "shadow model: 68  epoch: 73  loss= 0.07607541233301163\n",
            "shadow model: 68  epoch: 74  loss= 0.08360105007886887\n",
            "shadow model: 68  epoch: 75  loss= 0.07645594328641891\n",
            "shadow model: 68  epoch: 76  loss= 0.08110979199409485\n",
            "shadow model: 68  epoch: 77  loss= 0.11291676759719849\n",
            "shadow model: 68  epoch: 78  loss= 0.09891892224550247\n",
            "shadow model: 68  epoch: 79  loss= 0.07360436767339706\n",
            "shadow model: 68  epoch: 80  loss= 0.15632063150405884\n",
            "shadow model: 68  epoch: 81  loss= 0.1220470443367958\n",
            "shadow model: 68  epoch: 82  loss= 0.0695699080824852\n",
            "shadow model: 68  epoch: 83  loss= 0.06785403937101364\n",
            "shadow model: 68  epoch: 84  loss= 0.0783696249127388\n",
            "shadow model: 68  epoch: 85  loss= 0.0366482250392437\n",
            "shadow model: 68  epoch: 86  loss= 0.09079539030790329\n",
            "shadow model: 68  epoch: 87  loss= 0.14821173250675201\n",
            "shadow model: 68  epoch: 88  loss= 0.06520313769578934\n",
            "shadow model: 68  epoch: 89  loss= 0.06005671247839928\n",
            "shadow model: 68  epoch: 90  loss= 0.06750117987394333\n",
            "shadow model: 68  epoch: 91  loss= 0.11736530810594559\n",
            "shadow model: 68  epoch: 92  loss= 0.08952963352203369\n",
            "shadow model: 68  epoch: 93  loss= 0.0756845697760582\n",
            "shadow model: 68  epoch: 94  loss= 0.16647396981716156\n",
            "shadow model: 68  epoch: 95  loss= 0.09765156358480453\n",
            "shadow model: 68  epoch: 96  loss= 0.018699700012803078\n",
            "shadow model: 68  epoch: 97  loss= 0.037296976894140244\n",
            "shadow model: 68  epoch: 98  loss= 0.1128627136349678\n",
            "shadow model: 68  epoch: 99  loss= 0.03956123813986778\n",
            "shadow model: 68  epoch: 100  loss= 0.024762161076068878\n",
            "shadow model: 68  epoch: 101  loss= 0.07913468033075333\n",
            "shadow model: 68  epoch: 102  loss= 0.05799861252307892\n",
            "shadow model: 68  epoch: 103  loss= 0.0464593805372715\n",
            "shadow model: 68  epoch: 104  loss= 0.10017172247171402\n",
            "shadow model: 68  epoch: 105  loss= 0.0414537712931633\n",
            "shadow model: 68  epoch: 106  loss= 0.07103932648897171\n",
            "shadow model: 68  epoch: 107  loss= 0.12710212171077728\n",
            "shadow model: 68  epoch: 108  loss= 0.04439587891101837\n",
            "shadow model: 68  epoch: 109  loss= 0.02696932666003704\n",
            "shadow model: 68  epoch: 110  loss= 0.13245666027069092\n",
            "shadow model: 68  epoch: 111  loss= 0.10082986950874329\n",
            "shadow model: 68  epoch: 112  loss= 0.0414249412715435\n",
            "shadow model: 68  epoch: 113  loss= 0.0841962918639183\n",
            "shadow model: 68  epoch: 114  loss= 0.04322503134608269\n",
            "shadow model: 68  epoch: 115  loss= 0.03487032651901245\n",
            "shadow model: 68  epoch: 116  loss= 0.01900494284927845\n",
            "shadow model: 68  epoch: 117  loss= 0.02449539303779602\n",
            "shadow model: 68  epoch: 118  loss= 0.09442806988954544\n",
            "shadow model: 68  epoch: 119  loss= 0.020737262442708015\n",
            "shadow model: 68  epoch: 120  loss= 0.02468431554734707\n",
            "shadow model: 68  epoch: 121  loss= 0.05550561845302582\n",
            "shadow model: 68  epoch: 122  loss= 0.08102922886610031\n",
            "shadow model: 68  epoch: 123  loss= 0.1042630672454834\n",
            "shadow model: 68  epoch: 124  loss= 0.047447796911001205\n",
            "shadow model: 68  epoch: 125  loss= 0.08313173800706863\n",
            "shadow model: 68  epoch: 126  loss= 0.026460735127329826\n",
            "shadow model: 68  epoch: 127  loss= 0.011382509022951126\n",
            "shadow model: 68  epoch: 128  loss= 0.025831324979662895\n",
            "shadow model: 68  epoch: 129  loss= 0.08299072086811066\n",
            "shadow model: 68  epoch: 130  loss= 0.03348110616207123\n",
            "shadow model: 68  epoch: 131  loss= 0.029493050649762154\n",
            "shadow model: 68  epoch: 132  loss= 0.07102090865373611\n",
            "shadow model: 68  epoch: 133  loss= 0.05472489818930626\n",
            "shadow model: 68  epoch: 134  loss= 0.0374569408595562\n",
            "shadow model: 68  epoch: 135  loss= 0.04257330298423767\n",
            "shadow model: 68  epoch: 136  loss= 0.03873733803629875\n",
            "shadow model: 68  epoch: 137  loss= 0.0528264082968235\n",
            "shadow model: 68  epoch: 138  loss= 0.02652781270444393\n",
            "shadow model: 68  epoch: 139  loss= 0.02768584154546261\n",
            "shadow model: 68  epoch: 140  loss= 0.026224590837955475\n",
            "shadow model: 68  epoch: 141  loss= 0.010590867139399052\n",
            "shadow model: 68  epoch: 142  loss= 0.039393115788698196\n",
            "shadow model: 68  epoch: 143  loss= 0.06336913257837296\n",
            "shadow model: 68  epoch: 144  loss= 0.028138816356658936\n",
            "shadow model: 68  epoch: 145  loss= 0.043180033564567566\n",
            "shadow model: 68  epoch: 146  loss= 0.059123069047927856\n",
            "shadow model: 68  epoch: 147  loss= 0.0440182089805603\n",
            "shadow model: 68  epoch: 148  loss= 0.028838025406003\n",
            "shadow model: 68  epoch: 149  loss= 0.06872149556875229\n",
            "\n",
            "shadow model: 69  epoch: 0  loss= 2.3827455043792725\n",
            "shadow model: 69  epoch: 1  loss= 2.2587997913360596\n",
            "shadow model: 69  epoch: 2  loss= 2.208721876144409\n",
            "shadow model: 69  epoch: 3  loss= 2.131676435470581\n",
            "shadow model: 69  epoch: 4  loss= 2.1106393337249756\n",
            "shadow model: 69  epoch: 5  loss= 1.989305019378662\n",
            "shadow model: 69  epoch: 6  loss= 1.7840741872787476\n",
            "shadow model: 69  epoch: 7  loss= 1.8901891708374023\n",
            "shadow model: 69  epoch: 8  loss= 1.922192096710205\n",
            "shadow model: 69  epoch: 9  loss= 1.7535486221313477\n",
            "shadow model: 69  epoch: 10  loss= 1.605646014213562\n",
            "shadow model: 69  epoch: 11  loss= 1.4715867042541504\n",
            "shadow model: 69  epoch: 12  loss= 1.353498101234436\n",
            "shadow model: 69  epoch: 13  loss= 1.4716272354125977\n",
            "shadow model: 69  epoch: 14  loss= 1.1072360277175903\n",
            "shadow model: 69  epoch: 15  loss= 1.3375349044799805\n",
            "shadow model: 69  epoch: 16  loss= 1.2859362363815308\n",
            "shadow model: 69  epoch: 17  loss= 0.8220994472503662\n",
            "shadow model: 69  epoch: 18  loss= 0.8152356147766113\n",
            "shadow model: 69  epoch: 19  loss= 0.9794558882713318\n",
            "shadow model: 69  epoch: 20  loss= 0.9951301217079163\n",
            "shadow model: 69  epoch: 21  loss= 0.8365421891212463\n",
            "shadow model: 69  epoch: 22  loss= 0.7065885066986084\n",
            "shadow model: 69  epoch: 23  loss= 0.9163112044334412\n",
            "shadow model: 69  epoch: 24  loss= 0.8518396019935608\n",
            "shadow model: 69  epoch: 25  loss= 0.6026437878608704\n",
            "shadow model: 69  epoch: 26  loss= 0.7417390942573547\n",
            "shadow model: 69  epoch: 27  loss= 0.7784945964813232\n",
            "shadow model: 69  epoch: 28  loss= 0.6922007203102112\n",
            "shadow model: 69  epoch: 29  loss= 0.576082170009613\n",
            "shadow model: 69  epoch: 30  loss= 0.555253803730011\n",
            "shadow model: 69  epoch: 31  loss= 0.6033539175987244\n",
            "shadow model: 69  epoch: 32  loss= 0.5490959882736206\n",
            "shadow model: 69  epoch: 33  loss= 0.4659109115600586\n",
            "shadow model: 69  epoch: 34  loss= 0.3633282482624054\n",
            "shadow model: 69  epoch: 35  loss= 0.44101759791374207\n",
            "shadow model: 69  epoch: 36  loss= 0.3462415933609009\n",
            "shadow model: 69  epoch: 37  loss= 0.35050907731056213\n",
            "shadow model: 69  epoch: 38  loss= 0.4011448919773102\n",
            "shadow model: 69  epoch: 39  loss= 0.3416675627231598\n",
            "shadow model: 69  epoch: 40  loss= 0.4380027949810028\n",
            "shadow model: 69  epoch: 41  loss= 0.19468027353286743\n",
            "shadow model: 69  epoch: 42  loss= 0.41290244460105896\n",
            "shadow model: 69  epoch: 43  loss= 0.25732097029685974\n",
            "shadow model: 69  epoch: 44  loss= 0.39815470576286316\n",
            "shadow model: 69  epoch: 45  loss= 0.2889157831668854\n",
            "shadow model: 69  epoch: 46  loss= 0.38853704929351807\n",
            "shadow model: 69  epoch: 47  loss= 0.255229651927948\n",
            "shadow model: 69  epoch: 48  loss= 0.36725106835365295\n",
            "shadow model: 69  epoch: 49  loss= 0.38493624329566956\n",
            "shadow model: 69  epoch: 50  loss= 0.31262412667274475\n",
            "shadow model: 69  epoch: 51  loss= 0.18160812556743622\n",
            "shadow model: 69  epoch: 52  loss= 0.1476418524980545\n",
            "shadow model: 69  epoch: 53  loss= 0.1905299425125122\n",
            "shadow model: 69  epoch: 54  loss= 0.3165600001811981\n",
            "shadow model: 69  epoch: 55  loss= 0.32999175786972046\n",
            "shadow model: 69  epoch: 56  loss= 0.14455989003181458\n",
            "shadow model: 69  epoch: 57  loss= 0.11241522431373596\n",
            "shadow model: 69  epoch: 58  loss= 0.2824288010597229\n",
            "shadow model: 69  epoch: 59  loss= 0.2212141901254654\n",
            "shadow model: 69  epoch: 60  loss= 0.19908781349658966\n",
            "shadow model: 69  epoch: 61  loss= 0.12937380373477936\n",
            "shadow model: 69  epoch: 62  loss= 0.10475045442581177\n",
            "shadow model: 69  epoch: 63  loss= 0.24786706268787384\n",
            "shadow model: 69  epoch: 64  loss= 0.21921657025814056\n",
            "shadow model: 69  epoch: 65  loss= 0.08327905088663101\n",
            "shadow model: 69  epoch: 66  loss= 0.19013698399066925\n",
            "shadow model: 69  epoch: 67  loss= 0.2724744379520416\n",
            "shadow model: 69  epoch: 68  loss= 0.07826227694749832\n",
            "shadow model: 69  epoch: 69  loss= 0.13958929479122162\n",
            "shadow model: 69  epoch: 70  loss= 0.16751353442668915\n",
            "shadow model: 69  epoch: 71  loss= 0.11532366275787354\n",
            "shadow model: 69  epoch: 72  loss= 0.23485243320465088\n",
            "shadow model: 69  epoch: 73  loss= 0.10519786924123764\n",
            "shadow model: 69  epoch: 74  loss= 0.2332887202501297\n",
            "shadow model: 69  epoch: 75  loss= 0.12988215684890747\n",
            "shadow model: 69  epoch: 76  loss= 0.11767377704381943\n",
            "shadow model: 69  epoch: 77  loss= 0.1812506467103958\n",
            "shadow model: 69  epoch: 78  loss= 0.0674697682261467\n",
            "shadow model: 69  epoch: 79  loss= 0.1463657170534134\n",
            "shadow model: 69  epoch: 80  loss= 0.14361010491847992\n",
            "shadow model: 69  epoch: 81  loss= 0.1477210968732834\n",
            "shadow model: 69  epoch: 82  loss= 0.056262385100126266\n",
            "shadow model: 69  epoch: 83  loss= 0.1107344701886177\n",
            "shadow model: 69  epoch: 84  loss= 0.08156682550907135\n",
            "shadow model: 69  epoch: 85  loss= 0.08998463302850723\n",
            "shadow model: 69  epoch: 86  loss= 0.1252261996269226\n",
            "shadow model: 69  epoch: 87  loss= 0.13977216184139252\n",
            "shadow model: 69  epoch: 88  loss= 0.047543659806251526\n",
            "shadow model: 69  epoch: 89  loss= 0.166055366396904\n",
            "shadow model: 69  epoch: 90  loss= 0.1289214789867401\n",
            "shadow model: 69  epoch: 91  loss= 0.11457190662622452\n",
            "shadow model: 69  epoch: 92  loss= 0.07691358029842377\n",
            "shadow model: 69  epoch: 93  loss= 0.18094800412654877\n",
            "shadow model: 69  epoch: 94  loss= 0.1213746964931488\n",
            "shadow model: 69  epoch: 95  loss= 0.08173073828220367\n",
            "shadow model: 69  epoch: 96  loss= 0.1319590061903\n",
            "shadow model: 69  epoch: 97  loss= 0.07864402234554291\n",
            "shadow model: 69  epoch: 98  loss= 0.05404632166028023\n",
            "shadow model: 69  epoch: 99  loss= 0.159475639462471\n",
            "shadow model: 69  epoch: 100  loss= 0.18582642078399658\n",
            "shadow model: 69  epoch: 101  loss= 0.07931017130613327\n",
            "shadow model: 69  epoch: 102  loss= 0.11057457327842712\n",
            "shadow model: 69  epoch: 103  loss= 0.162306547164917\n",
            "shadow model: 69  epoch: 104  loss= 0.12464738637208939\n",
            "shadow model: 69  epoch: 105  loss= 0.06445806473493576\n",
            "shadow model: 69  epoch: 106  loss= 0.07066792994737625\n",
            "shadow model: 69  epoch: 107  loss= 0.1734311431646347\n",
            "shadow model: 69  epoch: 108  loss= 0.16228406131267548\n",
            "shadow model: 69  epoch: 109  loss= 0.0494796484708786\n",
            "shadow model: 69  epoch: 110  loss= 0.12297580391168594\n",
            "shadow model: 69  epoch: 111  loss= 0.08231908828020096\n",
            "shadow model: 69  epoch: 112  loss= 0.0799240842461586\n",
            "shadow model: 69  epoch: 113  loss= 0.029128722846508026\n",
            "shadow model: 69  epoch: 114  loss= 0.3321087956428528\n",
            "shadow model: 69  epoch: 115  loss= 0.05406346917152405\n",
            "shadow model: 69  epoch: 116  loss= 0.09649217128753662\n",
            "shadow model: 69  epoch: 117  loss= 0.09519677609205246\n",
            "shadow model: 69  epoch: 118  loss= 0.07518164068460464\n",
            "shadow model: 69  epoch: 119  loss= 0.020778223872184753\n",
            "shadow model: 69  epoch: 120  loss= 0.027316339313983917\n",
            "shadow model: 69  epoch: 121  loss= 0.052341263741254807\n",
            "shadow model: 69  epoch: 122  loss= 0.043589454144239426\n",
            "shadow model: 69  epoch: 123  loss= 0.08955926448106766\n",
            "shadow model: 69  epoch: 124  loss= 0.12608854472637177\n",
            "shadow model: 69  epoch: 125  loss= 0.048005521297454834\n",
            "shadow model: 69  epoch: 126  loss= 0.11761777848005295\n",
            "shadow model: 69  epoch: 127  loss= 0.08728056401014328\n",
            "shadow model: 69  epoch: 128  loss= 0.09926760196685791\n",
            "shadow model: 69  epoch: 129  loss= 0.09081963449716568\n",
            "shadow model: 69  epoch: 130  loss= 0.13847647607326508\n",
            "shadow model: 69  epoch: 131  loss= 0.11972720175981522\n",
            "shadow model: 69  epoch: 132  loss= 0.04848337173461914\n",
            "shadow model: 69  epoch: 133  loss= 0.07215341180562973\n",
            "shadow model: 69  epoch: 134  loss= 0.11364864557981491\n",
            "shadow model: 69  epoch: 135  loss= 0.03876060992479324\n",
            "shadow model: 69  epoch: 136  loss= 0.04770292714238167\n",
            "shadow model: 69  epoch: 137  loss= 0.042802345007658005\n",
            "shadow model: 69  epoch: 138  loss= 0.1731330305337906\n",
            "shadow model: 69  epoch: 139  loss= 0.06203542277216911\n",
            "shadow model: 69  epoch: 140  loss= 0.022975057363510132\n",
            "shadow model: 69  epoch: 141  loss= 0.05876169726252556\n",
            "shadow model: 69  epoch: 142  loss= 0.018091067671775818\n",
            "shadow model: 69  epoch: 143  loss= 0.15441899001598358\n",
            "shadow model: 69  epoch: 144  loss= 0.030977552756667137\n",
            "shadow model: 69  epoch: 145  loss= 0.0868907943367958\n",
            "shadow model: 69  epoch: 146  loss= 0.07629410922527313\n",
            "shadow model: 69  epoch: 147  loss= 0.04941035434603691\n",
            "shadow model: 69  epoch: 148  loss= 0.08291330933570862\n",
            "shadow model: 69  epoch: 149  loss= 0.14620977640151978\n",
            "\n",
            "shadow model: 70  epoch: 0  loss= 2.3638715744018555\n",
            "shadow model: 70  epoch: 1  loss= 2.2708699703216553\n",
            "shadow model: 70  epoch: 2  loss= 2.1554007530212402\n",
            "shadow model: 70  epoch: 3  loss= 2.155574321746826\n",
            "shadow model: 70  epoch: 4  loss= 2.0258965492248535\n",
            "shadow model: 70  epoch: 5  loss= 2.0237786769866943\n",
            "shadow model: 70  epoch: 6  loss= 1.7170162200927734\n",
            "shadow model: 70  epoch: 7  loss= 1.9260395765304565\n",
            "shadow model: 70  epoch: 8  loss= 1.721889615058899\n",
            "shadow model: 70  epoch: 9  loss= 1.6708984375\n",
            "shadow model: 70  epoch: 10  loss= 1.7010222673416138\n",
            "shadow model: 70  epoch: 11  loss= 1.6495829820632935\n",
            "shadow model: 70  epoch: 12  loss= 1.2653449773788452\n",
            "shadow model: 70  epoch: 13  loss= 1.338578224182129\n",
            "shadow model: 70  epoch: 14  loss= 1.675736904144287\n",
            "shadow model: 70  epoch: 15  loss= 1.1513642072677612\n",
            "shadow model: 70  epoch: 16  loss= 1.3263636827468872\n",
            "shadow model: 70  epoch: 17  loss= 1.3475583791732788\n",
            "shadow model: 70  epoch: 18  loss= 1.2411409616470337\n",
            "shadow model: 70  epoch: 19  loss= 1.0771113634109497\n",
            "shadow model: 70  epoch: 20  loss= 1.1012003421783447\n",
            "shadow model: 70  epoch: 21  loss= 0.7879895567893982\n",
            "shadow model: 70  epoch: 22  loss= 0.7317689061164856\n",
            "shadow model: 70  epoch: 23  loss= 0.6801807880401611\n",
            "shadow model: 70  epoch: 24  loss= 0.5866764187812805\n",
            "shadow model: 70  epoch: 25  loss= 0.5331260561943054\n",
            "shadow model: 70  epoch: 26  loss= 0.8086509108543396\n",
            "shadow model: 70  epoch: 27  loss= 0.7273324131965637\n",
            "shadow model: 70  epoch: 28  loss= 0.5635181069374084\n",
            "shadow model: 70  epoch: 29  loss= 0.689993679523468\n",
            "shadow model: 70  epoch: 30  loss= 0.5941235423088074\n",
            "shadow model: 70  epoch: 31  loss= 0.5692505240440369\n",
            "shadow model: 70  epoch: 32  loss= 0.47023919224739075\n",
            "shadow model: 70  epoch: 33  loss= 0.3359619081020355\n",
            "shadow model: 70  epoch: 34  loss= 0.4070124626159668\n",
            "shadow model: 70  epoch: 35  loss= 0.4059915840625763\n",
            "shadow model: 70  epoch: 36  loss= 0.2573557496070862\n",
            "shadow model: 70  epoch: 37  loss= 0.3160386085510254\n",
            "shadow model: 70  epoch: 38  loss= 0.30680131912231445\n",
            "shadow model: 70  epoch: 39  loss= 0.272629052400589\n",
            "shadow model: 70  epoch: 40  loss= 0.33353087306022644\n",
            "shadow model: 70  epoch: 41  loss= 0.3436235189437866\n",
            "shadow model: 70  epoch: 42  loss= 0.1785532832145691\n",
            "shadow model: 70  epoch: 43  loss= 0.2542668282985687\n",
            "shadow model: 70  epoch: 44  loss= 0.24870270490646362\n",
            "shadow model: 70  epoch: 45  loss= 0.1256614774465561\n",
            "shadow model: 70  epoch: 46  loss= 0.15466777980327606\n",
            "shadow model: 70  epoch: 47  loss= 0.3745591640472412\n",
            "shadow model: 70  epoch: 48  loss= 0.10785597562789917\n",
            "shadow model: 70  epoch: 49  loss= 0.19456206262111664\n",
            "shadow model: 70  epoch: 50  loss= 0.15097595751285553\n",
            "shadow model: 70  epoch: 51  loss= 0.08992886543273926\n",
            "shadow model: 70  epoch: 52  loss= 0.35866427421569824\n",
            "shadow model: 70  epoch: 53  loss= 0.22008031606674194\n",
            "shadow model: 70  epoch: 54  loss= 0.1927453726530075\n",
            "shadow model: 70  epoch: 55  loss= 0.14195168018341064\n",
            "shadow model: 70  epoch: 56  loss= 0.2493995577096939\n",
            "shadow model: 70  epoch: 57  loss= 0.14458756148815155\n",
            "shadow model: 70  epoch: 58  loss= 0.10744189471006393\n",
            "shadow model: 70  epoch: 59  loss= 0.18369245529174805\n",
            "shadow model: 70  epoch: 60  loss= 0.21097511053085327\n",
            "shadow model: 70  epoch: 61  loss= 0.13313791155815125\n",
            "shadow model: 70  epoch: 62  loss= 0.14236141741275787\n",
            "shadow model: 70  epoch: 63  loss= 0.06760512292385101\n",
            "shadow model: 70  epoch: 64  loss= 0.20274388790130615\n",
            "shadow model: 70  epoch: 65  loss= 0.1031193733215332\n",
            "shadow model: 70  epoch: 66  loss= 0.18340198695659637\n",
            "shadow model: 70  epoch: 67  loss= 0.09654086083173752\n",
            "shadow model: 70  epoch: 68  loss= 0.17032058537006378\n",
            "shadow model: 70  epoch: 69  loss= 0.16540908813476562\n",
            "shadow model: 70  epoch: 70  loss= 0.20246683061122894\n",
            "shadow model: 70  epoch: 71  loss= 0.11620033532381058\n",
            "shadow model: 70  epoch: 72  loss= 0.062407780438661575\n",
            "shadow model: 70  epoch: 73  loss= 0.03710130974650383\n",
            "shadow model: 70  epoch: 74  loss= 0.05372343584895134\n",
            "shadow model: 70  epoch: 75  loss= 0.06513112038373947\n",
            "shadow model: 70  epoch: 76  loss= 0.061015497893095016\n",
            "shadow model: 70  epoch: 77  loss= 0.1011902317404747\n",
            "shadow model: 70  epoch: 78  loss= 0.06644613295793533\n",
            "shadow model: 70  epoch: 79  loss= 0.16155920922756195\n",
            "shadow model: 70  epoch: 80  loss= 0.14829085767269135\n",
            "shadow model: 70  epoch: 81  loss= 0.12456239014863968\n",
            "shadow model: 70  epoch: 82  loss= 0.07170319557189941\n",
            "shadow model: 70  epoch: 83  loss= 0.17180603742599487\n",
            "shadow model: 70  epoch: 84  loss= 0.10079708695411682\n",
            "shadow model: 70  epoch: 85  loss= 0.05129941180348396\n",
            "shadow model: 70  epoch: 86  loss= 0.09087032824754715\n",
            "shadow model: 70  epoch: 87  loss= 0.09528211504220963\n",
            "shadow model: 70  epoch: 88  loss= 0.06602175533771515\n",
            "shadow model: 70  epoch: 89  loss= 0.0621957890689373\n",
            "shadow model: 70  epoch: 90  loss= 0.06438013166189194\n",
            "shadow model: 70  epoch: 91  loss= 0.13881172239780426\n",
            "shadow model: 70  epoch: 92  loss= 0.07595892995595932\n",
            "shadow model: 70  epoch: 93  loss= 0.07132821530103683\n",
            "shadow model: 70  epoch: 94  loss= 0.09137313812971115\n",
            "shadow model: 70  epoch: 95  loss= 0.09403438121080399\n",
            "shadow model: 70  epoch: 96  loss= 0.07757043093442917\n",
            "shadow model: 70  epoch: 97  loss= 0.1578531116247177\n",
            "shadow model: 70  epoch: 98  loss= 0.07542257755994797\n",
            "shadow model: 70  epoch: 99  loss= 0.1531796157360077\n",
            "shadow model: 70  epoch: 100  loss= 0.041438471525907516\n",
            "shadow model: 70  epoch: 101  loss= 0.0702102780342102\n",
            "shadow model: 70  epoch: 102  loss= 0.08487901091575623\n",
            "shadow model: 70  epoch: 103  loss= 0.03033532202243805\n",
            "shadow model: 70  epoch: 104  loss= 0.10093215107917786\n",
            "shadow model: 70  epoch: 105  loss= 0.06919586658477783\n",
            "shadow model: 70  epoch: 106  loss= 0.023844795301556587\n",
            "shadow model: 70  epoch: 107  loss= 0.10606295615434647\n",
            "shadow model: 70  epoch: 108  loss= 0.021585287526249886\n",
            "shadow model: 70  epoch: 109  loss= 0.12812916934490204\n",
            "shadow model: 70  epoch: 110  loss= 0.07546104490756989\n",
            "shadow model: 70  epoch: 111  loss= 0.05460013449192047\n",
            "shadow model: 70  epoch: 112  loss= 0.04698190093040466\n",
            "shadow model: 70  epoch: 113  loss= 0.06572213768959045\n",
            "shadow model: 70  epoch: 114  loss= 0.027661887928843498\n",
            "shadow model: 70  epoch: 115  loss= 0.04897540435194969\n",
            "shadow model: 70  epoch: 116  loss= 0.05028757080435753\n",
            "shadow model: 70  epoch: 117  loss= 0.06050017103552818\n",
            "shadow model: 70  epoch: 118  loss= 0.04933800920844078\n",
            "shadow model: 70  epoch: 119  loss= 0.013428863137960434\n",
            "shadow model: 70  epoch: 120  loss= 0.022640710696578026\n",
            "shadow model: 70  epoch: 121  loss= 0.03208256885409355\n",
            "shadow model: 70  epoch: 122  loss= 0.08152740448713303\n",
            "shadow model: 70  epoch: 123  loss= 0.04131263867020607\n",
            "shadow model: 70  epoch: 124  loss= 0.04511329531669617\n",
            "shadow model: 70  epoch: 125  loss= 0.06684427708387375\n",
            "shadow model: 70  epoch: 126  loss= 0.050043780356645584\n",
            "shadow model: 70  epoch: 127  loss= 0.046450451016426086\n",
            "shadow model: 70  epoch: 128  loss= 0.05844813585281372\n",
            "shadow model: 70  epoch: 129  loss= 0.0628301128745079\n",
            "shadow model: 70  epoch: 130  loss= 0.07469425350427628\n",
            "shadow model: 70  epoch: 131  loss= 0.034871261566877365\n",
            "shadow model: 70  epoch: 132  loss= 0.03967518359422684\n",
            "shadow model: 70  epoch: 133  loss= 0.14032529294490814\n",
            "shadow model: 70  epoch: 134  loss= 0.03317973390221596\n",
            "shadow model: 70  epoch: 135  loss= 0.027109889313578606\n",
            "shadow model: 70  epoch: 136  loss= 0.05570654198527336\n",
            "shadow model: 70  epoch: 137  loss= 0.05447312071919441\n",
            "shadow model: 70  epoch: 138  loss= 0.019327184185385704\n",
            "shadow model: 70  epoch: 139  loss= 0.01918758824467659\n",
            "shadow model: 70  epoch: 140  loss= 0.02797764725983143\n",
            "shadow model: 70  epoch: 141  loss= 0.025980202481150627\n",
            "shadow model: 70  epoch: 142  loss= 0.15516714751720428\n",
            "shadow model: 70  epoch: 143  loss= 0.023548424243927002\n",
            "shadow model: 70  epoch: 144  loss= 0.06710102409124374\n",
            "shadow model: 70  epoch: 145  loss= 0.016390616074204445\n",
            "shadow model: 70  epoch: 146  loss= 0.08348677307367325\n",
            "shadow model: 70  epoch: 147  loss= 0.0393783263862133\n",
            "shadow model: 70  epoch: 148  loss= 0.032180435955524445\n",
            "shadow model: 70  epoch: 149  loss= 0.026177575811743736\n",
            "\n",
            "shadow model: 71  epoch: 0  loss= 2.3496720790863037\n",
            "shadow model: 71  epoch: 1  loss= 2.2226974964141846\n",
            "shadow model: 71  epoch: 2  loss= 2.146838665008545\n",
            "shadow model: 71  epoch: 3  loss= 2.1400463581085205\n",
            "shadow model: 71  epoch: 4  loss= 2.0293495655059814\n",
            "shadow model: 71  epoch: 5  loss= 2.0375897884368896\n",
            "shadow model: 71  epoch: 6  loss= 1.9245494604110718\n",
            "shadow model: 71  epoch: 7  loss= 1.963412880897522\n",
            "shadow model: 71  epoch: 8  loss= 1.6877899169921875\n",
            "shadow model: 71  epoch: 9  loss= 1.8997997045516968\n",
            "shadow model: 71  epoch: 10  loss= 1.855669617652893\n",
            "shadow model: 71  epoch: 11  loss= 1.6579046249389648\n",
            "shadow model: 71  epoch: 12  loss= 1.761954426765442\n",
            "shadow model: 71  epoch: 13  loss= 1.6810550689697266\n",
            "shadow model: 71  epoch: 14  loss= 1.6614755392074585\n",
            "shadow model: 71  epoch: 15  loss= 1.7393113374710083\n",
            "shadow model: 71  epoch: 16  loss= 1.469812273979187\n",
            "shadow model: 71  epoch: 17  loss= 1.3197002410888672\n",
            "shadow model: 71  epoch: 18  loss= 1.26555597782135\n",
            "shadow model: 71  epoch: 19  loss= 1.1546401977539062\n",
            "shadow model: 71  epoch: 20  loss= 1.137603521347046\n",
            "shadow model: 71  epoch: 21  loss= 0.9466072916984558\n",
            "shadow model: 71  epoch: 22  loss= 1.0222235918045044\n",
            "shadow model: 71  epoch: 23  loss= 1.0794786214828491\n",
            "shadow model: 71  epoch: 24  loss= 1.1152665615081787\n",
            "shadow model: 71  epoch: 25  loss= 0.8905701041221619\n",
            "shadow model: 71  epoch: 26  loss= 0.9541857838630676\n",
            "shadow model: 71  epoch: 27  loss= 0.6742528080940247\n",
            "shadow model: 71  epoch: 28  loss= 0.6619573831558228\n",
            "shadow model: 71  epoch: 29  loss= 0.7380728721618652\n",
            "shadow model: 71  epoch: 30  loss= 0.5563561320304871\n",
            "shadow model: 71  epoch: 31  loss= 0.529546856880188\n",
            "shadow model: 71  epoch: 32  loss= 0.6721634864807129\n",
            "shadow model: 71  epoch: 33  loss= 0.5458571910858154\n",
            "shadow model: 71  epoch: 34  loss= 0.6173385381698608\n",
            "shadow model: 71  epoch: 35  loss= 0.5728043913841248\n",
            "shadow model: 71  epoch: 36  loss= 0.4194309711456299\n",
            "shadow model: 71  epoch: 37  loss= 0.49808549880981445\n",
            "shadow model: 71  epoch: 38  loss= 0.5762093663215637\n",
            "shadow model: 71  epoch: 39  loss= 0.5340121388435364\n",
            "shadow model: 71  epoch: 40  loss= 0.4019050598144531\n",
            "shadow model: 71  epoch: 41  loss= 0.3439793586730957\n",
            "shadow model: 71  epoch: 42  loss= 0.23798821866512299\n",
            "shadow model: 71  epoch: 43  loss= 0.3551696538925171\n",
            "shadow model: 71  epoch: 44  loss= 0.3480403423309326\n",
            "shadow model: 71  epoch: 45  loss= 0.324339896440506\n",
            "shadow model: 71  epoch: 46  loss= 0.5062832236289978\n",
            "shadow model: 71  epoch: 47  loss= 0.3908860683441162\n",
            "shadow model: 71  epoch: 48  loss= 0.24051742255687714\n",
            "shadow model: 71  epoch: 49  loss= 0.17295198142528534\n",
            "shadow model: 71  epoch: 50  loss= 0.243152916431427\n",
            "shadow model: 71  epoch: 51  loss= 0.3004417419433594\n",
            "shadow model: 71  epoch: 52  loss= 0.22054030001163483\n",
            "shadow model: 71  epoch: 53  loss= 0.12612700462341309\n",
            "shadow model: 71  epoch: 54  loss= 0.2875751256942749\n",
            "shadow model: 71  epoch: 55  loss= 0.19149135053157806\n",
            "shadow model: 71  epoch: 56  loss= 0.19721399247646332\n",
            "shadow model: 71  epoch: 57  loss= 0.3114526867866516\n",
            "shadow model: 71  epoch: 58  loss= 0.2711702883243561\n",
            "shadow model: 71  epoch: 59  loss= 0.17781813442707062\n",
            "shadow model: 71  epoch: 60  loss= 0.29362285137176514\n",
            "shadow model: 71  epoch: 61  loss= 0.2515050768852234\n",
            "shadow model: 71  epoch: 62  loss= 0.24272505939006805\n",
            "shadow model: 71  epoch: 63  loss= 0.21798942983150482\n",
            "shadow model: 71  epoch: 64  loss= 0.208041250705719\n",
            "shadow model: 71  epoch: 65  loss= 0.22981958091259003\n",
            "shadow model: 71  epoch: 66  loss= 0.22789366543293\n",
            "shadow model: 71  epoch: 67  loss= 0.1396036297082901\n",
            "shadow model: 71  epoch: 68  loss= 0.22439587116241455\n",
            "shadow model: 71  epoch: 69  loss= 0.09279286861419678\n",
            "shadow model: 71  epoch: 70  loss= 0.1861727386713028\n",
            "shadow model: 71  epoch: 71  loss= 0.2064293622970581\n",
            "shadow model: 71  epoch: 72  loss= 0.12467630952596664\n",
            "shadow model: 71  epoch: 73  loss= 0.2081158608198166\n",
            "shadow model: 71  epoch: 74  loss= 0.06647281348705292\n",
            "shadow model: 71  epoch: 75  loss= 0.20573674142360687\n",
            "shadow model: 71  epoch: 76  loss= 0.09452982991933823\n",
            "shadow model: 71  epoch: 77  loss= 0.23415280878543854\n",
            "shadow model: 71  epoch: 78  loss= 0.1371198445558548\n",
            "shadow model: 71  epoch: 79  loss= 0.1627771258354187\n",
            "shadow model: 71  epoch: 80  loss= 0.05455368757247925\n",
            "shadow model: 71  epoch: 81  loss= 0.12841646373271942\n",
            "shadow model: 71  epoch: 82  loss= 0.07655821740627289\n",
            "shadow model: 71  epoch: 83  loss= 0.14447295665740967\n",
            "shadow model: 71  epoch: 84  loss= 0.1556405872106552\n",
            "shadow model: 71  epoch: 85  loss= 0.18631400167942047\n",
            "shadow model: 71  epoch: 86  loss= 0.1463773399591446\n",
            "shadow model: 71  epoch: 87  loss= 0.3072070777416229\n",
            "shadow model: 71  epoch: 88  loss= 0.15112288296222687\n",
            "shadow model: 71  epoch: 89  loss= 0.18960244953632355\n",
            "shadow model: 71  epoch: 90  loss= 0.15619371831417084\n",
            "shadow model: 71  epoch: 91  loss= 0.10958340764045715\n",
            "shadow model: 71  epoch: 92  loss= 0.11487386375665665\n",
            "shadow model: 71  epoch: 93  loss= 0.14554709196090698\n",
            "shadow model: 71  epoch: 94  loss= 0.09143438935279846\n",
            "shadow model: 71  epoch: 95  loss= 0.12233304232358932\n",
            "shadow model: 71  epoch: 96  loss= 0.09553743153810501\n",
            "shadow model: 71  epoch: 97  loss= 0.11864709854125977\n",
            "shadow model: 71  epoch: 98  loss= 0.05011589452624321\n",
            "shadow model: 71  epoch: 99  loss= 0.13445408642292023\n",
            "shadow model: 71  epoch: 100  loss= 0.06259958446025848\n",
            "shadow model: 71  epoch: 101  loss= 0.16749370098114014\n",
            "shadow model: 71  epoch: 102  loss= 0.06437581032514572\n",
            "shadow model: 71  epoch: 103  loss= 0.0900789201259613\n",
            "shadow model: 71  epoch: 104  loss= 0.05553264543414116\n",
            "shadow model: 71  epoch: 105  loss= 0.10884354263544083\n",
            "shadow model: 71  epoch: 106  loss= 0.13816432654857635\n",
            "shadow model: 71  epoch: 107  loss= 0.09400693327188492\n",
            "shadow model: 71  epoch: 108  loss= 0.1560489684343338\n",
            "shadow model: 71  epoch: 109  loss= 0.11655711382627487\n",
            "shadow model: 71  epoch: 110  loss= 0.0381481796503067\n",
            "shadow model: 71  epoch: 111  loss= 0.0807395651936531\n",
            "shadow model: 71  epoch: 112  loss= 0.1930772066116333\n",
            "shadow model: 71  epoch: 113  loss= 0.12022522836923599\n",
            "shadow model: 71  epoch: 114  loss= 0.04916863515973091\n",
            "shadow model: 71  epoch: 115  loss= 0.15297995507717133\n",
            "shadow model: 71  epoch: 116  loss= 0.14741235971450806\n",
            "shadow model: 71  epoch: 117  loss= 0.0784115344285965\n",
            "shadow model: 71  epoch: 118  loss= 0.13562753796577454\n",
            "shadow model: 71  epoch: 119  loss= 0.10959815979003906\n",
            "shadow model: 71  epoch: 120  loss= 0.133803591132164\n",
            "shadow model: 71  epoch: 121  loss= 0.0875406339764595\n",
            "shadow model: 71  epoch: 122  loss= 0.07062471657991409\n",
            "shadow model: 71  epoch: 123  loss= 0.104726642370224\n",
            "shadow model: 71  epoch: 124  loss= 0.05097116902470589\n",
            "shadow model: 71  epoch: 125  loss= 0.04460563138127327\n",
            "shadow model: 71  epoch: 126  loss= 0.06304699927568436\n",
            "shadow model: 71  epoch: 127  loss= 0.039954036474227905\n",
            "shadow model: 71  epoch: 128  loss= 0.10717906802892685\n",
            "shadow model: 71  epoch: 129  loss= 0.1565176546573639\n",
            "shadow model: 71  epoch: 130  loss= 0.141052708029747\n",
            "shadow model: 71  epoch: 131  loss= 0.09119760990142822\n",
            "shadow model: 71  epoch: 132  loss= 0.05267536640167236\n",
            "shadow model: 71  epoch: 133  loss= 0.15822626650333405\n",
            "shadow model: 71  epoch: 134  loss= 0.15717515349388123\n",
            "shadow model: 71  epoch: 135  loss= 0.03948067128658295\n",
            "shadow model: 71  epoch: 136  loss= 0.030765919014811516\n",
            "shadow model: 71  epoch: 137  loss= 0.04548371210694313\n",
            "shadow model: 71  epoch: 138  loss= 0.0786803662776947\n",
            "shadow model: 71  epoch: 139  loss= 0.07884775847196579\n",
            "shadow model: 71  epoch: 140  loss= 0.059077125042676926\n",
            "shadow model: 71  epoch: 141  loss= 0.06816578656435013\n",
            "shadow model: 71  epoch: 142  loss= 0.0998695120215416\n",
            "shadow model: 71  epoch: 143  loss= 0.0540020577609539\n",
            "shadow model: 71  epoch: 144  loss= 0.1227780282497406\n",
            "shadow model: 71  epoch: 145  loss= 0.17091470956802368\n",
            "shadow model: 71  epoch: 146  loss= 0.0733819529414177\n",
            "shadow model: 71  epoch: 147  loss= 0.035364456474781036\n",
            "shadow model: 71  epoch: 148  loss= 0.07413921505212784\n",
            "shadow model: 71  epoch: 149  loss= 0.13922756910324097\n",
            "\n",
            "shadow model: 72  epoch: 0  loss= 2.3332159519195557\n",
            "shadow model: 72  epoch: 1  loss= 2.254873514175415\n",
            "shadow model: 72  epoch: 2  loss= 2.207218885421753\n",
            "shadow model: 72  epoch: 3  loss= 2.144580364227295\n",
            "shadow model: 72  epoch: 4  loss= 2.0182878971099854\n",
            "shadow model: 72  epoch: 5  loss= 2.0987300872802734\n",
            "shadow model: 72  epoch: 6  loss= 1.9618383646011353\n",
            "shadow model: 72  epoch: 7  loss= 1.9155170917510986\n",
            "shadow model: 72  epoch: 8  loss= 1.8038158416748047\n",
            "shadow model: 72  epoch: 9  loss= 1.7087267637252808\n",
            "shadow model: 72  epoch: 10  loss= 1.727901816368103\n",
            "shadow model: 72  epoch: 11  loss= 1.7197849750518799\n",
            "shadow model: 72  epoch: 12  loss= 1.7521051168441772\n",
            "shadow model: 72  epoch: 13  loss= 1.6959728002548218\n",
            "shadow model: 72  epoch: 14  loss= 1.4410536289215088\n",
            "shadow model: 72  epoch: 15  loss= 1.3373477458953857\n",
            "shadow model: 72  epoch: 16  loss= 1.2919113636016846\n",
            "shadow model: 72  epoch: 17  loss= 1.215470314025879\n",
            "shadow model: 72  epoch: 18  loss= 1.1781083345413208\n",
            "shadow model: 72  epoch: 19  loss= 1.2603285312652588\n",
            "shadow model: 72  epoch: 20  loss= 1.0298759937286377\n",
            "shadow model: 72  epoch: 21  loss= 1.004960298538208\n",
            "shadow model: 72  epoch: 22  loss= 1.0203253030776978\n",
            "shadow model: 72  epoch: 23  loss= 1.1213864088058472\n",
            "shadow model: 72  epoch: 24  loss= 0.9819259643554688\n",
            "shadow model: 72  epoch: 25  loss= 0.8645474314689636\n",
            "shadow model: 72  epoch: 26  loss= 0.7739771008491516\n",
            "shadow model: 72  epoch: 27  loss= 0.7928060293197632\n",
            "shadow model: 72  epoch: 28  loss= 0.8310039043426514\n",
            "shadow model: 72  epoch: 29  loss= 0.8478142619132996\n",
            "shadow model: 72  epoch: 30  loss= 0.8567958474159241\n",
            "shadow model: 72  epoch: 31  loss= 0.7603041529655457\n",
            "shadow model: 72  epoch: 32  loss= 0.6800131797790527\n",
            "shadow model: 72  epoch: 33  loss= 0.7010551691055298\n",
            "shadow model: 72  epoch: 34  loss= 0.49697771668434143\n",
            "shadow model: 72  epoch: 35  loss= 0.5057404637336731\n",
            "shadow model: 72  epoch: 36  loss= 0.3938893973827362\n",
            "shadow model: 72  epoch: 37  loss= 0.3977978825569153\n",
            "shadow model: 72  epoch: 38  loss= 0.427339106798172\n",
            "shadow model: 72  epoch: 39  loss= 0.5208501219749451\n",
            "shadow model: 72  epoch: 40  loss= 0.4611074924468994\n",
            "shadow model: 72  epoch: 41  loss= 0.46212485432624817\n",
            "shadow model: 72  epoch: 42  loss= 0.5077673196792603\n",
            "shadow model: 72  epoch: 43  loss= 0.44085073471069336\n",
            "shadow model: 72  epoch: 44  loss= 0.37570080161094666\n",
            "shadow model: 72  epoch: 45  loss= 0.357164591550827\n",
            "shadow model: 72  epoch: 46  loss= 0.37672504782676697\n",
            "shadow model: 72  epoch: 47  loss= 0.30531999468803406\n",
            "shadow model: 72  epoch: 48  loss= 0.38664567470550537\n",
            "shadow model: 72  epoch: 49  loss= 0.260066956281662\n",
            "shadow model: 72  epoch: 50  loss= 0.3566305637359619\n",
            "shadow model: 72  epoch: 51  loss= 0.36897554993629456\n",
            "shadow model: 72  epoch: 52  loss= 0.27385759353637695\n",
            "shadow model: 72  epoch: 53  loss= 0.34394243359565735\n",
            "shadow model: 72  epoch: 54  loss= 0.1135338693857193\n",
            "shadow model: 72  epoch: 55  loss= 0.27528631687164307\n",
            "shadow model: 72  epoch: 56  loss= 0.2668919563293457\n",
            "shadow model: 72  epoch: 57  loss= 0.22548648715019226\n",
            "shadow model: 72  epoch: 58  loss= 0.1930409073829651\n",
            "shadow model: 72  epoch: 59  loss= 0.1921023279428482\n",
            "shadow model: 72  epoch: 60  loss= 0.22224895656108856\n",
            "shadow model: 72  epoch: 61  loss= 0.28805088996887207\n",
            "shadow model: 72  epoch: 62  loss= 0.23785854876041412\n",
            "shadow model: 72  epoch: 63  loss= 0.17415426671504974\n",
            "shadow model: 72  epoch: 64  loss= 0.16565744578838348\n",
            "shadow model: 72  epoch: 65  loss= 0.368238240480423\n",
            "shadow model: 72  epoch: 66  loss= 0.24790698289871216\n",
            "shadow model: 72  epoch: 67  loss= 0.10699684172868729\n",
            "shadow model: 72  epoch: 68  loss= 0.14640110731124878\n",
            "shadow model: 72  epoch: 69  loss= 0.18939770758152008\n",
            "shadow model: 72  epoch: 70  loss= 0.11418022960424423\n",
            "shadow model: 72  epoch: 71  loss= 0.1541931927204132\n",
            "shadow model: 72  epoch: 72  loss= 0.1525159329175949\n",
            "shadow model: 72  epoch: 73  loss= 0.136287659406662\n",
            "shadow model: 72  epoch: 74  loss= 0.21508046984672546\n",
            "shadow model: 72  epoch: 75  loss= 0.05260642617940903\n",
            "shadow model: 72  epoch: 76  loss= 0.1077871024608612\n",
            "shadow model: 72  epoch: 77  loss= 0.14558394253253937\n",
            "shadow model: 72  epoch: 78  loss= 0.17020590603351593\n",
            "shadow model: 72  epoch: 79  loss= 0.23052121698856354\n",
            "shadow model: 72  epoch: 80  loss= 0.11411383748054504\n",
            "shadow model: 72  epoch: 81  loss= 0.10065269470214844\n",
            "shadow model: 72  epoch: 82  loss= 0.1236739456653595\n",
            "shadow model: 72  epoch: 83  loss= 0.07956551015377045\n",
            "shadow model: 72  epoch: 84  loss= 0.14509135484695435\n",
            "shadow model: 72  epoch: 85  loss= 0.14817675948143005\n",
            "shadow model: 72  epoch: 86  loss= 0.06673894822597504\n",
            "shadow model: 72  epoch: 87  loss= 0.0559319332242012\n",
            "shadow model: 72  epoch: 88  loss= 0.14969345927238464\n",
            "shadow model: 72  epoch: 89  loss= 0.14478281140327454\n",
            "shadow model: 72  epoch: 90  loss= 0.10691690444946289\n",
            "shadow model: 72  epoch: 91  loss= 0.1292266845703125\n",
            "shadow model: 72  epoch: 92  loss= 0.11622418463230133\n",
            "shadow model: 72  epoch: 93  loss= 0.05899900197982788\n",
            "shadow model: 72  epoch: 94  loss= 0.07911935448646545\n",
            "shadow model: 72  epoch: 95  loss= 0.08607956767082214\n",
            "shadow model: 72  epoch: 96  loss= 0.07126827538013458\n",
            "shadow model: 72  epoch: 97  loss= 0.12691180408000946\n",
            "shadow model: 72  epoch: 98  loss= 0.14328841865062714\n",
            "shadow model: 72  epoch: 99  loss= 0.07300321757793427\n",
            "shadow model: 72  epoch: 100  loss= 0.16145604848861694\n",
            "shadow model: 72  epoch: 101  loss= 0.19846248626708984\n",
            "shadow model: 72  epoch: 102  loss= 0.1108473613858223\n",
            "shadow model: 72  epoch: 103  loss= 0.09062861651182175\n",
            "shadow model: 72  epoch: 104  loss= 0.16550539433956146\n",
            "shadow model: 72  epoch: 105  loss= 0.16077807545661926\n",
            "shadow model: 72  epoch: 106  loss= 0.07495736330747604\n",
            "shadow model: 72  epoch: 107  loss= 0.041830066591501236\n",
            "shadow model: 72  epoch: 108  loss= 0.14853186905384064\n",
            "shadow model: 72  epoch: 109  loss= 0.1258261799812317\n",
            "shadow model: 72  epoch: 110  loss= 0.16626699268817902\n",
            "shadow model: 72  epoch: 111  loss= 0.06701633334159851\n",
            "shadow model: 72  epoch: 112  loss= 0.10343103855848312\n",
            "shadow model: 72  epoch: 113  loss= 0.20720157027244568\n",
            "shadow model: 72  epoch: 114  loss= 0.10580715537071228\n",
            "shadow model: 72  epoch: 115  loss= 0.16867144405841827\n",
            "shadow model: 72  epoch: 116  loss= 0.047896917909383774\n",
            "shadow model: 72  epoch: 117  loss= 0.06979118287563324\n",
            "shadow model: 72  epoch: 118  loss= 0.038281068205833435\n",
            "shadow model: 72  epoch: 119  loss= 0.12072490155696869\n",
            "shadow model: 72  epoch: 120  loss= 0.06872300803661346\n",
            "shadow model: 72  epoch: 121  loss= 0.058919284492731094\n",
            "shadow model: 72  epoch: 122  loss= 0.09870441257953644\n",
            "shadow model: 72  epoch: 123  loss= 0.02244502678513527\n",
            "shadow model: 72  epoch: 124  loss= 0.042163096368312836\n",
            "shadow model: 72  epoch: 125  loss= 0.06266094744205475\n",
            "shadow model: 72  epoch: 126  loss= 0.15561212599277496\n",
            "shadow model: 72  epoch: 127  loss= 0.11864306777715683\n",
            "shadow model: 72  epoch: 128  loss= 0.09240546077489853\n",
            "shadow model: 72  epoch: 129  loss= 0.11065253615379333\n",
            "shadow model: 72  epoch: 130  loss= 0.0599413625895977\n",
            "shadow model: 72  epoch: 131  loss= 0.0845692977309227\n",
            "shadow model: 72  epoch: 132  loss= 0.03415984660387039\n",
            "shadow model: 72  epoch: 133  loss= 0.21778197586536407\n",
            "shadow model: 72  epoch: 134  loss= 0.11821090430021286\n",
            "shadow model: 72  epoch: 135  loss= 0.04718540236353874\n",
            "shadow model: 72  epoch: 136  loss= 0.011223796755075455\n",
            "shadow model: 72  epoch: 137  loss= 0.05331868305802345\n",
            "shadow model: 72  epoch: 138  loss= 0.17319750785827637\n",
            "shadow model: 72  epoch: 139  loss= 0.15424847602844238\n",
            "shadow model: 72  epoch: 140  loss= 0.07785626500844955\n",
            "shadow model: 72  epoch: 141  loss= 0.09186752885580063\n",
            "shadow model: 72  epoch: 142  loss= 0.08603716641664505\n",
            "shadow model: 72  epoch: 143  loss= 0.08213519304990768\n",
            "shadow model: 72  epoch: 144  loss= 0.05526546761393547\n",
            "shadow model: 72  epoch: 145  loss= 0.0706428587436676\n",
            "shadow model: 72  epoch: 146  loss= 0.09599458426237106\n",
            "shadow model: 72  epoch: 147  loss= 0.08067798614501953\n",
            "shadow model: 72  epoch: 148  loss= 0.08330857753753662\n",
            "shadow model: 72  epoch: 149  loss= 0.059037864208221436\n",
            "\n",
            "shadow model: 73  epoch: 0  loss= 2.2833316326141357\n",
            "shadow model: 73  epoch: 1  loss= 2.2591371536254883\n",
            "shadow model: 73  epoch: 2  loss= 2.238825798034668\n",
            "shadow model: 73  epoch: 3  loss= 2.1890947818756104\n",
            "shadow model: 73  epoch: 4  loss= 2.119704484939575\n",
            "shadow model: 73  epoch: 5  loss= 1.9513142108917236\n",
            "shadow model: 73  epoch: 6  loss= 1.744461178779602\n",
            "shadow model: 73  epoch: 7  loss= 1.8477447032928467\n",
            "shadow model: 73  epoch: 8  loss= 1.6226587295532227\n",
            "shadow model: 73  epoch: 9  loss= 1.7987818717956543\n",
            "shadow model: 73  epoch: 10  loss= 1.7774463891983032\n",
            "shadow model: 73  epoch: 11  loss= 1.5667115449905396\n",
            "shadow model: 73  epoch: 12  loss= 1.625166654586792\n",
            "shadow model: 73  epoch: 13  loss= 1.8681504726409912\n",
            "shadow model: 73  epoch: 14  loss= 1.350874900817871\n",
            "shadow model: 73  epoch: 15  loss= 1.3835687637329102\n",
            "shadow model: 73  epoch: 16  loss= 1.3539763689041138\n",
            "shadow model: 73  epoch: 17  loss= 1.2832565307617188\n",
            "shadow model: 73  epoch: 18  loss= 1.4405471086502075\n",
            "shadow model: 73  epoch: 19  loss= 1.1403533220291138\n",
            "shadow model: 73  epoch: 20  loss= 0.9962391257286072\n",
            "shadow model: 73  epoch: 21  loss= 0.9380322694778442\n",
            "shadow model: 73  epoch: 22  loss= 0.8263545036315918\n",
            "shadow model: 73  epoch: 23  loss= 1.005540370941162\n",
            "shadow model: 73  epoch: 24  loss= 0.7047325372695923\n",
            "shadow model: 73  epoch: 25  loss= 0.6947057247161865\n",
            "shadow model: 73  epoch: 26  loss= 0.8126292824745178\n",
            "shadow model: 73  epoch: 27  loss= 0.5969767570495605\n",
            "shadow model: 73  epoch: 28  loss= 0.6051250100135803\n",
            "shadow model: 73  epoch: 29  loss= 0.5722402334213257\n",
            "shadow model: 73  epoch: 30  loss= 0.6376162171363831\n",
            "shadow model: 73  epoch: 31  loss= 0.4656764566898346\n",
            "shadow model: 73  epoch: 32  loss= 0.5544989705085754\n",
            "shadow model: 73  epoch: 33  loss= 0.47401246428489685\n",
            "shadow model: 73  epoch: 34  loss= 0.7913333177566528\n",
            "shadow model: 73  epoch: 35  loss= 0.5035671591758728\n",
            "shadow model: 73  epoch: 36  loss= 0.4348217844963074\n",
            "shadow model: 73  epoch: 37  loss= 0.4349358379840851\n",
            "shadow model: 73  epoch: 38  loss= 0.3830946385860443\n",
            "shadow model: 73  epoch: 39  loss= 0.4337722957134247\n",
            "shadow model: 73  epoch: 40  loss= 0.27867430448532104\n",
            "shadow model: 73  epoch: 41  loss= 0.29948171973228455\n",
            "shadow model: 73  epoch: 42  loss= 0.33028703927993774\n",
            "shadow model: 73  epoch: 43  loss= 0.22697898745536804\n",
            "shadow model: 73  epoch: 44  loss= 0.3491050601005554\n",
            "shadow model: 73  epoch: 45  loss= 0.26431897282600403\n",
            "shadow model: 73  epoch: 46  loss= 0.3172788918018341\n",
            "shadow model: 73  epoch: 47  loss= 0.27242523431777954\n",
            "shadow model: 73  epoch: 48  loss= 0.12559665739536285\n",
            "shadow model: 73  epoch: 49  loss= 0.21629244089126587\n",
            "shadow model: 73  epoch: 50  loss= 0.2949746549129486\n",
            "shadow model: 73  epoch: 51  loss= 0.253749817609787\n",
            "shadow model: 73  epoch: 52  loss= 0.17865395545959473\n",
            "shadow model: 73  epoch: 53  loss= 0.2117704600095749\n",
            "shadow model: 73  epoch: 54  loss= 0.1530187875032425\n",
            "shadow model: 73  epoch: 55  loss= 0.3917936682701111\n",
            "shadow model: 73  epoch: 56  loss= 0.12528271973133087\n",
            "shadow model: 73  epoch: 57  loss= 0.1640869677066803\n",
            "shadow model: 73  epoch: 58  loss= 0.14411062002182007\n",
            "shadow model: 73  epoch: 59  loss= 0.21625709533691406\n",
            "shadow model: 73  epoch: 60  loss= 0.19161716103553772\n",
            "shadow model: 73  epoch: 61  loss= 0.29966941475868225\n",
            "shadow model: 73  epoch: 62  loss= 0.15069667994976044\n",
            "shadow model: 73  epoch: 63  loss= 0.15220856666564941\n",
            "shadow model: 73  epoch: 64  loss= 0.14482417702674866\n",
            "shadow model: 73  epoch: 65  loss= 0.11847493797540665\n",
            "shadow model: 73  epoch: 66  loss= 0.1020730584859848\n",
            "shadow model: 73  epoch: 67  loss= 0.1468084454536438\n",
            "shadow model: 73  epoch: 68  loss= 0.1440531611442566\n",
            "shadow model: 73  epoch: 69  loss= 0.18791227042675018\n",
            "shadow model: 73  epoch: 70  loss= 0.14891371130943298\n",
            "shadow model: 73  epoch: 71  loss= 0.11926209926605225\n",
            "shadow model: 73  epoch: 72  loss= 0.06725481897592545\n",
            "shadow model: 73  epoch: 73  loss= 0.1940566897392273\n",
            "shadow model: 73  epoch: 74  loss= 0.07606223225593567\n",
            "shadow model: 73  epoch: 75  loss= 0.07430577278137207\n",
            "shadow model: 73  epoch: 76  loss= 0.0973871499300003\n",
            "shadow model: 73  epoch: 77  loss= 0.12308967858552933\n",
            "shadow model: 73  epoch: 78  loss= 0.06909018754959106\n",
            "shadow model: 73  epoch: 79  loss= 0.12198428064584732\n",
            "shadow model: 73  epoch: 80  loss= 0.06921478360891342\n",
            "shadow model: 73  epoch: 81  loss= 0.06621576100587845\n",
            "shadow model: 73  epoch: 82  loss= 0.10830292105674744\n",
            "shadow model: 73  epoch: 83  loss= 0.05989021435379982\n",
            "shadow model: 73  epoch: 84  loss= 0.174395352602005\n",
            "shadow model: 73  epoch: 85  loss= 0.0980960801243782\n",
            "shadow model: 73  epoch: 86  loss= 0.12659037113189697\n",
            "shadow model: 73  epoch: 87  loss= 0.08647890388965607\n",
            "shadow model: 73  epoch: 88  loss= 0.128265842795372\n",
            "shadow model: 73  epoch: 89  loss= 0.08420733362436295\n",
            "shadow model: 73  epoch: 90  loss= 0.06046522408723831\n",
            "shadow model: 73  epoch: 91  loss= 0.059400562196969986\n",
            "shadow model: 73  epoch: 92  loss= 0.0681719183921814\n",
            "shadow model: 73  epoch: 93  loss= 0.07953368127346039\n",
            "shadow model: 73  epoch: 94  loss= 0.07434133440256119\n",
            "shadow model: 73  epoch: 95  loss= 0.15227816998958588\n",
            "shadow model: 73  epoch: 96  loss= 0.09649067372083664\n",
            "shadow model: 73  epoch: 97  loss= 0.0831059068441391\n",
            "shadow model: 73  epoch: 98  loss= 0.10656102001667023\n",
            "shadow model: 73  epoch: 99  loss= 0.11085662245750427\n",
            "shadow model: 73  epoch: 100  loss= 0.09884469956159592\n",
            "shadow model: 73  epoch: 101  loss= 0.1208917573094368\n",
            "shadow model: 73  epoch: 102  loss= 0.020013583824038506\n",
            "shadow model: 73  epoch: 103  loss= 0.01716107316315174\n",
            "shadow model: 73  epoch: 104  loss= 0.1701015830039978\n",
            "shadow model: 73  epoch: 105  loss= 0.03948419541120529\n",
            "shadow model: 73  epoch: 106  loss= 0.06841468065977097\n",
            "shadow model: 73  epoch: 107  loss= 0.03270835429430008\n",
            "shadow model: 73  epoch: 108  loss= 0.052485689520835876\n",
            "shadow model: 73  epoch: 109  loss= 0.037699129432439804\n",
            "shadow model: 73  epoch: 110  loss= 0.12190164625644684\n",
            "shadow model: 73  epoch: 111  loss= 0.05357140675187111\n",
            "shadow model: 73  epoch: 112  loss= 0.060022588819265366\n",
            "shadow model: 73  epoch: 113  loss= 0.05496115982532501\n",
            "shadow model: 73  epoch: 114  loss= 0.12260501831769943\n",
            "shadow model: 73  epoch: 115  loss= 0.06244327127933502\n",
            "shadow model: 73  epoch: 116  loss= 0.05964110791683197\n",
            "shadow model: 73  epoch: 117  loss= 0.0828729048371315\n",
            "shadow model: 73  epoch: 118  loss= 0.0878928080201149\n",
            "shadow model: 73  epoch: 119  loss= 0.05277251824736595\n",
            "shadow model: 73  epoch: 120  loss= 0.06012963131070137\n",
            "shadow model: 73  epoch: 121  loss= 0.08276886492967606\n",
            "shadow model: 73  epoch: 122  loss= 0.026691008359193802\n",
            "shadow model: 73  epoch: 123  loss= 0.11989453434944153\n",
            "shadow model: 73  epoch: 124  loss= 0.03241199254989624\n",
            "shadow model: 73  epoch: 125  loss= 0.06100795045495033\n",
            "shadow model: 73  epoch: 126  loss= 0.028759365901350975\n",
            "shadow model: 73  epoch: 127  loss= 0.02170080877840519\n",
            "shadow model: 73  epoch: 128  loss= 0.022554343566298485\n",
            "shadow model: 73  epoch: 129  loss= 0.15191107988357544\n",
            "shadow model: 73  epoch: 130  loss= 0.05600343272089958\n",
            "shadow model: 73  epoch: 131  loss= 0.1713510900735855\n",
            "shadow model: 73  epoch: 132  loss= 0.0379401259124279\n",
            "shadow model: 73  epoch: 133  loss= 0.07930613309144974\n",
            "shadow model: 73  epoch: 134  loss= 0.15874777734279633\n",
            "shadow model: 73  epoch: 135  loss= 0.05518870800733566\n",
            "shadow model: 73  epoch: 136  loss= 0.07519223541021347\n",
            "shadow model: 73  epoch: 137  loss= 0.0620749294757843\n",
            "shadow model: 73  epoch: 138  loss= 0.13536620140075684\n",
            "shadow model: 73  epoch: 139  loss= 0.06486305594444275\n",
            "shadow model: 73  epoch: 140  loss= 0.11031579226255417\n",
            "shadow model: 73  epoch: 141  loss= 0.10907766968011856\n",
            "shadow model: 73  epoch: 142  loss= 0.10966642946004868\n",
            "shadow model: 73  epoch: 143  loss= 0.07947830855846405\n",
            "shadow model: 73  epoch: 144  loss= 0.03026624210178852\n",
            "shadow model: 73  epoch: 145  loss= 0.05930216237902641\n",
            "shadow model: 73  epoch: 146  loss= 0.06975557655096054\n",
            "shadow model: 73  epoch: 147  loss= 0.05131804570555687\n",
            "shadow model: 73  epoch: 148  loss= 0.0861753523349762\n",
            "shadow model: 73  epoch: 149  loss= 0.01827031560242176\n",
            "\n",
            "shadow model: 74  epoch: 0  loss= 2.3074474334716797\n",
            "shadow model: 74  epoch: 1  loss= 2.2706708908081055\n",
            "shadow model: 74  epoch: 2  loss= 2.1805763244628906\n",
            "shadow model: 74  epoch: 3  loss= 2.050283908843994\n",
            "shadow model: 74  epoch: 4  loss= 2.0339083671569824\n",
            "shadow model: 74  epoch: 5  loss= 1.8898022174835205\n",
            "shadow model: 74  epoch: 6  loss= 1.8730324506759644\n",
            "shadow model: 74  epoch: 7  loss= 1.8958324193954468\n",
            "shadow model: 74  epoch: 8  loss= 1.7371158599853516\n",
            "shadow model: 74  epoch: 9  loss= 1.605372667312622\n",
            "shadow model: 74  epoch: 10  loss= 1.8039368391036987\n",
            "shadow model: 74  epoch: 11  loss= 1.4443447589874268\n",
            "shadow model: 74  epoch: 12  loss= 1.564491868019104\n",
            "shadow model: 74  epoch: 13  loss= 1.6037219762802124\n",
            "shadow model: 74  epoch: 14  loss= 1.2216582298278809\n",
            "shadow model: 74  epoch: 15  loss= 1.1131727695465088\n",
            "shadow model: 74  epoch: 16  loss= 1.3055393695831299\n",
            "shadow model: 74  epoch: 17  loss= 1.12644624710083\n",
            "shadow model: 74  epoch: 18  loss= 1.0678040981292725\n",
            "shadow model: 74  epoch: 19  loss= 0.9049664735794067\n",
            "shadow model: 74  epoch: 20  loss= 0.8657397627830505\n",
            "shadow model: 74  epoch: 21  loss= 0.8623812198638916\n",
            "shadow model: 74  epoch: 22  loss= 0.9363515377044678\n",
            "shadow model: 74  epoch: 23  loss= 0.8201687335968018\n",
            "shadow model: 74  epoch: 24  loss= 0.6084677577018738\n",
            "shadow model: 74  epoch: 25  loss= 0.6214827299118042\n",
            "shadow model: 74  epoch: 26  loss= 0.4737008213996887\n",
            "shadow model: 74  epoch: 27  loss= 0.9214625954627991\n",
            "shadow model: 74  epoch: 28  loss= 0.5526117086410522\n",
            "shadow model: 74  epoch: 29  loss= 0.521628737449646\n",
            "shadow model: 74  epoch: 30  loss= 0.3777283728122711\n",
            "shadow model: 74  epoch: 31  loss= 0.39217355847358704\n",
            "shadow model: 74  epoch: 32  loss= 0.3595271706581116\n",
            "shadow model: 74  epoch: 33  loss= 0.4303043782711029\n",
            "shadow model: 74  epoch: 34  loss= 0.3662205636501312\n",
            "shadow model: 74  epoch: 35  loss= 0.4421495795249939\n",
            "shadow model: 74  epoch: 36  loss= 0.3931489586830139\n",
            "shadow model: 74  epoch: 37  loss= 0.31783023476600647\n",
            "shadow model: 74  epoch: 38  loss= 0.3227997124195099\n",
            "shadow model: 74  epoch: 39  loss= 0.22696825861930847\n",
            "shadow model: 74  epoch: 40  loss= 0.17467942833900452\n",
            "shadow model: 74  epoch: 41  loss= 0.3913843333721161\n",
            "shadow model: 74  epoch: 42  loss= 0.4395900070667267\n",
            "shadow model: 74  epoch: 43  loss= 0.2519957423210144\n",
            "shadow model: 74  epoch: 44  loss= 0.13593080639839172\n",
            "shadow model: 74  epoch: 45  loss= 0.20071953535079956\n",
            "shadow model: 74  epoch: 46  loss= 0.4044415354728699\n",
            "shadow model: 74  epoch: 47  loss= 0.2310866117477417\n",
            "shadow model: 74  epoch: 48  loss= 0.28608977794647217\n",
            "shadow model: 74  epoch: 49  loss= 0.24483461678028107\n",
            "shadow model: 74  epoch: 50  loss= 0.19951124489307404\n",
            "shadow model: 74  epoch: 51  loss= 0.21341067552566528\n",
            "shadow model: 74  epoch: 52  loss= 0.31834152340888977\n",
            "shadow model: 74  epoch: 53  loss= 0.23339667916297913\n",
            "shadow model: 74  epoch: 54  loss= 0.18270015716552734\n",
            "shadow model: 74  epoch: 55  loss= 0.2764679193496704\n",
            "shadow model: 74  epoch: 56  loss= 0.19771958887577057\n",
            "shadow model: 74  epoch: 57  loss= 0.1496535837650299\n",
            "shadow model: 74  epoch: 58  loss= 0.18395644426345825\n",
            "shadow model: 74  epoch: 59  loss= 0.09487906098365784\n",
            "shadow model: 74  epoch: 60  loss= 0.1627793312072754\n",
            "shadow model: 74  epoch: 61  loss= 0.1407676488161087\n",
            "shadow model: 74  epoch: 62  loss= 0.08014193922281265\n",
            "shadow model: 74  epoch: 63  loss= 0.11085887998342514\n",
            "shadow model: 74  epoch: 64  loss= 0.11360076069831848\n",
            "shadow model: 74  epoch: 65  loss= 0.15572670102119446\n",
            "shadow model: 74  epoch: 66  loss= 0.09146919846534729\n",
            "shadow model: 74  epoch: 67  loss= 0.12079727649688721\n",
            "shadow model: 74  epoch: 68  loss= 0.08236107230186462\n",
            "shadow model: 74  epoch: 69  loss= 0.13356783986091614\n",
            "shadow model: 74  epoch: 70  loss= 0.09078387171030045\n",
            "shadow model: 74  epoch: 71  loss= 0.11062824726104736\n",
            "shadow model: 74  epoch: 72  loss= 0.07942330837249756\n",
            "shadow model: 74  epoch: 73  loss= 0.1540561020374298\n",
            "shadow model: 74  epoch: 74  loss= 0.07357054203748703\n",
            "shadow model: 74  epoch: 75  loss= 0.09642396867275238\n",
            "shadow model: 74  epoch: 76  loss= 0.10875626653432846\n",
            "shadow model: 74  epoch: 77  loss= 0.06186627224087715\n",
            "shadow model: 74  epoch: 78  loss= 0.09298434108495712\n",
            "shadow model: 74  epoch: 79  loss= 0.20701460540294647\n",
            "shadow model: 74  epoch: 80  loss= 0.08370272815227509\n",
            "shadow model: 74  epoch: 81  loss= 0.09673396497964859\n",
            "shadow model: 74  epoch: 82  loss= 0.11402305960655212\n",
            "shadow model: 74  epoch: 83  loss= 0.08501725643873215\n",
            "shadow model: 74  epoch: 84  loss= 0.12773540616035461\n",
            "shadow model: 74  epoch: 85  loss= 0.13697507977485657\n",
            "shadow model: 74  epoch: 86  loss= 0.14562030136585236\n",
            "shadow model: 74  epoch: 87  loss= 0.028627991676330566\n",
            "shadow model: 74  epoch: 88  loss= 0.12949803471565247\n",
            "shadow model: 74  epoch: 89  loss= 0.03151426091790199\n",
            "shadow model: 74  epoch: 90  loss= 0.07892750948667526\n",
            "shadow model: 74  epoch: 91  loss= 0.055063385516405106\n",
            "shadow model: 74  epoch: 92  loss= 0.11870313435792923\n",
            "shadow model: 74  epoch: 93  loss= 0.09287059307098389\n",
            "shadow model: 74  epoch: 94  loss= 0.07709787040948868\n",
            "shadow model: 74  epoch: 95  loss= 0.10349451005458832\n",
            "shadow model: 74  epoch: 96  loss= 0.06661902368068695\n",
            "shadow model: 74  epoch: 97  loss= 0.04121775925159454\n",
            "shadow model: 74  epoch: 98  loss= 0.08038166910409927\n",
            "shadow model: 74  epoch: 99  loss= 0.10462457686662674\n",
            "shadow model: 74  epoch: 100  loss= 0.03182372823357582\n",
            "shadow model: 74  epoch: 101  loss= 0.08030972629785538\n",
            "shadow model: 74  epoch: 102  loss= 0.04613669961690903\n",
            "shadow model: 74  epoch: 103  loss= 0.11488877236843109\n",
            "shadow model: 74  epoch: 104  loss= 0.09162328392267227\n",
            "shadow model: 74  epoch: 105  loss= 0.054138462990522385\n",
            "shadow model: 74  epoch: 106  loss= 0.06926638633012772\n",
            "shadow model: 74  epoch: 107  loss= 0.12811075150966644\n",
            "shadow model: 74  epoch: 108  loss= 0.0605294443666935\n",
            "shadow model: 74  epoch: 109  loss= 0.12874001264572144\n",
            "shadow model: 74  epoch: 110  loss= 0.08304405212402344\n",
            "shadow model: 74  epoch: 111  loss= 0.13964681327342987\n",
            "shadow model: 74  epoch: 112  loss= 0.009400269947946072\n",
            "shadow model: 74  epoch: 113  loss= 0.045074015855789185\n",
            "shadow model: 74  epoch: 114  loss= 0.09892471134662628\n",
            "shadow model: 74  epoch: 115  loss= 0.036356255412101746\n",
            "shadow model: 74  epoch: 116  loss= 0.048412028700113297\n",
            "shadow model: 74  epoch: 117  loss= 0.0441524013876915\n",
            "shadow model: 74  epoch: 118  loss= 0.0616636723279953\n",
            "shadow model: 74  epoch: 119  loss= 0.06378223747015\n",
            "shadow model: 74  epoch: 120  loss= 0.08462735265493393\n",
            "shadow model: 74  epoch: 121  loss= 0.08961324393749237\n",
            "shadow model: 74  epoch: 122  loss= 0.08526871353387833\n",
            "shadow model: 74  epoch: 123  loss= 0.019658297300338745\n",
            "shadow model: 74  epoch: 124  loss= 0.11231470108032227\n",
            "shadow model: 74  epoch: 125  loss= 0.10664215683937073\n",
            "shadow model: 74  epoch: 126  loss= 0.06136728450655937\n",
            "shadow model: 74  epoch: 127  loss= 0.030200721696019173\n",
            "shadow model: 74  epoch: 128  loss= 0.07482106983661652\n",
            "shadow model: 74  epoch: 129  loss= 0.05739844962954521\n",
            "shadow model: 74  epoch: 130  loss= 0.05723294988274574\n",
            "shadow model: 74  epoch: 131  loss= 0.019167669117450714\n",
            "shadow model: 74  epoch: 132  loss= 0.051913242787122726\n",
            "shadow model: 74  epoch: 133  loss= 0.05295715481042862\n",
            "shadow model: 74  epoch: 134  loss= 0.06738699972629547\n",
            "shadow model: 74  epoch: 135  loss= 0.024235481396317482\n",
            "shadow model: 74  epoch: 136  loss= 0.060346368700265884\n",
            "shadow model: 74  epoch: 137  loss= 0.12441389262676239\n",
            "shadow model: 74  epoch: 138  loss= 0.07293839007616043\n",
            "shadow model: 74  epoch: 139  loss= 0.08910337090492249\n",
            "shadow model: 74  epoch: 140  loss= 0.05975509062409401\n",
            "shadow model: 74  epoch: 141  loss= 0.07191802561283112\n",
            "shadow model: 74  epoch: 142  loss= 0.03963444381952286\n",
            "shadow model: 74  epoch: 143  loss= 0.10424722731113434\n",
            "shadow model: 74  epoch: 144  loss= 0.038251034915447235\n",
            "shadow model: 74  epoch: 145  loss= 0.08315621316432953\n",
            "shadow model: 74  epoch: 146  loss= 0.03317296877503395\n",
            "shadow model: 74  epoch: 147  loss= 0.09948175400495529\n",
            "shadow model: 74  epoch: 148  loss= 0.04132574424147606\n",
            "shadow model: 74  epoch: 149  loss= 0.06221083924174309\n",
            "\n",
            "shadow model: 75  epoch: 0  loss= 2.338629722595215\n",
            "shadow model: 75  epoch: 1  loss= 2.2544991970062256\n",
            "shadow model: 75  epoch: 2  loss= 2.233147144317627\n",
            "shadow model: 75  epoch: 3  loss= 2.156898260116577\n",
            "shadow model: 75  epoch: 4  loss= 2.0283493995666504\n",
            "shadow model: 75  epoch: 5  loss= 1.989408016204834\n",
            "shadow model: 75  epoch: 6  loss= 1.889419674873352\n",
            "shadow model: 75  epoch: 7  loss= 2.1141278743743896\n",
            "shadow model: 75  epoch: 8  loss= 1.7682361602783203\n",
            "shadow model: 75  epoch: 9  loss= 1.6158664226531982\n",
            "shadow model: 75  epoch: 10  loss= 1.6151723861694336\n",
            "shadow model: 75  epoch: 11  loss= 1.6465134620666504\n",
            "shadow model: 75  epoch: 12  loss= 1.6966651678085327\n",
            "shadow model: 75  epoch: 13  loss= 1.5280464887619019\n",
            "shadow model: 75  epoch: 14  loss= 1.6851928234100342\n",
            "shadow model: 75  epoch: 15  loss= 1.2152600288391113\n",
            "shadow model: 75  epoch: 16  loss= 1.4518924951553345\n",
            "shadow model: 75  epoch: 17  loss= 1.127638816833496\n",
            "shadow model: 75  epoch: 18  loss= 1.190063714981079\n",
            "shadow model: 75  epoch: 19  loss= 0.9525564312934875\n",
            "shadow model: 75  epoch: 20  loss= 0.8521789312362671\n",
            "shadow model: 75  epoch: 21  loss= 1.0611462593078613\n",
            "shadow model: 75  epoch: 22  loss= 0.8013216257095337\n",
            "shadow model: 75  epoch: 23  loss= 1.016876220703125\n",
            "shadow model: 75  epoch: 24  loss= 0.6795845627784729\n",
            "shadow model: 75  epoch: 25  loss= 0.6053342819213867\n",
            "shadow model: 75  epoch: 26  loss= 0.6764615774154663\n",
            "shadow model: 75  epoch: 27  loss= 0.7185509204864502\n",
            "shadow model: 75  epoch: 28  loss= 0.7371150851249695\n",
            "shadow model: 75  epoch: 29  loss= 0.5532756447792053\n",
            "shadow model: 75  epoch: 30  loss= 0.4075131416320801\n",
            "shadow model: 75  epoch: 31  loss= 0.48096540570259094\n",
            "shadow model: 75  epoch: 32  loss= 0.5230353474617004\n",
            "shadow model: 75  epoch: 33  loss= 0.32912495732307434\n",
            "shadow model: 75  epoch: 34  loss= 0.40699800848960876\n",
            "shadow model: 75  epoch: 35  loss= 0.26866501569747925\n",
            "shadow model: 75  epoch: 36  loss= 0.45793578028678894\n",
            "shadow model: 75  epoch: 37  loss= 0.4028412103652954\n",
            "shadow model: 75  epoch: 38  loss= 0.4220430552959442\n",
            "shadow model: 75  epoch: 39  loss= 0.4555363059043884\n",
            "shadow model: 75  epoch: 40  loss= 0.29332321882247925\n",
            "shadow model: 75  epoch: 41  loss= 0.23485936224460602\n",
            "shadow model: 75  epoch: 42  loss= 0.3158467710018158\n",
            "shadow model: 75  epoch: 43  loss= 0.2734369933605194\n",
            "shadow model: 75  epoch: 44  loss= 0.21831104159355164\n",
            "shadow model: 75  epoch: 45  loss= 0.2729356288909912\n",
            "shadow model: 75  epoch: 46  loss= 0.16062578558921814\n",
            "shadow model: 75  epoch: 47  loss= 0.2670857310295105\n",
            "shadow model: 75  epoch: 48  loss= 0.13858261704444885\n",
            "shadow model: 75  epoch: 49  loss= 0.14094491302967072\n",
            "shadow model: 75  epoch: 50  loss= 0.15333443880081177\n",
            "shadow model: 75  epoch: 51  loss= 0.1528375893831253\n",
            "shadow model: 75  epoch: 52  loss= 0.15092091262340546\n",
            "shadow model: 75  epoch: 53  loss= 0.2986575663089752\n",
            "shadow model: 75  epoch: 54  loss= 0.0874374657869339\n",
            "shadow model: 75  epoch: 55  loss= 0.08853835612535477\n",
            "shadow model: 75  epoch: 56  loss= 0.24724797904491425\n",
            "shadow model: 75  epoch: 57  loss= 0.135586217045784\n",
            "shadow model: 75  epoch: 58  loss= 0.25368818640708923\n",
            "shadow model: 75  epoch: 59  loss= 0.12539179623126984\n",
            "shadow model: 75  epoch: 60  loss= 0.14149145781993866\n",
            "shadow model: 75  epoch: 61  loss= 0.16409932076931\n",
            "shadow model: 75  epoch: 62  loss= 0.11040549725294113\n",
            "shadow model: 75  epoch: 63  loss= 0.20599186420440674\n",
            "shadow model: 75  epoch: 64  loss= 0.21885834634304047\n",
            "shadow model: 75  epoch: 65  loss= 0.21894803643226624\n",
            "shadow model: 75  epoch: 66  loss= 0.06863672286272049\n",
            "shadow model: 75  epoch: 67  loss= 0.05281517282128334\n",
            "shadow model: 75  epoch: 68  loss= 0.13200423121452332\n",
            "shadow model: 75  epoch: 69  loss= 0.11550227552652359\n",
            "shadow model: 75  epoch: 70  loss= 0.09612619131803513\n",
            "shadow model: 75  epoch: 71  loss= 0.23090632259845734\n",
            "shadow model: 75  epoch: 72  loss= 0.14318865537643433\n",
            "shadow model: 75  epoch: 73  loss= 0.057647231966257095\n",
            "shadow model: 75  epoch: 74  loss= 0.18082472681999207\n",
            "shadow model: 75  epoch: 75  loss= 0.037787243723869324\n",
            "shadow model: 75  epoch: 76  loss= 0.12490766495466232\n",
            "shadow model: 75  epoch: 77  loss= 0.08517253398895264\n",
            "shadow model: 75  epoch: 78  loss= 0.11596222966909409\n",
            "shadow model: 75  epoch: 79  loss= 0.19007998704910278\n",
            "shadow model: 75  epoch: 80  loss= 0.07008489966392517\n",
            "shadow model: 75  epoch: 81  loss= 0.055658008903265\n",
            "shadow model: 75  epoch: 82  loss= 0.13111740350723267\n",
            "shadow model: 75  epoch: 83  loss= 0.1799137443304062\n",
            "shadow model: 75  epoch: 84  loss= 0.09525129944086075\n",
            "shadow model: 75  epoch: 85  loss= 0.09206666052341461\n",
            "shadow model: 75  epoch: 86  loss= 0.06362144649028778\n",
            "shadow model: 75  epoch: 87  loss= 0.07373998314142227\n",
            "shadow model: 75  epoch: 88  loss= 0.11678674072027206\n",
            "shadow model: 75  epoch: 89  loss= 0.03491700813174248\n",
            "shadow model: 75  epoch: 90  loss= 0.04185344651341438\n",
            "shadow model: 75  epoch: 91  loss= 0.09529224038124084\n",
            "shadow model: 75  epoch: 92  loss= 0.07909051328897476\n",
            "shadow model: 75  epoch: 93  loss= 0.09043034166097641\n",
            "shadow model: 75  epoch: 94  loss= 0.05041937157511711\n",
            "shadow model: 75  epoch: 95  loss= 0.04596749320626259\n",
            "shadow model: 75  epoch: 96  loss= 0.06298760324716568\n",
            "shadow model: 75  epoch: 97  loss= 0.0783170759677887\n",
            "shadow model: 75  epoch: 98  loss= 0.07002851366996765\n",
            "shadow model: 75  epoch: 99  loss= 0.08329028636217117\n",
            "shadow model: 75  epoch: 100  loss= 0.10536426305770874\n",
            "shadow model: 75  epoch: 101  loss= 0.10195602476596832\n",
            "shadow model: 75  epoch: 102  loss= 0.0724669024348259\n",
            "shadow model: 75  epoch: 103  loss= 0.04241656884551048\n",
            "shadow model: 75  epoch: 104  loss= 0.1263672560453415\n",
            "shadow model: 75  epoch: 105  loss= 0.10280853509902954\n",
            "shadow model: 75  epoch: 106  loss= 0.07667452096939087\n",
            "shadow model: 75  epoch: 107  loss= 0.050088442862033844\n",
            "shadow model: 75  epoch: 108  loss= 0.027879752218723297\n",
            "shadow model: 75  epoch: 109  loss= 0.06312482059001923\n",
            "shadow model: 75  epoch: 110  loss= 0.09664875268936157\n",
            "shadow model: 75  epoch: 111  loss= 0.07970276474952698\n",
            "shadow model: 75  epoch: 112  loss= 0.08710522204637527\n",
            "shadow model: 75  epoch: 113  loss= 0.029258737340569496\n",
            "shadow model: 75  epoch: 114  loss= 0.0249027106910944\n",
            "shadow model: 75  epoch: 115  loss= 0.10099034756422043\n",
            "shadow model: 75  epoch: 116  loss= 0.12247733026742935\n",
            "shadow model: 75  epoch: 117  loss= 0.07175856083631516\n",
            "shadow model: 75  epoch: 118  loss= 0.03540540114045143\n",
            "shadow model: 75  epoch: 119  loss= 0.09037046134471893\n",
            "shadow model: 75  epoch: 120  loss= 0.037402935326099396\n",
            "shadow model: 75  epoch: 121  loss= 0.025755658745765686\n",
            "shadow model: 75  epoch: 122  loss= 0.13283054530620575\n",
            "shadow model: 75  epoch: 123  loss= 0.09208675473928452\n",
            "shadow model: 75  epoch: 124  loss= 0.036804575473070145\n",
            "shadow model: 75  epoch: 125  loss= 0.11183308809995651\n",
            "shadow model: 75  epoch: 126  loss= 0.06647447496652603\n",
            "shadow model: 75  epoch: 127  loss= 0.04792359098792076\n",
            "shadow model: 75  epoch: 128  loss= 0.04464590921998024\n",
            "shadow model: 75  epoch: 129  loss= 0.03752196207642555\n",
            "shadow model: 75  epoch: 130  loss= 0.11315101385116577\n",
            "shadow model: 75  epoch: 131  loss= 0.06536907702684402\n",
            "shadow model: 75  epoch: 132  loss= 0.051330458372831345\n",
            "shadow model: 75  epoch: 133  loss= 0.06871197372674942\n",
            "shadow model: 75  epoch: 134  loss= 0.026320436969399452\n",
            "shadow model: 75  epoch: 135  loss= 0.015851762145757675\n",
            "shadow model: 75  epoch: 136  loss= 0.03050241991877556\n",
            "shadow model: 75  epoch: 137  loss= 0.0445125550031662\n",
            "shadow model: 75  epoch: 138  loss= 0.04440835863351822\n",
            "shadow model: 75  epoch: 139  loss= 0.028377218171954155\n",
            "shadow model: 75  epoch: 140  loss= 0.02195044606924057\n",
            "shadow model: 75  epoch: 141  loss= 0.06860116869211197\n",
            "shadow model: 75  epoch: 142  loss= 0.01131055224686861\n",
            "shadow model: 75  epoch: 143  loss= 0.014218917116522789\n",
            "shadow model: 75  epoch: 144  loss= 0.11116262525320053\n",
            "shadow model: 75  epoch: 145  loss= 0.06069754436612129\n",
            "shadow model: 75  epoch: 146  loss= 0.1226864755153656\n",
            "shadow model: 75  epoch: 147  loss= 0.04487656429409981\n",
            "shadow model: 75  epoch: 148  loss= 0.05542381852865219\n",
            "shadow model: 75  epoch: 149  loss= 0.07126004248857498\n",
            "\n",
            "shadow model: 76  epoch: 0  loss= 2.3254101276397705\n",
            "shadow model: 76  epoch: 1  loss= 2.2981154918670654\n",
            "shadow model: 76  epoch: 2  loss= 2.2341952323913574\n",
            "shadow model: 76  epoch: 3  loss= 2.166348934173584\n",
            "shadow model: 76  epoch: 4  loss= 2.0783193111419678\n",
            "shadow model: 76  epoch: 5  loss= 2.022831678390503\n",
            "shadow model: 76  epoch: 6  loss= 2.069270133972168\n",
            "shadow model: 76  epoch: 7  loss= 2.0486748218536377\n",
            "shadow model: 76  epoch: 8  loss= 1.8804931640625\n",
            "shadow model: 76  epoch: 9  loss= 1.803261637687683\n",
            "shadow model: 76  epoch: 10  loss= 1.6342523097991943\n",
            "shadow model: 76  epoch: 11  loss= 1.4303627014160156\n",
            "shadow model: 76  epoch: 12  loss= 1.729883074760437\n",
            "shadow model: 76  epoch: 13  loss= 1.6289201974868774\n",
            "shadow model: 76  epoch: 14  loss= 1.5627665519714355\n",
            "shadow model: 76  epoch: 15  loss= 1.4924235343933105\n",
            "shadow model: 76  epoch: 16  loss= 1.4574881792068481\n",
            "shadow model: 76  epoch: 17  loss= 1.4145218133926392\n",
            "shadow model: 76  epoch: 18  loss= 1.304306149482727\n",
            "shadow model: 76  epoch: 19  loss= 1.2959834337234497\n",
            "shadow model: 76  epoch: 20  loss= 1.0711567401885986\n",
            "shadow model: 76  epoch: 21  loss= 1.2883884906768799\n",
            "shadow model: 76  epoch: 22  loss= 1.2097903490066528\n",
            "shadow model: 76  epoch: 23  loss= 1.1692492961883545\n",
            "shadow model: 76  epoch: 24  loss= 1.010401964187622\n",
            "shadow model: 76  epoch: 25  loss= 0.8996211290359497\n",
            "shadow model: 76  epoch: 26  loss= 0.729875922203064\n",
            "shadow model: 76  epoch: 27  loss= 0.6573747396469116\n",
            "shadow model: 76  epoch: 28  loss= 1.0021535158157349\n",
            "shadow model: 76  epoch: 29  loss= 0.8655560612678528\n",
            "shadow model: 76  epoch: 30  loss= 0.5450805425643921\n",
            "shadow model: 76  epoch: 31  loss= 0.5593762397766113\n",
            "shadow model: 76  epoch: 32  loss= 0.5704313516616821\n",
            "shadow model: 76  epoch: 33  loss= 0.6206932663917542\n",
            "shadow model: 76  epoch: 34  loss= 0.6202902793884277\n",
            "shadow model: 76  epoch: 35  loss= 0.46228358149528503\n",
            "shadow model: 76  epoch: 36  loss= 0.5484772324562073\n",
            "shadow model: 76  epoch: 37  loss= 0.44385653734207153\n",
            "shadow model: 76  epoch: 38  loss= 0.4488026201725006\n",
            "shadow model: 76  epoch: 39  loss= 0.3795906603336334\n",
            "shadow model: 76  epoch: 40  loss= 0.3901272118091583\n",
            "shadow model: 76  epoch: 41  loss= 0.30740562081336975\n",
            "shadow model: 76  epoch: 42  loss= 0.5297141075134277\n",
            "shadow model: 76  epoch: 43  loss= 0.3342716097831726\n",
            "shadow model: 76  epoch: 44  loss= 0.3492017686367035\n",
            "shadow model: 76  epoch: 45  loss= 0.3083938956260681\n",
            "shadow model: 76  epoch: 46  loss= 0.19250530004501343\n",
            "shadow model: 76  epoch: 47  loss= 0.3069143295288086\n",
            "shadow model: 76  epoch: 48  loss= 0.3776101768016815\n",
            "shadow model: 76  epoch: 49  loss= 0.24526284635066986\n",
            "shadow model: 76  epoch: 50  loss= 0.14799466729164124\n",
            "shadow model: 76  epoch: 51  loss= 0.27210816740989685\n",
            "shadow model: 76  epoch: 52  loss= 0.15709422528743744\n",
            "shadow model: 76  epoch: 53  loss= 0.3629734218120575\n",
            "shadow model: 76  epoch: 54  loss= 0.23726175725460052\n",
            "shadow model: 76  epoch: 55  loss= 0.21984991431236267\n",
            "shadow model: 76  epoch: 56  loss= 0.38348275423049927\n",
            "shadow model: 76  epoch: 57  loss= 0.17539596557617188\n",
            "shadow model: 76  epoch: 58  loss= 0.2177772969007492\n",
            "shadow model: 76  epoch: 59  loss= 0.3318761885166168\n",
            "shadow model: 76  epoch: 60  loss= 0.3147837817668915\n",
            "shadow model: 76  epoch: 61  loss= 0.19087621569633484\n",
            "shadow model: 76  epoch: 62  loss= 0.17582449316978455\n",
            "shadow model: 76  epoch: 63  loss= 0.1722911149263382\n",
            "shadow model: 76  epoch: 64  loss= 0.3045576214790344\n",
            "shadow model: 76  epoch: 65  loss= 0.13212256133556366\n",
            "shadow model: 76  epoch: 66  loss= 0.2064901441335678\n",
            "shadow model: 76  epoch: 67  loss= 0.20577315986156464\n",
            "shadow model: 76  epoch: 68  loss= 0.13244304060935974\n",
            "shadow model: 76  epoch: 69  loss= 0.10564897209405899\n",
            "shadow model: 76  epoch: 70  loss= 0.17057479918003082\n",
            "shadow model: 76  epoch: 71  loss= 0.21479414403438568\n",
            "shadow model: 76  epoch: 72  loss= 0.16481231153011322\n",
            "shadow model: 76  epoch: 73  loss= 0.1655655801296234\n",
            "shadow model: 76  epoch: 74  loss= 0.12947353720664978\n",
            "shadow model: 76  epoch: 75  loss= 0.1465146541595459\n",
            "shadow model: 76  epoch: 76  loss= 0.13176827132701874\n",
            "shadow model: 76  epoch: 77  loss= 0.13817912340164185\n",
            "shadow model: 76  epoch: 78  loss= 0.2566407024860382\n",
            "shadow model: 76  epoch: 79  loss= 0.17335450649261475\n",
            "shadow model: 76  epoch: 80  loss= 0.08796726912260056\n",
            "shadow model: 76  epoch: 81  loss= 0.07509151101112366\n",
            "shadow model: 76  epoch: 82  loss= 0.14759433269500732\n",
            "shadow model: 76  epoch: 83  loss= 0.10148803144693375\n",
            "shadow model: 76  epoch: 84  loss= 0.12949582934379578\n",
            "shadow model: 76  epoch: 85  loss= 0.23868736624717712\n",
            "shadow model: 76  epoch: 86  loss= 0.13607165217399597\n",
            "shadow model: 76  epoch: 87  loss= 0.13430142402648926\n",
            "shadow model: 76  epoch: 88  loss= 0.11192750930786133\n",
            "shadow model: 76  epoch: 89  loss= 0.07151663303375244\n",
            "shadow model: 76  epoch: 90  loss= 0.09031197428703308\n",
            "shadow model: 76  epoch: 91  loss= 0.09604130685329437\n",
            "shadow model: 76  epoch: 92  loss= 0.061883050948381424\n",
            "shadow model: 76  epoch: 93  loss= 0.09671778231859207\n",
            "shadow model: 76  epoch: 94  loss= 0.0974893569946289\n",
            "shadow model: 76  epoch: 95  loss= 0.11704673618078232\n",
            "shadow model: 76  epoch: 96  loss= 0.1510619968175888\n",
            "shadow model: 76  epoch: 97  loss= 0.07583513110876083\n",
            "shadow model: 76  epoch: 98  loss= 0.15018677711486816\n",
            "shadow model: 76  epoch: 99  loss= 0.15028981864452362\n",
            "shadow model: 76  epoch: 100  loss= 0.0873984545469284\n",
            "shadow model: 76  epoch: 101  loss= 0.08270225673913956\n",
            "shadow model: 76  epoch: 102  loss= 0.10285146534442902\n",
            "shadow model: 76  epoch: 103  loss= 0.153239443898201\n",
            "shadow model: 76  epoch: 104  loss= 0.08920898288488388\n",
            "shadow model: 76  epoch: 105  loss= 0.08734557777643204\n",
            "shadow model: 76  epoch: 106  loss= 0.08967370539903641\n",
            "shadow model: 76  epoch: 107  loss= 0.0761554166674614\n",
            "shadow model: 76  epoch: 108  loss= 0.08844245225191116\n",
            "shadow model: 76  epoch: 109  loss= 0.02872144617140293\n",
            "shadow model: 76  epoch: 110  loss= 0.11076712608337402\n",
            "shadow model: 76  epoch: 111  loss= 0.07458944618701935\n",
            "shadow model: 76  epoch: 112  loss= 0.18384499847888947\n",
            "shadow model: 76  epoch: 113  loss= 0.03035648539662361\n",
            "shadow model: 76  epoch: 114  loss= 0.053166426718235016\n",
            "shadow model: 76  epoch: 115  loss= 0.15604443848133087\n",
            "shadow model: 76  epoch: 116  loss= 0.09906873852014542\n",
            "shadow model: 76  epoch: 117  loss= 0.09083501249551773\n",
            "shadow model: 76  epoch: 118  loss= 0.10219984501600266\n",
            "shadow model: 76  epoch: 119  loss= 0.0645025372505188\n",
            "shadow model: 76  epoch: 120  loss= 0.13510163128376007\n",
            "shadow model: 76  epoch: 121  loss= 0.1050812155008316\n",
            "shadow model: 76  epoch: 122  loss= 0.05086440593004227\n",
            "shadow model: 76  epoch: 123  loss= 0.11519663035869598\n",
            "shadow model: 76  epoch: 124  loss= 0.11905062943696976\n",
            "shadow model: 76  epoch: 125  loss= 0.16463635861873627\n",
            "shadow model: 76  epoch: 126  loss= 0.10114764422178268\n",
            "shadow model: 76  epoch: 127  loss= 0.14832177758216858\n",
            "shadow model: 76  epoch: 128  loss= 0.05872943997383118\n",
            "shadow model: 76  epoch: 129  loss= 0.061302248388528824\n",
            "shadow model: 76  epoch: 130  loss= 0.027874821797013283\n",
            "shadow model: 76  epoch: 131  loss= 0.058500055223703384\n",
            "shadow model: 76  epoch: 132  loss= 0.16162005066871643\n",
            "shadow model: 76  epoch: 133  loss= 0.10972688347101212\n",
            "shadow model: 76  epoch: 134  loss= 0.03439880535006523\n",
            "shadow model: 76  epoch: 135  loss= 0.04023684561252594\n",
            "shadow model: 76  epoch: 136  loss= 0.05264337733387947\n",
            "shadow model: 76  epoch: 137  loss= 0.11639530956745148\n",
            "shadow model: 76  epoch: 138  loss= 0.12762704491615295\n",
            "shadow model: 76  epoch: 139  loss= 0.043347738683223724\n",
            "shadow model: 76  epoch: 140  loss= 0.1205141618847847\n",
            "shadow model: 76  epoch: 141  loss= 0.036393579095602036\n",
            "shadow model: 76  epoch: 142  loss= 0.13480789959430695\n",
            "shadow model: 76  epoch: 143  loss= 0.035833295434713364\n",
            "shadow model: 76  epoch: 144  loss= 0.02951117791235447\n",
            "shadow model: 76  epoch: 145  loss= 0.038384292274713516\n",
            "shadow model: 76  epoch: 146  loss= 0.09352006018161774\n",
            "shadow model: 76  epoch: 147  loss= 0.12627722322940826\n",
            "shadow model: 76  epoch: 148  loss= 0.07965095341205597\n",
            "shadow model: 76  epoch: 149  loss= 0.07145535200834274\n",
            "\n",
            "shadow model: 77  epoch: 0  loss= 2.2866148948669434\n",
            "shadow model: 77  epoch: 1  loss= 2.2962090969085693\n",
            "shadow model: 77  epoch: 2  loss= 2.1732840538024902\n",
            "shadow model: 77  epoch: 3  loss= 2.2022080421447754\n",
            "shadow model: 77  epoch: 4  loss= 2.0768978595733643\n",
            "shadow model: 77  epoch: 5  loss= 2.001133680343628\n",
            "shadow model: 77  epoch: 6  loss= 1.9481223821640015\n",
            "shadow model: 77  epoch: 7  loss= 1.8270071744918823\n",
            "shadow model: 77  epoch: 8  loss= 1.6861587762832642\n",
            "shadow model: 77  epoch: 9  loss= 1.8222830295562744\n",
            "shadow model: 77  epoch: 10  loss= 1.712161660194397\n",
            "shadow model: 77  epoch: 11  loss= 1.6190036535263062\n",
            "shadow model: 77  epoch: 12  loss= 1.5565097332000732\n",
            "shadow model: 77  epoch: 13  loss= 1.5499420166015625\n",
            "shadow model: 77  epoch: 14  loss= 1.3490095138549805\n",
            "shadow model: 77  epoch: 15  loss= 1.4313126802444458\n",
            "shadow model: 77  epoch: 16  loss= 1.4109140634536743\n",
            "shadow model: 77  epoch: 17  loss= 1.2733064889907837\n",
            "shadow model: 77  epoch: 18  loss= 1.2444958686828613\n",
            "shadow model: 77  epoch: 19  loss= 1.1162245273590088\n",
            "shadow model: 77  epoch: 20  loss= 1.002779245376587\n",
            "shadow model: 77  epoch: 21  loss= 0.9709144830703735\n",
            "shadow model: 77  epoch: 22  loss= 0.9569905400276184\n",
            "shadow model: 77  epoch: 23  loss= 0.976871132850647\n",
            "shadow model: 77  epoch: 24  loss= 0.8831146359443665\n",
            "shadow model: 77  epoch: 25  loss= 0.6781536340713501\n",
            "shadow model: 77  epoch: 26  loss= 0.7184673547744751\n",
            "shadow model: 77  epoch: 27  loss= 0.6507718563079834\n",
            "shadow model: 77  epoch: 28  loss= 0.713970959186554\n",
            "shadow model: 77  epoch: 29  loss= 0.8010504245758057\n",
            "shadow model: 77  epoch: 30  loss= 0.46413835883140564\n",
            "shadow model: 77  epoch: 31  loss= 0.5456454157829285\n",
            "shadow model: 77  epoch: 32  loss= 0.54721999168396\n",
            "shadow model: 77  epoch: 33  loss= 0.5082605481147766\n",
            "shadow model: 77  epoch: 34  loss= 0.4746059775352478\n",
            "shadow model: 77  epoch: 35  loss= 0.4595649242401123\n",
            "shadow model: 77  epoch: 36  loss= 0.42281511425971985\n",
            "shadow model: 77  epoch: 37  loss= 0.47766411304473877\n",
            "shadow model: 77  epoch: 38  loss= 0.40339195728302\n",
            "shadow model: 77  epoch: 39  loss= 0.3078969717025757\n",
            "shadow model: 77  epoch: 40  loss= 0.34470996260643005\n",
            "shadow model: 77  epoch: 41  loss= 0.37091097235679626\n",
            "shadow model: 77  epoch: 42  loss= 0.393635630607605\n",
            "shadow model: 77  epoch: 43  loss= 0.350130170583725\n",
            "shadow model: 77  epoch: 44  loss= 0.414140909910202\n",
            "shadow model: 77  epoch: 45  loss= 0.30939164757728577\n",
            "shadow model: 77  epoch: 46  loss= 0.3086618483066559\n",
            "shadow model: 77  epoch: 47  loss= 0.3033488988876343\n",
            "shadow model: 77  epoch: 48  loss= 0.31557992100715637\n",
            "shadow model: 77  epoch: 49  loss= 0.3813859224319458\n",
            "shadow model: 77  epoch: 50  loss= 0.27699360251426697\n",
            "shadow model: 77  epoch: 51  loss= 0.2363659143447876\n",
            "shadow model: 77  epoch: 52  loss= 0.23592157661914825\n",
            "shadow model: 77  epoch: 53  loss= 0.3639095425605774\n",
            "shadow model: 77  epoch: 54  loss= 0.19698074460029602\n",
            "shadow model: 77  epoch: 55  loss= 0.34480705857276917\n",
            "shadow model: 77  epoch: 56  loss= 0.28852784633636475\n",
            "shadow model: 77  epoch: 57  loss= 0.18385906517505646\n",
            "shadow model: 77  epoch: 58  loss= 0.18882493674755096\n",
            "shadow model: 77  epoch: 59  loss= 0.11349150538444519\n",
            "shadow model: 77  epoch: 60  loss= 0.1584358513355255\n",
            "shadow model: 77  epoch: 61  loss= 0.17527027428150177\n",
            "shadow model: 77  epoch: 62  loss= 0.06520865112543106\n",
            "shadow model: 77  epoch: 63  loss= 0.14477063715457916\n",
            "shadow model: 77  epoch: 64  loss= 0.20376825332641602\n",
            "shadow model: 77  epoch: 65  loss= 0.10261651873588562\n",
            "shadow model: 77  epoch: 66  loss= 0.1854269802570343\n",
            "shadow model: 77  epoch: 67  loss= 0.14990529417991638\n",
            "shadow model: 77  epoch: 68  loss= 0.14405357837677002\n",
            "shadow model: 77  epoch: 69  loss= 0.1478247195482254\n",
            "shadow model: 77  epoch: 70  loss= 0.12893633544445038\n",
            "shadow model: 77  epoch: 71  loss= 0.152970552444458\n",
            "shadow model: 77  epoch: 72  loss= 0.16452933847904205\n",
            "shadow model: 77  epoch: 73  loss= 0.05756962671875954\n",
            "shadow model: 77  epoch: 74  loss= 0.07656258344650269\n",
            "shadow model: 77  epoch: 75  loss= 0.15460200607776642\n",
            "shadow model: 77  epoch: 76  loss= 0.0889345183968544\n",
            "shadow model: 77  epoch: 77  loss= 0.04089060798287392\n",
            "shadow model: 77  epoch: 78  loss= 0.20596440136432648\n",
            "shadow model: 77  epoch: 79  loss= 0.10738501697778702\n",
            "shadow model: 77  epoch: 80  loss= 0.08273457735776901\n",
            "shadow model: 77  epoch: 81  loss= 0.09373173862695694\n",
            "shadow model: 77  epoch: 82  loss= 0.14100836217403412\n",
            "shadow model: 77  epoch: 83  loss= 0.074065662920475\n",
            "shadow model: 77  epoch: 84  loss= 0.16208207607269287\n",
            "shadow model: 77  epoch: 85  loss= 0.10732952505350113\n",
            "shadow model: 77  epoch: 86  loss= 0.07436000555753708\n",
            "shadow model: 77  epoch: 87  loss= 0.09757862985134125\n",
            "shadow model: 77  epoch: 88  loss= 0.10139144957065582\n",
            "shadow model: 77  epoch: 89  loss= 0.075539231300354\n",
            "shadow model: 77  epoch: 90  loss= 0.12024110555648804\n",
            "shadow model: 77  epoch: 91  loss= 0.09139537066221237\n",
            "shadow model: 77  epoch: 92  loss= 0.10974778234958649\n",
            "shadow model: 77  epoch: 93  loss= 0.08555018156766891\n",
            "shadow model: 77  epoch: 94  loss= 0.09697867184877396\n",
            "shadow model: 77  epoch: 95  loss= 0.07965049892663956\n",
            "shadow model: 77  epoch: 96  loss= 0.0911732017993927\n",
            "shadow model: 77  epoch: 97  loss= 0.15156127512454987\n",
            "shadow model: 77  epoch: 98  loss= 0.02965521067380905\n",
            "shadow model: 77  epoch: 99  loss= 0.13823142647743225\n",
            "shadow model: 77  epoch: 100  loss= 0.042917557060718536\n",
            "shadow model: 77  epoch: 101  loss= 0.1504160314798355\n",
            "shadow model: 77  epoch: 102  loss= 0.07585548609495163\n",
            "shadow model: 77  epoch: 103  loss= 0.08604758232831955\n",
            "shadow model: 77  epoch: 104  loss= 0.049262356013059616\n",
            "shadow model: 77  epoch: 105  loss= 0.1260925531387329\n",
            "shadow model: 77  epoch: 106  loss= 0.03868446499109268\n",
            "shadow model: 77  epoch: 107  loss= 0.12689997255802155\n",
            "shadow model: 77  epoch: 108  loss= 0.06557709723711014\n",
            "shadow model: 77  epoch: 109  loss= 0.04524514451622963\n",
            "shadow model: 77  epoch: 110  loss= 0.026744073256850243\n",
            "shadow model: 77  epoch: 111  loss= 0.15935297310352325\n",
            "shadow model: 77  epoch: 112  loss= 0.06945665180683136\n",
            "shadow model: 77  epoch: 113  loss= 0.0975109189748764\n",
            "shadow model: 77  epoch: 114  loss= 0.0959513783454895\n",
            "shadow model: 77  epoch: 115  loss= 0.03497125580906868\n",
            "shadow model: 77  epoch: 116  loss= 0.09035954624414444\n",
            "shadow model: 77  epoch: 117  loss= 0.05056842043995857\n",
            "shadow model: 77  epoch: 118  loss= 0.09820496290922165\n",
            "shadow model: 77  epoch: 119  loss= 0.04838644340634346\n",
            "shadow model: 77  epoch: 120  loss= 0.04762766510248184\n",
            "shadow model: 77  epoch: 121  loss= 0.15397904813289642\n",
            "shadow model: 77  epoch: 122  loss= 0.04019460454583168\n",
            "shadow model: 77  epoch: 123  loss= 0.028931891545653343\n",
            "shadow model: 77  epoch: 124  loss= 0.057565294206142426\n",
            "shadow model: 77  epoch: 125  loss= 0.0891614779829979\n",
            "shadow model: 77  epoch: 126  loss= 0.03832608088850975\n",
            "shadow model: 77  epoch: 127  loss= 0.1533164083957672\n",
            "shadow model: 77  epoch: 128  loss= 0.03734339401125908\n",
            "shadow model: 77  epoch: 129  loss= 0.03859541565179825\n",
            "shadow model: 77  epoch: 130  loss= 0.1660795658826828\n",
            "shadow model: 77  epoch: 131  loss= 0.03468642383813858\n",
            "shadow model: 77  epoch: 132  loss= 0.019371272996068\n",
            "shadow model: 77  epoch: 133  loss= 0.14304625988006592\n",
            "shadow model: 77  epoch: 134  loss= 0.077632375061512\n",
            "shadow model: 77  epoch: 135  loss= 0.04594401642680168\n",
            "shadow model: 77  epoch: 136  loss= 0.13438662886619568\n",
            "shadow model: 77  epoch: 137  loss= 0.17733831703662872\n",
            "shadow model: 77  epoch: 138  loss= 0.02745877206325531\n",
            "shadow model: 77  epoch: 139  loss= 0.08916547894477844\n",
            "shadow model: 77  epoch: 140  loss= 0.025303011760115623\n",
            "shadow model: 77  epoch: 141  loss= 0.0691327229142189\n",
            "shadow model: 77  epoch: 142  loss= 0.03333927318453789\n",
            "shadow model: 77  epoch: 143  loss= 0.03394993022084236\n",
            "shadow model: 77  epoch: 144  loss= 0.07894047349691391\n",
            "shadow model: 77  epoch: 145  loss= 0.01782708428800106\n",
            "shadow model: 77  epoch: 146  loss= 0.07291583716869354\n",
            "shadow model: 77  epoch: 147  loss= 0.13857845962047577\n",
            "shadow model: 77  epoch: 148  loss= 0.12305980175733566\n",
            "shadow model: 77  epoch: 149  loss= 0.04923512786626816\n",
            "\n",
            "shadow model: 78  epoch: 0  loss= 2.231856346130371\n",
            "shadow model: 78  epoch: 1  loss= 2.2987053394317627\n",
            "shadow model: 78  epoch: 2  loss= 2.2006986141204834\n",
            "shadow model: 78  epoch: 3  loss= 2.212402582168579\n",
            "shadow model: 78  epoch: 4  loss= 2.0517678260803223\n",
            "shadow model: 78  epoch: 5  loss= 1.936224102973938\n",
            "shadow model: 78  epoch: 6  loss= 1.7906129360198975\n",
            "shadow model: 78  epoch: 7  loss= 1.6299687623977661\n",
            "shadow model: 78  epoch: 8  loss= 1.6143794059753418\n",
            "shadow model: 78  epoch: 9  loss= 1.6194424629211426\n",
            "shadow model: 78  epoch: 10  loss= 1.7329236268997192\n",
            "shadow model: 78  epoch: 11  loss= 1.7863112688064575\n",
            "shadow model: 78  epoch: 12  loss= 1.6578000783920288\n",
            "shadow model: 78  epoch: 13  loss= 1.5071052312850952\n",
            "shadow model: 78  epoch: 14  loss= 1.639908790588379\n",
            "shadow model: 78  epoch: 15  loss= 1.7280917167663574\n",
            "shadow model: 78  epoch: 16  loss= 1.2196264266967773\n",
            "shadow model: 78  epoch: 17  loss= 1.5807101726531982\n",
            "shadow model: 78  epoch: 18  loss= 1.450432300567627\n",
            "shadow model: 78  epoch: 19  loss= 1.2188185453414917\n",
            "shadow model: 78  epoch: 20  loss= 1.111801266670227\n",
            "shadow model: 78  epoch: 21  loss= 1.057917594909668\n",
            "shadow model: 78  epoch: 22  loss= 1.1443867683410645\n",
            "shadow model: 78  epoch: 23  loss= 0.8533189296722412\n",
            "shadow model: 78  epoch: 24  loss= 0.9213696122169495\n",
            "shadow model: 78  epoch: 25  loss= 0.8229566812515259\n",
            "shadow model: 78  epoch: 26  loss= 0.8444303274154663\n",
            "shadow model: 78  epoch: 27  loss= 0.9491252899169922\n",
            "shadow model: 78  epoch: 28  loss= 0.7337744235992432\n",
            "shadow model: 78  epoch: 29  loss= 0.9578185677528381\n",
            "shadow model: 78  epoch: 30  loss= 0.7135787606239319\n",
            "shadow model: 78  epoch: 31  loss= 0.7166152000427246\n",
            "shadow model: 78  epoch: 32  loss= 0.6745883822441101\n",
            "shadow model: 78  epoch: 33  loss= 0.7889167666435242\n",
            "shadow model: 78  epoch: 34  loss= 0.5038540363311768\n",
            "shadow model: 78  epoch: 35  loss= 0.6303778886795044\n",
            "shadow model: 78  epoch: 36  loss= 0.46350279450416565\n",
            "shadow model: 78  epoch: 37  loss= 0.4494306445121765\n",
            "shadow model: 78  epoch: 38  loss= 0.5051835179328918\n",
            "shadow model: 78  epoch: 39  loss= 0.5288577079772949\n",
            "shadow model: 78  epoch: 40  loss= 0.6378486156463623\n",
            "shadow model: 78  epoch: 41  loss= 0.5542327761650085\n",
            "shadow model: 78  epoch: 42  loss= 0.3689115643501282\n",
            "shadow model: 78  epoch: 43  loss= 0.44228991866111755\n",
            "shadow model: 78  epoch: 44  loss= 0.3223417103290558\n",
            "shadow model: 78  epoch: 45  loss= 0.45610669255256653\n",
            "shadow model: 78  epoch: 46  loss= 0.23186613619327545\n",
            "shadow model: 78  epoch: 47  loss= 0.2856948673725128\n",
            "shadow model: 78  epoch: 48  loss= 0.40411871671676636\n",
            "shadow model: 78  epoch: 49  loss= 0.3649269640445709\n",
            "shadow model: 78  epoch: 50  loss= 0.3203297555446625\n",
            "shadow model: 78  epoch: 51  loss= 0.48439234495162964\n",
            "shadow model: 78  epoch: 52  loss= 0.361358642578125\n",
            "shadow model: 78  epoch: 53  loss= 0.31561943888664246\n",
            "shadow model: 78  epoch: 54  loss= 0.31774693727493286\n",
            "shadow model: 78  epoch: 55  loss= 0.4045027792453766\n",
            "shadow model: 78  epoch: 56  loss= 0.2940090298652649\n",
            "shadow model: 78  epoch: 57  loss= 0.15459948778152466\n",
            "shadow model: 78  epoch: 58  loss= 0.290202260017395\n",
            "shadow model: 78  epoch: 59  loss= 0.23580090701580048\n",
            "shadow model: 78  epoch: 60  loss= 0.21652066707611084\n",
            "shadow model: 78  epoch: 61  loss= 0.24396105110645294\n",
            "shadow model: 78  epoch: 62  loss= 0.2557576596736908\n",
            "shadow model: 78  epoch: 63  loss= 0.07733850181102753\n",
            "shadow model: 78  epoch: 64  loss= 0.163007915019989\n",
            "shadow model: 78  epoch: 65  loss= 0.19473765790462494\n",
            "shadow model: 78  epoch: 66  loss= 0.18142090737819672\n",
            "shadow model: 78  epoch: 67  loss= 0.21599288284778595\n",
            "shadow model: 78  epoch: 68  loss= 0.16055640578269958\n",
            "shadow model: 78  epoch: 69  loss= 0.38680440187454224\n",
            "shadow model: 78  epoch: 70  loss= 0.12233859300613403\n",
            "shadow model: 78  epoch: 71  loss= 0.2169189304113388\n",
            "shadow model: 78  epoch: 72  loss= 0.2702023983001709\n",
            "shadow model: 78  epoch: 73  loss= 0.19953790307044983\n",
            "shadow model: 78  epoch: 74  loss= 0.20733998715877533\n",
            "shadow model: 78  epoch: 75  loss= 0.04499489814043045\n",
            "shadow model: 78  epoch: 76  loss= 0.09768392890691757\n",
            "shadow model: 78  epoch: 77  loss= 0.21353553235530853\n",
            "shadow model: 78  epoch: 78  loss= 0.14199434220790863\n",
            "shadow model: 78  epoch: 79  loss= 0.32665133476257324\n",
            "shadow model: 78  epoch: 80  loss= 0.2198115587234497\n",
            "shadow model: 78  epoch: 81  loss= 0.1863538920879364\n",
            "shadow model: 78  epoch: 82  loss= 0.17606252431869507\n",
            "shadow model: 78  epoch: 83  loss= 0.07910541445016861\n",
            "shadow model: 78  epoch: 84  loss= 0.14817818999290466\n",
            "shadow model: 78  epoch: 85  loss= 0.2314048856496811\n",
            "shadow model: 78  epoch: 86  loss= 0.21119451522827148\n",
            "shadow model: 78  epoch: 87  loss= 0.14802926778793335\n",
            "shadow model: 78  epoch: 88  loss= 0.19491656124591827\n",
            "shadow model: 78  epoch: 89  loss= 0.22851915657520294\n",
            "shadow model: 78  epoch: 90  loss= 0.15369394421577454\n",
            "shadow model: 78  epoch: 91  loss= 0.12980563938617706\n",
            "shadow model: 78  epoch: 92  loss= 0.045149289071559906\n",
            "shadow model: 78  epoch: 93  loss= 0.19234785437583923\n",
            "shadow model: 78  epoch: 94  loss= 0.16957612335681915\n",
            "shadow model: 78  epoch: 95  loss= 0.10927819460630417\n",
            "shadow model: 78  epoch: 96  loss= 0.1130167618393898\n",
            "shadow model: 78  epoch: 97  loss= 0.14204300940036774\n",
            "shadow model: 78  epoch: 98  loss= 0.0981326624751091\n",
            "shadow model: 78  epoch: 99  loss= 0.16159874200820923\n",
            "shadow model: 78  epoch: 100  loss= 0.13916552066802979\n",
            "shadow model: 78  epoch: 101  loss= 0.12689492106437683\n",
            "shadow model: 78  epoch: 102  loss= 0.17871394753456116\n",
            "shadow model: 78  epoch: 103  loss= 0.08665317296981812\n",
            "shadow model: 78  epoch: 104  loss= 0.05443865433335304\n",
            "shadow model: 78  epoch: 105  loss= 0.17691633105278015\n",
            "shadow model: 78  epoch: 106  loss= 0.10856007784605026\n",
            "shadow model: 78  epoch: 107  loss= 0.1593056619167328\n",
            "shadow model: 78  epoch: 108  loss= 0.06544752418994904\n",
            "shadow model: 78  epoch: 109  loss= 0.11871303617954254\n",
            "shadow model: 78  epoch: 110  loss= 0.08510886877775192\n",
            "shadow model: 78  epoch: 111  loss= 0.07544641941785812\n",
            "shadow model: 78  epoch: 112  loss= 0.12105493992567062\n",
            "shadow model: 78  epoch: 113  loss= 0.1591600477695465\n",
            "shadow model: 78  epoch: 114  loss= 0.04551718011498451\n",
            "shadow model: 78  epoch: 115  loss= 0.08837181329727173\n",
            "shadow model: 78  epoch: 116  loss= 0.11149007081985474\n",
            "shadow model: 78  epoch: 117  loss= 0.08999156951904297\n",
            "shadow model: 78  epoch: 118  loss= 0.049453578889369965\n",
            "shadow model: 78  epoch: 119  loss= 0.08052460849285126\n",
            "shadow model: 78  epoch: 120  loss= 0.09758427739143372\n",
            "shadow model: 78  epoch: 121  loss= 0.1010642796754837\n",
            "shadow model: 78  epoch: 122  loss= 0.025768497958779335\n",
            "shadow model: 78  epoch: 123  loss= 0.0462346076965332\n",
            "shadow model: 78  epoch: 124  loss= 0.0853915885090828\n",
            "shadow model: 78  epoch: 125  loss= 0.06146664544939995\n",
            "shadow model: 78  epoch: 126  loss= 0.07404356449842453\n",
            "shadow model: 78  epoch: 127  loss= 0.04139416292309761\n",
            "shadow model: 78  epoch: 128  loss= 0.16778036952018738\n",
            "shadow model: 78  epoch: 129  loss= 0.023887090384960175\n",
            "shadow model: 78  epoch: 130  loss= 0.1402973234653473\n",
            "shadow model: 78  epoch: 131  loss= 0.028115220367908478\n",
            "shadow model: 78  epoch: 132  loss= 0.055089063942432404\n",
            "shadow model: 78  epoch: 133  loss= 0.0341804139316082\n",
            "shadow model: 78  epoch: 134  loss= 0.06935416162014008\n",
            "shadow model: 78  epoch: 135  loss= 0.05391717329621315\n",
            "shadow model: 78  epoch: 136  loss= 0.11087798327207565\n",
            "shadow model: 78  epoch: 137  loss= 0.045512255281209946\n",
            "shadow model: 78  epoch: 138  loss= 0.07373356819152832\n",
            "shadow model: 78  epoch: 139  loss= 0.04181768745183945\n",
            "shadow model: 78  epoch: 140  loss= 0.13517224788665771\n",
            "shadow model: 78  epoch: 141  loss= 0.055186644196510315\n",
            "shadow model: 78  epoch: 142  loss= 0.15346528589725494\n",
            "shadow model: 78  epoch: 143  loss= 0.16685831546783447\n",
            "shadow model: 78  epoch: 144  loss= 0.059031516313552856\n",
            "shadow model: 78  epoch: 145  loss= 0.020694198086857796\n",
            "shadow model: 78  epoch: 146  loss= 0.14192529022693634\n",
            "shadow model: 78  epoch: 147  loss= 0.06915511935949326\n",
            "shadow model: 78  epoch: 148  loss= 0.07703468948602676\n",
            "shadow model: 78  epoch: 149  loss= 0.09732924401760101\n",
            "\n",
            "shadow model: 79  epoch: 0  loss= 2.3372766971588135\n",
            "shadow model: 79  epoch: 1  loss= 2.2491610050201416\n",
            "shadow model: 79  epoch: 2  loss= 2.222978115081787\n",
            "shadow model: 79  epoch: 3  loss= 2.185462713241577\n",
            "shadow model: 79  epoch: 4  loss= 2.1101882457733154\n",
            "shadow model: 79  epoch: 5  loss= 2.0725162029266357\n",
            "shadow model: 79  epoch: 6  loss= 2.0583837032318115\n",
            "shadow model: 79  epoch: 7  loss= 1.9724807739257812\n",
            "shadow model: 79  epoch: 8  loss= 1.7766422033309937\n",
            "shadow model: 79  epoch: 9  loss= 1.9837641716003418\n",
            "shadow model: 79  epoch: 10  loss= 1.8184809684753418\n",
            "shadow model: 79  epoch: 11  loss= 1.4739525318145752\n",
            "shadow model: 79  epoch: 12  loss= 1.521701455116272\n",
            "shadow model: 79  epoch: 13  loss= 1.5078526735305786\n",
            "shadow model: 79  epoch: 14  loss= 1.991456389427185\n",
            "shadow model: 79  epoch: 15  loss= 1.510356068611145\n",
            "shadow model: 79  epoch: 16  loss= 1.5091164112091064\n",
            "shadow model: 79  epoch: 17  loss= 1.3424561023712158\n",
            "shadow model: 79  epoch: 18  loss= 1.4324942827224731\n",
            "shadow model: 79  epoch: 19  loss= 1.4195533990859985\n",
            "shadow model: 79  epoch: 20  loss= 1.185713291168213\n",
            "shadow model: 79  epoch: 21  loss= 1.18573796749115\n",
            "shadow model: 79  epoch: 22  loss= 1.2753913402557373\n",
            "shadow model: 79  epoch: 23  loss= 1.3141173124313354\n",
            "shadow model: 79  epoch: 24  loss= 1.1392678022384644\n",
            "shadow model: 79  epoch: 25  loss= 1.121532917022705\n",
            "shadow model: 79  epoch: 26  loss= 0.9579025506973267\n",
            "shadow model: 79  epoch: 27  loss= 0.7150039076805115\n",
            "shadow model: 79  epoch: 28  loss= 0.8821313381195068\n",
            "shadow model: 79  epoch: 29  loss= 0.901872456073761\n",
            "shadow model: 79  epoch: 30  loss= 0.7552276849746704\n",
            "shadow model: 79  epoch: 31  loss= 0.8118705749511719\n",
            "shadow model: 79  epoch: 32  loss= 0.7828262448310852\n",
            "shadow model: 79  epoch: 33  loss= 0.5966921448707581\n",
            "shadow model: 79  epoch: 34  loss= 0.5819116234779358\n",
            "shadow model: 79  epoch: 35  loss= 0.5833983421325684\n",
            "shadow model: 79  epoch: 36  loss= 0.620423436164856\n",
            "shadow model: 79  epoch: 37  loss= 0.549871027469635\n",
            "shadow model: 79  epoch: 38  loss= 0.5719687938690186\n",
            "shadow model: 79  epoch: 39  loss= 0.5320059061050415\n",
            "shadow model: 79  epoch: 40  loss= 0.576560914516449\n",
            "shadow model: 79  epoch: 41  loss= 0.5458069443702698\n",
            "shadow model: 79  epoch: 42  loss= 0.4404393136501312\n",
            "shadow model: 79  epoch: 43  loss= 0.5792399048805237\n",
            "shadow model: 79  epoch: 44  loss= 0.43323102593421936\n",
            "shadow model: 79  epoch: 45  loss= 0.4480779469013214\n",
            "shadow model: 79  epoch: 46  loss= 0.4090632498264313\n",
            "shadow model: 79  epoch: 47  loss= 0.4440991282463074\n",
            "shadow model: 79  epoch: 48  loss= 0.3514064848423004\n",
            "shadow model: 79  epoch: 49  loss= 0.4412057399749756\n",
            "shadow model: 79  epoch: 50  loss= 0.32876378297805786\n",
            "shadow model: 79  epoch: 51  loss= 0.5190860033035278\n",
            "shadow model: 79  epoch: 52  loss= 0.1790301352739334\n",
            "shadow model: 79  epoch: 53  loss= 0.3464955687522888\n",
            "shadow model: 79  epoch: 54  loss= 0.36263105273246765\n",
            "shadow model: 79  epoch: 55  loss= 0.3342769145965576\n",
            "shadow model: 79  epoch: 56  loss= 0.3308473825454712\n",
            "shadow model: 79  epoch: 57  loss= 0.2681146562099457\n",
            "shadow model: 79  epoch: 58  loss= 0.2314871847629547\n",
            "shadow model: 79  epoch: 59  loss= 0.2430991679430008\n",
            "shadow model: 79  epoch: 60  loss= 0.43762245774269104\n",
            "shadow model: 79  epoch: 61  loss= 0.27664536237716675\n",
            "shadow model: 79  epoch: 62  loss= 0.1939905434846878\n",
            "shadow model: 79  epoch: 63  loss= 0.20058313012123108\n",
            "shadow model: 79  epoch: 64  loss= 0.11054473370313644\n",
            "shadow model: 79  epoch: 65  loss= 0.36386650800704956\n",
            "shadow model: 79  epoch: 66  loss= 0.2090785801410675\n",
            "shadow model: 79  epoch: 67  loss= 0.22478491067886353\n",
            "shadow model: 79  epoch: 68  loss= 0.18429560959339142\n",
            "shadow model: 79  epoch: 69  loss= 0.14669939875602722\n",
            "shadow model: 79  epoch: 70  loss= 0.233607679605484\n",
            "shadow model: 79  epoch: 71  loss= 0.14447326958179474\n",
            "shadow model: 79  epoch: 72  loss= 0.14999926090240479\n",
            "shadow model: 79  epoch: 73  loss= 0.13612166047096252\n",
            "shadow model: 79  epoch: 74  loss= 0.15771907567977905\n",
            "shadow model: 79  epoch: 75  loss= 0.11267012357711792\n",
            "shadow model: 79  epoch: 76  loss= 0.09471618384122849\n",
            "shadow model: 79  epoch: 77  loss= 0.20428255200386047\n",
            "shadow model: 79  epoch: 78  loss= 0.23631148040294647\n",
            "shadow model: 79  epoch: 79  loss= 0.1647605299949646\n",
            "shadow model: 79  epoch: 80  loss= 0.16565395891666412\n",
            "shadow model: 79  epoch: 81  loss= 0.19948583841323853\n",
            "shadow model: 79  epoch: 82  loss= 0.07288113981485367\n",
            "shadow model: 79  epoch: 83  loss= 0.2788640558719635\n",
            "shadow model: 79  epoch: 84  loss= 0.16522561013698578\n",
            "shadow model: 79  epoch: 85  loss= 0.1930413693189621\n",
            "shadow model: 79  epoch: 86  loss= 0.18183591961860657\n",
            "shadow model: 79  epoch: 87  loss= 0.22759674489498138\n",
            "shadow model: 79  epoch: 88  loss= 0.21379582583904266\n",
            "shadow model: 79  epoch: 89  loss= 0.12894457578659058\n",
            "shadow model: 79  epoch: 90  loss= 0.12495440244674683\n",
            "shadow model: 79  epoch: 91  loss= 0.17651531100273132\n",
            "shadow model: 79  epoch: 92  loss= 0.16484619677066803\n",
            "shadow model: 79  epoch: 93  loss= 0.2101026475429535\n",
            "shadow model: 79  epoch: 94  loss= 0.1878078728914261\n",
            "shadow model: 79  epoch: 95  loss= 0.2672596275806427\n",
            "shadow model: 79  epoch: 96  loss= 0.15603022277355194\n",
            "shadow model: 79  epoch: 97  loss= 0.06965053081512451\n",
            "shadow model: 79  epoch: 98  loss= 0.13673140108585358\n",
            "shadow model: 79  epoch: 99  loss= 0.17732354998588562\n",
            "shadow model: 79  epoch: 100  loss= 0.1024872213602066\n",
            "shadow model: 79  epoch: 101  loss= 0.05464164540171623\n",
            "shadow model: 79  epoch: 102  loss= 0.11970631778240204\n",
            "shadow model: 79  epoch: 103  loss= 0.12372225522994995\n",
            "shadow model: 79  epoch: 104  loss= 0.07503283768892288\n",
            "shadow model: 79  epoch: 105  loss= 0.18053336441516876\n",
            "shadow model: 79  epoch: 106  loss= 0.12427537143230438\n",
            "shadow model: 79  epoch: 107  loss= 0.15172451734542847\n",
            "shadow model: 79  epoch: 108  loss= 0.10967384278774261\n",
            "shadow model: 79  epoch: 109  loss= 0.04394666105508804\n",
            "shadow model: 79  epoch: 110  loss= 0.21802781522274017\n",
            "shadow model: 79  epoch: 111  loss= 0.07925162464380264\n",
            "shadow model: 79  epoch: 112  loss= 0.20325502753257751\n",
            "shadow model: 79  epoch: 113  loss= 0.15864714980125427\n",
            "shadow model: 79  epoch: 114  loss= 0.08635266870260239\n",
            "shadow model: 79  epoch: 115  loss= 0.1535872220993042\n",
            "shadow model: 79  epoch: 116  loss= 0.10651784390211105\n",
            "shadow model: 79  epoch: 117  loss= 0.22194752097129822\n",
            "shadow model: 79  epoch: 118  loss= 0.12325631827116013\n",
            "shadow model: 79  epoch: 119  loss= 0.057801999151706696\n",
            "shadow model: 79  epoch: 120  loss= 0.20505231618881226\n",
            "shadow model: 79  epoch: 121  loss= 0.12468105554580688\n",
            "shadow model: 79  epoch: 122  loss= 0.13194286823272705\n",
            "shadow model: 79  epoch: 123  loss= 0.031563807278871536\n",
            "shadow model: 79  epoch: 124  loss= 0.1757276952266693\n",
            "shadow model: 79  epoch: 125  loss= 0.11828188598155975\n",
            "shadow model: 79  epoch: 126  loss= 0.10540753602981567\n",
            "shadow model: 79  epoch: 127  loss= 0.11874198168516159\n",
            "shadow model: 79  epoch: 128  loss= 0.07489504665136337\n",
            "shadow model: 79  epoch: 129  loss= 0.07144111394882202\n",
            "shadow model: 79  epoch: 130  loss= 0.070120669901371\n",
            "shadow model: 79  epoch: 131  loss= 0.10128153860569\n",
            "shadow model: 79  epoch: 132  loss= 0.417033314704895\n",
            "shadow model: 79  epoch: 133  loss= 0.09428948909044266\n",
            "shadow model: 79  epoch: 134  loss= 0.058747466653585434\n",
            "shadow model: 79  epoch: 135  loss= 0.1320454627275467\n",
            "shadow model: 79  epoch: 136  loss= 0.07553007453680038\n",
            "shadow model: 79  epoch: 137  loss= 0.1062723770737648\n",
            "shadow model: 79  epoch: 138  loss= 0.10233563929796219\n",
            "shadow model: 79  epoch: 139  loss= 0.03244686871767044\n",
            "shadow model: 79  epoch: 140  loss= 0.13184329867362976\n",
            "shadow model: 79  epoch: 141  loss= 0.08054464310407639\n",
            "shadow model: 79  epoch: 142  loss= 0.04388890415430069\n",
            "shadow model: 79  epoch: 143  loss= 0.10895296931266785\n",
            "shadow model: 79  epoch: 144  loss= 0.23359987139701843\n",
            "shadow model: 79  epoch: 145  loss= 0.0850224494934082\n",
            "shadow model: 79  epoch: 146  loss= 0.05760747939348221\n",
            "shadow model: 79  epoch: 147  loss= 0.03558596223592758\n",
            "shadow model: 79  epoch: 148  loss= 0.022673215717077255\n",
            "shadow model: 79  epoch: 149  loss= 0.03825979679822922\n",
            "\n",
            "shadow model: 80  epoch: 0  loss= 2.3433027267456055\n",
            "shadow model: 80  epoch: 1  loss= 2.313438653945923\n",
            "shadow model: 80  epoch: 2  loss= 2.226329803466797\n",
            "shadow model: 80  epoch: 3  loss= 2.2492146492004395\n",
            "shadow model: 80  epoch: 4  loss= 2.1879568099975586\n",
            "shadow model: 80  epoch: 5  loss= 2.1016640663146973\n",
            "shadow model: 80  epoch: 6  loss= 2.0071816444396973\n",
            "shadow model: 80  epoch: 7  loss= 2.092334032058716\n",
            "shadow model: 80  epoch: 8  loss= 2.0425331592559814\n",
            "shadow model: 80  epoch: 9  loss= 1.8348431587219238\n",
            "shadow model: 80  epoch: 10  loss= 1.842098355293274\n",
            "shadow model: 80  epoch: 11  loss= 1.7587122917175293\n",
            "shadow model: 80  epoch: 12  loss= 1.8023782968521118\n",
            "shadow model: 80  epoch: 13  loss= 1.4311569929122925\n",
            "shadow model: 80  epoch: 14  loss= 1.5267338752746582\n",
            "shadow model: 80  epoch: 15  loss= 1.4482612609863281\n",
            "shadow model: 80  epoch: 16  loss= 1.4105024337768555\n",
            "shadow model: 80  epoch: 17  loss= 1.4609429836273193\n",
            "shadow model: 80  epoch: 18  loss= 1.3810619115829468\n",
            "shadow model: 80  epoch: 19  loss= 1.4279158115386963\n",
            "shadow model: 80  epoch: 20  loss= 1.2629423141479492\n",
            "shadow model: 80  epoch: 21  loss= 1.1991695165634155\n",
            "shadow model: 80  epoch: 22  loss= 1.095185399055481\n",
            "shadow model: 80  epoch: 23  loss= 1.094447374343872\n",
            "shadow model: 80  epoch: 24  loss= 0.8257874250411987\n",
            "shadow model: 80  epoch: 25  loss= 1.0194838047027588\n",
            "shadow model: 80  epoch: 26  loss= 0.8963610529899597\n",
            "shadow model: 80  epoch: 27  loss= 0.7725035548210144\n",
            "shadow model: 80  epoch: 28  loss= 0.7464044690132141\n",
            "shadow model: 80  epoch: 29  loss= 0.6971626877784729\n",
            "shadow model: 80  epoch: 30  loss= 0.6210946440696716\n",
            "shadow model: 80  epoch: 31  loss= 0.6467984914779663\n",
            "shadow model: 80  epoch: 32  loss= 0.6078848242759705\n",
            "shadow model: 80  epoch: 33  loss= 0.5530014038085938\n",
            "shadow model: 80  epoch: 34  loss= 0.46972182393074036\n",
            "shadow model: 80  epoch: 35  loss= 0.6897966861724854\n",
            "shadow model: 80  epoch: 36  loss= 0.5521536469459534\n",
            "shadow model: 80  epoch: 37  loss= 0.42470425367355347\n",
            "shadow model: 80  epoch: 38  loss= 0.5257604122161865\n",
            "shadow model: 80  epoch: 39  loss= 0.5395240187644958\n",
            "shadow model: 80  epoch: 40  loss= 0.4903731048107147\n",
            "shadow model: 80  epoch: 41  loss= 0.500617504119873\n",
            "shadow model: 80  epoch: 42  loss= 0.44356465339660645\n",
            "shadow model: 80  epoch: 43  loss= 0.2824135720729828\n",
            "shadow model: 80  epoch: 44  loss= 0.37852033972740173\n",
            "shadow model: 80  epoch: 45  loss= 0.49705687165260315\n",
            "shadow model: 80  epoch: 46  loss= 0.4800189137458801\n",
            "shadow model: 80  epoch: 47  loss= 0.32486242055892944\n",
            "shadow model: 80  epoch: 48  loss= 0.2669401466846466\n",
            "shadow model: 80  epoch: 49  loss= 0.3361031413078308\n",
            "shadow model: 80  epoch: 50  loss= 0.2509387135505676\n",
            "shadow model: 80  epoch: 51  loss= 0.4438875913619995\n",
            "shadow model: 80  epoch: 52  loss= 0.312597393989563\n",
            "shadow model: 80  epoch: 53  loss= 0.1902874857187271\n",
            "shadow model: 80  epoch: 54  loss= 0.22599200904369354\n",
            "shadow model: 80  epoch: 55  loss= 0.19494619965553284\n",
            "shadow model: 80  epoch: 56  loss= 0.21903584897518158\n",
            "shadow model: 80  epoch: 57  loss= 0.25673553347587585\n",
            "shadow model: 80  epoch: 58  loss= 0.1965598165988922\n",
            "shadow model: 80  epoch: 59  loss= 0.22554439306259155\n",
            "shadow model: 80  epoch: 60  loss= 0.18740586936473846\n",
            "shadow model: 80  epoch: 61  loss= 0.24705353379249573\n",
            "shadow model: 80  epoch: 62  loss= 0.20146603882312775\n",
            "shadow model: 80  epoch: 63  loss= 0.22308461368083954\n",
            "shadow model: 80  epoch: 64  loss= 0.22831159830093384\n",
            "shadow model: 80  epoch: 65  loss= 0.14266858994960785\n",
            "shadow model: 80  epoch: 66  loss= 0.20983687043190002\n",
            "shadow model: 80  epoch: 67  loss= 0.17295947670936584\n",
            "shadow model: 80  epoch: 68  loss= 0.14833350479602814\n",
            "shadow model: 80  epoch: 69  loss= 0.15602651238441467\n",
            "shadow model: 80  epoch: 70  loss= 0.12184876203536987\n",
            "shadow model: 80  epoch: 71  loss= 0.15074460208415985\n",
            "shadow model: 80  epoch: 72  loss= 0.12574319541454315\n",
            "shadow model: 80  epoch: 73  loss= 0.11727415025234222\n",
            "shadow model: 80  epoch: 74  loss= 0.2213069200515747\n",
            "shadow model: 80  epoch: 75  loss= 0.13889503479003906\n",
            "shadow model: 80  epoch: 76  loss= 0.08468819409608841\n",
            "shadow model: 80  epoch: 77  loss= 0.16517123579978943\n",
            "shadow model: 80  epoch: 78  loss= 0.06463892757892609\n",
            "shadow model: 80  epoch: 79  loss= 0.10747682303190231\n",
            "shadow model: 80  epoch: 80  loss= 0.15949635207653046\n",
            "shadow model: 80  epoch: 81  loss= 0.08910779654979706\n",
            "shadow model: 80  epoch: 82  loss= 0.15757803618907928\n",
            "shadow model: 80  epoch: 83  loss= 0.039347920566797256\n",
            "shadow model: 80  epoch: 84  loss= 0.13923344016075134\n",
            "shadow model: 80  epoch: 85  loss= 0.09712939709424973\n",
            "shadow model: 80  epoch: 86  loss= 0.18390898406505585\n",
            "shadow model: 80  epoch: 87  loss= 0.15470002591609955\n",
            "shadow model: 80  epoch: 88  loss= 0.10936151444911957\n",
            "shadow model: 80  epoch: 89  loss= 0.11221621185541153\n",
            "shadow model: 80  epoch: 90  loss= 0.1949983537197113\n",
            "shadow model: 80  epoch: 91  loss= 0.08556719869375229\n",
            "shadow model: 80  epoch: 92  loss= 0.09295985847711563\n",
            "shadow model: 80  epoch: 93  loss= 0.05025924742221832\n",
            "shadow model: 80  epoch: 94  loss= 0.18015389144420624\n",
            "shadow model: 80  epoch: 95  loss= 0.12614408135414124\n",
            "shadow model: 80  epoch: 96  loss= 0.19533126056194305\n",
            "shadow model: 80  epoch: 97  loss= 0.09758744388818741\n",
            "shadow model: 80  epoch: 98  loss= 0.07368078827857971\n",
            "shadow model: 80  epoch: 99  loss= 0.11220672726631165\n",
            "shadow model: 80  epoch: 100  loss= 0.06209099292755127\n",
            "shadow model: 80  epoch: 101  loss= 0.07807982712984085\n",
            "shadow model: 80  epoch: 102  loss= 0.14206355810165405\n",
            "shadow model: 80  epoch: 103  loss= 0.16885064542293549\n",
            "shadow model: 80  epoch: 104  loss= 0.052988361567258835\n",
            "shadow model: 80  epoch: 105  loss= 0.08689254522323608\n",
            "shadow model: 80  epoch: 106  loss= 0.10370633751153946\n",
            "shadow model: 80  epoch: 107  loss= 0.13230860233306885\n",
            "shadow model: 80  epoch: 108  loss= 0.1324455738067627\n",
            "shadow model: 80  epoch: 109  loss= 0.06436681002378464\n",
            "shadow model: 80  epoch: 110  loss= 0.07629796117544174\n",
            "shadow model: 80  epoch: 111  loss= 0.20075654983520508\n",
            "shadow model: 80  epoch: 112  loss= 0.031421639025211334\n",
            "shadow model: 80  epoch: 113  loss= 0.04897165670990944\n",
            "shadow model: 80  epoch: 114  loss= 0.060867954045534134\n",
            "shadow model: 80  epoch: 115  loss= 0.07587229460477829\n",
            "shadow model: 80  epoch: 116  loss= 0.03539817035198212\n",
            "shadow model: 80  epoch: 117  loss= 0.13260804116725922\n",
            "shadow model: 80  epoch: 118  loss= 0.17405804991722107\n",
            "shadow model: 80  epoch: 119  loss= 0.09827218949794769\n",
            "shadow model: 80  epoch: 120  loss= 0.08464435487985611\n",
            "shadow model: 80  epoch: 121  loss= 0.15313607454299927\n",
            "shadow model: 80  epoch: 122  loss= 0.13639682531356812\n",
            "shadow model: 80  epoch: 123  loss= 0.12411842495203018\n",
            "shadow model: 80  epoch: 124  loss= 0.08655417710542679\n",
            "shadow model: 80  epoch: 125  loss= 0.042744603008031845\n",
            "shadow model: 80  epoch: 126  loss= 0.1448150873184204\n",
            "shadow model: 80  epoch: 127  loss= 0.0735895186662674\n",
            "shadow model: 80  epoch: 128  loss= 0.05915138125419617\n",
            "shadow model: 80  epoch: 129  loss= 0.0543045699596405\n",
            "shadow model: 80  epoch: 130  loss= 0.042415499687194824\n",
            "shadow model: 80  epoch: 131  loss= 0.15235504508018494\n",
            "shadow model: 80  epoch: 132  loss= 0.14597107470035553\n",
            "shadow model: 80  epoch: 133  loss= 0.06487783044576645\n",
            "shadow model: 80  epoch: 134  loss= 0.04224472492933273\n",
            "shadow model: 80  epoch: 135  loss= 0.025139233097434044\n",
            "shadow model: 80  epoch: 136  loss= 0.08305612206459045\n",
            "shadow model: 80  epoch: 137  loss= 0.03575008362531662\n",
            "shadow model: 80  epoch: 138  loss= 0.09826786816120148\n",
            "shadow model: 80  epoch: 139  loss= 0.0459246002137661\n",
            "shadow model: 80  epoch: 140  loss= 0.07831453531980515\n",
            "shadow model: 80  epoch: 141  loss= 0.05634206160902977\n",
            "shadow model: 80  epoch: 142  loss= 0.07994679361581802\n",
            "shadow model: 80  epoch: 143  loss= 0.01717008650302887\n",
            "shadow model: 80  epoch: 144  loss= 0.07487015426158905\n",
            "shadow model: 80  epoch: 145  loss= 0.058798495680093765\n",
            "shadow model: 80  epoch: 146  loss= 0.0536961704492569\n",
            "shadow model: 80  epoch: 147  loss= 0.07992678880691528\n",
            "shadow model: 80  epoch: 148  loss= 0.02506740391254425\n",
            "shadow model: 80  epoch: 149  loss= 0.08887121826410294\n",
            "\n",
            "shadow model: 81  epoch: 0  loss= 2.269181728363037\n",
            "shadow model: 81  epoch: 1  loss= 2.1894869804382324\n",
            "shadow model: 81  epoch: 2  loss= 2.0720443725585938\n",
            "shadow model: 81  epoch: 3  loss= 2.1132609844207764\n",
            "shadow model: 81  epoch: 4  loss= 2.0064759254455566\n",
            "shadow model: 81  epoch: 5  loss= 1.973892092704773\n",
            "shadow model: 81  epoch: 6  loss= 1.8960292339324951\n",
            "shadow model: 81  epoch: 7  loss= 1.9476906061172485\n",
            "shadow model: 81  epoch: 8  loss= 1.786687970161438\n",
            "shadow model: 81  epoch: 9  loss= 1.7296198606491089\n",
            "shadow model: 81  epoch: 10  loss= 1.7158516645431519\n",
            "shadow model: 81  epoch: 11  loss= 1.742613434791565\n",
            "shadow model: 81  epoch: 12  loss= 1.4280089139938354\n",
            "shadow model: 81  epoch: 13  loss= 1.5656852722167969\n",
            "shadow model: 81  epoch: 14  loss= 1.339040756225586\n",
            "shadow model: 81  epoch: 15  loss= 1.373274803161621\n",
            "shadow model: 81  epoch: 16  loss= 1.328266978263855\n",
            "shadow model: 81  epoch: 17  loss= 1.2201777696609497\n",
            "shadow model: 81  epoch: 18  loss= 0.9857796430587769\n",
            "shadow model: 81  epoch: 19  loss= 1.1138403415679932\n",
            "shadow model: 81  epoch: 20  loss= 0.979754626750946\n",
            "shadow model: 81  epoch: 21  loss= 1.0840961933135986\n",
            "shadow model: 81  epoch: 22  loss= 1.1534903049468994\n",
            "shadow model: 81  epoch: 23  loss= 1.0815528631210327\n",
            "shadow model: 81  epoch: 24  loss= 0.9248825311660767\n",
            "shadow model: 81  epoch: 25  loss= 0.8916717767715454\n",
            "shadow model: 81  epoch: 26  loss= 1.162642240524292\n",
            "shadow model: 81  epoch: 27  loss= 0.7300415635108948\n",
            "shadow model: 81  epoch: 28  loss= 0.815950334072113\n",
            "shadow model: 81  epoch: 29  loss= 0.684175431728363\n",
            "shadow model: 81  epoch: 30  loss= 0.5299833416938782\n",
            "shadow model: 81  epoch: 31  loss= 0.49418333172798157\n",
            "shadow model: 81  epoch: 32  loss= 0.6992814540863037\n",
            "shadow model: 81  epoch: 33  loss= 0.46413329243659973\n",
            "shadow model: 81  epoch: 34  loss= 0.49540868401527405\n",
            "shadow model: 81  epoch: 35  loss= 0.5828098058700562\n",
            "shadow model: 81  epoch: 36  loss= 0.6961814761161804\n",
            "shadow model: 81  epoch: 37  loss= 0.37012219429016113\n",
            "shadow model: 81  epoch: 38  loss= 0.4541434347629547\n",
            "shadow model: 81  epoch: 39  loss= 0.4730627238750458\n",
            "shadow model: 81  epoch: 40  loss= 0.4529663622379303\n",
            "shadow model: 81  epoch: 41  loss= 0.5153229236602783\n",
            "shadow model: 81  epoch: 42  loss= 0.36916470527648926\n",
            "shadow model: 81  epoch: 43  loss= 0.44234699010849\n",
            "shadow model: 81  epoch: 44  loss= 0.38530775904655457\n",
            "shadow model: 81  epoch: 45  loss= 0.30657628178596497\n",
            "shadow model: 81  epoch: 46  loss= 0.28729352355003357\n",
            "shadow model: 81  epoch: 47  loss= 0.4404204487800598\n",
            "shadow model: 81  epoch: 48  loss= 0.4192981719970703\n",
            "shadow model: 81  epoch: 49  loss= 0.4322963058948517\n",
            "shadow model: 81  epoch: 50  loss= 0.32958367466926575\n",
            "shadow model: 81  epoch: 51  loss= 0.21946264803409576\n",
            "shadow model: 81  epoch: 52  loss= 0.1769103854894638\n",
            "shadow model: 81  epoch: 53  loss= 0.11855802685022354\n",
            "shadow model: 81  epoch: 54  loss= 0.15928839147090912\n",
            "shadow model: 81  epoch: 55  loss= 0.2251080572605133\n",
            "shadow model: 81  epoch: 56  loss= 0.1442612260580063\n",
            "shadow model: 81  epoch: 57  loss= 0.21721358597278595\n",
            "shadow model: 81  epoch: 58  loss= 0.17355148494243622\n",
            "shadow model: 81  epoch: 59  loss= 0.16567204892635345\n",
            "shadow model: 81  epoch: 60  loss= 0.1850929856300354\n",
            "shadow model: 81  epoch: 61  loss= 0.33261924982070923\n",
            "shadow model: 81  epoch: 62  loss= 0.15105938911437988\n",
            "shadow model: 81  epoch: 63  loss= 0.2084621787071228\n",
            "shadow model: 81  epoch: 64  loss= 0.26173844933509827\n",
            "shadow model: 81  epoch: 65  loss= 0.26866841316223145\n",
            "shadow model: 81  epoch: 66  loss= 0.13938292860984802\n",
            "shadow model: 81  epoch: 67  loss= 0.21351364254951477\n",
            "shadow model: 81  epoch: 68  loss= 0.1841251701116562\n",
            "shadow model: 81  epoch: 69  loss= 0.15152549743652344\n",
            "shadow model: 81  epoch: 70  loss= 0.185321643948555\n",
            "shadow model: 81  epoch: 71  loss= 0.2501610815525055\n",
            "shadow model: 81  epoch: 72  loss= 0.10528648644685745\n",
            "shadow model: 81  epoch: 73  loss= 0.14554204046726227\n",
            "shadow model: 81  epoch: 74  loss= 0.3609723150730133\n",
            "shadow model: 81  epoch: 75  loss= 0.24022206664085388\n",
            "shadow model: 81  epoch: 76  loss= 0.12165249139070511\n",
            "shadow model: 81  epoch: 77  loss= 0.10142609477043152\n",
            "shadow model: 81  epoch: 78  loss= 0.1132904514670372\n",
            "shadow model: 81  epoch: 79  loss= 0.11570855975151062\n",
            "shadow model: 81  epoch: 80  loss= 0.14443664252758026\n",
            "shadow model: 81  epoch: 81  loss= 0.1616985946893692\n",
            "shadow model: 81  epoch: 82  loss= 0.13890738785266876\n",
            "shadow model: 81  epoch: 83  loss= 0.09971001744270325\n",
            "shadow model: 81  epoch: 84  loss= 0.13181905448436737\n",
            "shadow model: 81  epoch: 85  loss= 0.15415863692760468\n",
            "shadow model: 81  epoch: 86  loss= 0.10057240724563599\n",
            "shadow model: 81  epoch: 87  loss= 0.10863136500120163\n",
            "shadow model: 81  epoch: 88  loss= 0.1567838191986084\n",
            "shadow model: 81  epoch: 89  loss= 0.05463283136487007\n",
            "shadow model: 81  epoch: 90  loss= 0.18779520690441132\n",
            "shadow model: 81  epoch: 91  loss= 0.15611234307289124\n",
            "shadow model: 81  epoch: 92  loss= 0.2531341016292572\n",
            "shadow model: 81  epoch: 93  loss= 0.13793538510799408\n",
            "shadow model: 81  epoch: 94  loss= 0.2446192055940628\n",
            "shadow model: 81  epoch: 95  loss= 0.047901738435029984\n",
            "shadow model: 81  epoch: 96  loss= 0.11751386523246765\n",
            "shadow model: 81  epoch: 97  loss= 0.12674544751644135\n",
            "shadow model: 81  epoch: 98  loss= 0.17936167120933533\n",
            "shadow model: 81  epoch: 99  loss= 0.21221686899662018\n",
            "shadow model: 81  epoch: 100  loss= 0.11398688703775406\n",
            "shadow model: 81  epoch: 101  loss= 0.15742066502571106\n",
            "shadow model: 81  epoch: 102  loss= 0.1051303818821907\n",
            "shadow model: 81  epoch: 103  loss= 0.2693028748035431\n",
            "shadow model: 81  epoch: 104  loss= 0.1854007989168167\n",
            "shadow model: 81  epoch: 105  loss= 0.07728368043899536\n",
            "shadow model: 81  epoch: 106  loss= 0.0530204139649868\n",
            "shadow model: 81  epoch: 107  loss= 0.12138791382312775\n",
            "shadow model: 81  epoch: 108  loss= 0.11118435859680176\n",
            "shadow model: 81  epoch: 109  loss= 0.16142161190509796\n",
            "shadow model: 81  epoch: 110  loss= 0.0905771255493164\n",
            "shadow model: 81  epoch: 111  loss= 0.04829136282205582\n",
            "shadow model: 81  epoch: 112  loss= 0.09535669535398483\n",
            "shadow model: 81  epoch: 113  loss= 0.006443284917622805\n",
            "shadow model: 81  epoch: 114  loss= 0.10725953429937363\n",
            "shadow model: 81  epoch: 115  loss= 0.15761597454547882\n",
            "shadow model: 81  epoch: 116  loss= 0.1831190139055252\n",
            "shadow model: 81  epoch: 117  loss= 0.10804655402898788\n",
            "shadow model: 81  epoch: 118  loss= 0.035777099430561066\n",
            "shadow model: 81  epoch: 119  loss= 0.049878109246492386\n",
            "shadow model: 81  epoch: 120  loss= 0.06720945984125137\n",
            "shadow model: 81  epoch: 121  loss= 0.10068342834711075\n",
            "shadow model: 81  epoch: 122  loss= 0.11724313348531723\n",
            "shadow model: 81  epoch: 123  loss= 0.021031463518738747\n",
            "shadow model: 81  epoch: 124  loss= 0.06862790137529373\n",
            "shadow model: 81  epoch: 125  loss= 0.036718204617500305\n",
            "shadow model: 81  epoch: 126  loss= 0.07575858384370804\n",
            "shadow model: 81  epoch: 127  loss= 0.12932203710079193\n",
            "shadow model: 81  epoch: 128  loss= 0.05418940261006355\n",
            "shadow model: 81  epoch: 129  loss= 0.13293826580047607\n",
            "shadow model: 81  epoch: 130  loss= 0.14258155226707458\n",
            "shadow model: 81  epoch: 131  loss= 0.11333904415369034\n",
            "shadow model: 81  epoch: 132  loss= 0.03120323084294796\n",
            "shadow model: 81  epoch: 133  loss= 0.026923684403300285\n",
            "shadow model: 81  epoch: 134  loss= 0.07036793231964111\n",
            "shadow model: 81  epoch: 135  loss= 0.03958015516400337\n",
            "shadow model: 81  epoch: 136  loss= 0.04080387204885483\n",
            "shadow model: 81  epoch: 137  loss= 0.11894673854112625\n",
            "shadow model: 81  epoch: 138  loss= 0.10386480391025543\n",
            "shadow model: 81  epoch: 139  loss= 0.027814777567982674\n",
            "shadow model: 81  epoch: 140  loss= 0.10374649614095688\n",
            "shadow model: 81  epoch: 141  loss= 0.021751344203948975\n",
            "shadow model: 81  epoch: 142  loss= 0.026145154610276222\n",
            "shadow model: 81  epoch: 143  loss= 0.09831349551677704\n",
            "shadow model: 81  epoch: 144  loss= 0.09646876901388168\n",
            "shadow model: 81  epoch: 145  loss= 0.012095523066818714\n",
            "shadow model: 81  epoch: 146  loss= 0.0969955176115036\n",
            "shadow model: 81  epoch: 147  loss= 0.08192061632871628\n",
            "shadow model: 81  epoch: 148  loss= 0.04776541143655777\n",
            "shadow model: 81  epoch: 149  loss= 0.06526200473308563\n",
            "\n",
            "shadow model: 82  epoch: 0  loss= 2.3280537128448486\n",
            "shadow model: 82  epoch: 1  loss= 2.2438323497772217\n",
            "shadow model: 82  epoch: 2  loss= 2.1668102741241455\n",
            "shadow model: 82  epoch: 3  loss= 2.1730453968048096\n",
            "shadow model: 82  epoch: 4  loss= 2.07926869392395\n",
            "shadow model: 82  epoch: 5  loss= 1.9864031076431274\n",
            "shadow model: 82  epoch: 6  loss= 1.8567225933074951\n",
            "shadow model: 82  epoch: 7  loss= 1.9139683246612549\n",
            "shadow model: 82  epoch: 8  loss= 1.808456301689148\n",
            "shadow model: 82  epoch: 9  loss= 1.6749534606933594\n",
            "shadow model: 82  epoch: 10  loss= 1.580122947692871\n",
            "shadow model: 82  epoch: 11  loss= 1.734384298324585\n",
            "shadow model: 82  epoch: 12  loss= 1.610461711883545\n",
            "shadow model: 82  epoch: 13  loss= 1.4516851902008057\n",
            "shadow model: 82  epoch: 14  loss= 1.4646810293197632\n",
            "shadow model: 82  epoch: 15  loss= 1.3567407131195068\n",
            "shadow model: 82  epoch: 16  loss= 1.3512367010116577\n",
            "shadow model: 82  epoch: 17  loss= 1.2880046367645264\n",
            "shadow model: 82  epoch: 18  loss= 1.2062311172485352\n",
            "shadow model: 82  epoch: 19  loss= 1.125160813331604\n",
            "shadow model: 82  epoch: 20  loss= 0.9808957576751709\n",
            "shadow model: 82  epoch: 21  loss= 0.8820982575416565\n",
            "shadow model: 82  epoch: 22  loss= 0.9399837255477905\n",
            "shadow model: 82  epoch: 23  loss= 0.9995923042297363\n",
            "shadow model: 82  epoch: 24  loss= 0.9986616373062134\n",
            "shadow model: 82  epoch: 25  loss= 0.9684056639671326\n",
            "shadow model: 82  epoch: 26  loss= 0.9316384792327881\n",
            "shadow model: 82  epoch: 27  loss= 0.6046671867370605\n",
            "shadow model: 82  epoch: 28  loss= 0.6753506660461426\n",
            "shadow model: 82  epoch: 29  loss= 0.5624667406082153\n",
            "shadow model: 82  epoch: 30  loss= 0.5902023911476135\n",
            "shadow model: 82  epoch: 31  loss= 0.6993184089660645\n",
            "shadow model: 82  epoch: 32  loss= 0.6083993315696716\n",
            "shadow model: 82  epoch: 33  loss= 0.41635510325431824\n",
            "shadow model: 82  epoch: 34  loss= 0.4235764741897583\n",
            "shadow model: 82  epoch: 35  loss= 0.6131309270858765\n",
            "shadow model: 82  epoch: 36  loss= 0.45100975036621094\n",
            "shadow model: 82  epoch: 37  loss= 0.43917542695999146\n",
            "shadow model: 82  epoch: 38  loss= 0.6588431000709534\n",
            "shadow model: 82  epoch: 39  loss= 0.39677155017852783\n",
            "shadow model: 82  epoch: 40  loss= 0.4819220304489136\n",
            "shadow model: 82  epoch: 41  loss= 0.3502027690410614\n",
            "shadow model: 82  epoch: 42  loss= 0.28460949659347534\n",
            "shadow model: 82  epoch: 43  loss= 0.3023277223110199\n",
            "shadow model: 82  epoch: 44  loss= 0.37542256712913513\n",
            "shadow model: 82  epoch: 45  loss= 0.5165061354637146\n",
            "shadow model: 82  epoch: 46  loss= 0.33975130319595337\n",
            "shadow model: 82  epoch: 47  loss= 0.20587587356567383\n",
            "shadow model: 82  epoch: 48  loss= 0.4060247242450714\n",
            "shadow model: 82  epoch: 49  loss= 0.4251856505870819\n",
            "shadow model: 82  epoch: 50  loss= 0.538785457611084\n",
            "shadow model: 82  epoch: 51  loss= 0.3779248893260956\n",
            "shadow model: 82  epoch: 52  loss= 0.2376570850610733\n",
            "shadow model: 82  epoch: 53  loss= 0.2495615929365158\n",
            "shadow model: 82  epoch: 54  loss= 0.2876967489719391\n",
            "shadow model: 82  epoch: 55  loss= 0.3649698793888092\n",
            "shadow model: 82  epoch: 56  loss= 0.28601911664009094\n",
            "shadow model: 82  epoch: 57  loss= 0.1744072139263153\n",
            "shadow model: 82  epoch: 58  loss= 0.3706636428833008\n",
            "shadow model: 82  epoch: 59  loss= 0.28925999999046326\n",
            "shadow model: 82  epoch: 60  loss= 0.18058770895004272\n",
            "shadow model: 82  epoch: 61  loss= 0.15574422478675842\n",
            "shadow model: 82  epoch: 62  loss= 0.31801214814186096\n",
            "shadow model: 82  epoch: 63  loss= 0.2064039409160614\n",
            "shadow model: 82  epoch: 64  loss= 0.15624143183231354\n",
            "shadow model: 82  epoch: 65  loss= 0.29890742897987366\n",
            "shadow model: 82  epoch: 66  loss= 0.19481848180294037\n",
            "shadow model: 82  epoch: 67  loss= 0.3078867495059967\n",
            "shadow model: 82  epoch: 68  loss= 0.275362491607666\n",
            "shadow model: 82  epoch: 69  loss= 0.18015581369400024\n",
            "shadow model: 82  epoch: 70  loss= 0.225293830037117\n",
            "shadow model: 82  epoch: 71  loss= 0.24457353353500366\n",
            "shadow model: 82  epoch: 72  loss= 0.2145807445049286\n",
            "shadow model: 82  epoch: 73  loss= 0.23803293704986572\n",
            "shadow model: 82  epoch: 74  loss= 0.13145363330841064\n",
            "shadow model: 82  epoch: 75  loss= 0.19301201403141022\n",
            "shadow model: 82  epoch: 76  loss= 0.06441132724285126\n",
            "shadow model: 82  epoch: 77  loss= 0.07483271509408951\n",
            "shadow model: 82  epoch: 78  loss= 0.14662571251392365\n",
            "shadow model: 82  epoch: 79  loss= 0.16677197813987732\n",
            "shadow model: 82  epoch: 80  loss= 0.28928831219673157\n",
            "shadow model: 82  epoch: 81  loss= 0.16660648584365845\n",
            "shadow model: 82  epoch: 82  loss= 0.052167538553476334\n",
            "shadow model: 82  epoch: 83  loss= 0.06678009033203125\n",
            "shadow model: 82  epoch: 84  loss= 0.0844414159655571\n",
            "shadow model: 82  epoch: 85  loss= 0.12039046734571457\n",
            "shadow model: 82  epoch: 86  loss= 0.15046565234661102\n",
            "shadow model: 82  epoch: 87  loss= 0.1394456923007965\n",
            "shadow model: 82  epoch: 88  loss= 0.12620200216770172\n",
            "shadow model: 82  epoch: 89  loss= 0.0738159716129303\n",
            "shadow model: 82  epoch: 90  loss= 0.1834748089313507\n",
            "shadow model: 82  epoch: 91  loss= 0.19539770483970642\n",
            "shadow model: 82  epoch: 92  loss= 0.13997206091880798\n",
            "shadow model: 82  epoch: 93  loss= 0.20072469115257263\n",
            "shadow model: 82  epoch: 94  loss= 0.19359949231147766\n",
            "shadow model: 82  epoch: 95  loss= 0.2276652604341507\n",
            "shadow model: 82  epoch: 96  loss= 0.13951298594474792\n",
            "shadow model: 82  epoch: 97  loss= 0.10341644287109375\n",
            "shadow model: 82  epoch: 98  loss= 0.1579057276248932\n",
            "shadow model: 82  epoch: 99  loss= 0.17604121565818787\n",
            "shadow model: 82  epoch: 100  loss= 0.10678955912590027\n",
            "shadow model: 82  epoch: 101  loss= 0.17129841446876526\n",
            "shadow model: 82  epoch: 102  loss= 0.09353738278150558\n",
            "shadow model: 82  epoch: 103  loss= 0.10089357197284698\n",
            "shadow model: 82  epoch: 104  loss= 0.2153310328722\n",
            "shadow model: 82  epoch: 105  loss= 0.188872292637825\n",
            "shadow model: 82  epoch: 106  loss= 0.06921244412660599\n",
            "shadow model: 82  epoch: 107  loss= 0.17610915005207062\n",
            "shadow model: 82  epoch: 108  loss= 0.1284274160861969\n",
            "shadow model: 82  epoch: 109  loss= 0.14875593781471252\n",
            "shadow model: 82  epoch: 110  loss= 0.14716213941574097\n",
            "shadow model: 82  epoch: 111  loss= 0.08108232170343399\n",
            "shadow model: 82  epoch: 112  loss= 0.05727245658636093\n",
            "shadow model: 82  epoch: 113  loss= 0.2574200928211212\n",
            "shadow model: 82  epoch: 114  loss= 0.046281494200229645\n",
            "shadow model: 82  epoch: 115  loss= 0.12312786281108856\n",
            "shadow model: 82  epoch: 116  loss= 0.0755811557173729\n",
            "shadow model: 82  epoch: 117  loss= 0.10428986698389053\n",
            "shadow model: 82  epoch: 118  loss= 0.1064760684967041\n",
            "shadow model: 82  epoch: 119  loss= 0.0790233314037323\n",
            "shadow model: 82  epoch: 120  loss= 0.1657724529504776\n",
            "shadow model: 82  epoch: 121  loss= 0.10824408382177353\n",
            "shadow model: 82  epoch: 122  loss= 0.11392752826213837\n",
            "shadow model: 82  epoch: 123  loss= 0.11553183943033218\n",
            "shadow model: 82  epoch: 124  loss= 0.04722867161035538\n",
            "shadow model: 82  epoch: 125  loss= 0.13004915416240692\n",
            "shadow model: 82  epoch: 126  loss= 0.1268550306558609\n",
            "shadow model: 82  epoch: 127  loss= 0.039775121957063675\n",
            "shadow model: 82  epoch: 128  loss= 0.14818115532398224\n",
            "shadow model: 82  epoch: 129  loss= 0.06677993386983871\n",
            "shadow model: 82  epoch: 130  loss= 0.05255771800875664\n",
            "shadow model: 82  epoch: 131  loss= 0.18903648853302002\n",
            "shadow model: 82  epoch: 132  loss= 0.07436960935592651\n",
            "shadow model: 82  epoch: 133  loss= 0.11880512535572052\n",
            "shadow model: 82  epoch: 134  loss= 0.13225440680980682\n",
            "shadow model: 82  epoch: 135  loss= 0.04044923186302185\n",
            "shadow model: 82  epoch: 136  loss= 0.15176093578338623\n",
            "shadow model: 82  epoch: 137  loss= 0.12456407397985458\n",
            "shadow model: 82  epoch: 138  loss= 0.0925976112484932\n",
            "shadow model: 82  epoch: 139  loss= 0.11599572747945786\n",
            "shadow model: 82  epoch: 140  loss= 0.050304070115089417\n",
            "shadow model: 82  epoch: 141  loss= 0.0769241452217102\n",
            "shadow model: 82  epoch: 142  loss= 0.15178997814655304\n",
            "shadow model: 82  epoch: 143  loss= 0.12013643980026245\n",
            "shadow model: 82  epoch: 144  loss= 0.0743444412946701\n",
            "shadow model: 82  epoch: 145  loss= 0.11116854101419449\n",
            "shadow model: 82  epoch: 146  loss= 0.18376627564430237\n",
            "shadow model: 82  epoch: 147  loss= 0.08373882621526718\n",
            "shadow model: 82  epoch: 148  loss= 0.17313948273658752\n",
            "shadow model: 82  epoch: 149  loss= 0.0974951758980751\n",
            "\n",
            "shadow model: 83  epoch: 0  loss= 2.311434268951416\n",
            "shadow model: 83  epoch: 1  loss= 2.310389995574951\n",
            "shadow model: 83  epoch: 2  loss= 2.2223267555236816\n",
            "shadow model: 83  epoch: 3  loss= 2.2312631607055664\n",
            "shadow model: 83  epoch: 4  loss= 1.9921433925628662\n",
            "shadow model: 83  epoch: 5  loss= 1.9934964179992676\n",
            "shadow model: 83  epoch: 6  loss= 1.8139731884002686\n",
            "shadow model: 83  epoch: 7  loss= 1.7887095212936401\n",
            "shadow model: 83  epoch: 8  loss= 1.8258641958236694\n",
            "shadow model: 83  epoch: 9  loss= 1.7384157180786133\n",
            "shadow model: 83  epoch: 10  loss= 1.6650985479354858\n",
            "shadow model: 83  epoch: 11  loss= 1.6721004247665405\n",
            "shadow model: 83  epoch: 12  loss= 1.5616668462753296\n",
            "shadow model: 83  epoch: 13  loss= 1.4819221496582031\n",
            "shadow model: 83  epoch: 14  loss= 1.4641937017440796\n",
            "shadow model: 83  epoch: 15  loss= 1.4719589948654175\n",
            "shadow model: 83  epoch: 16  loss= 1.1714626550674438\n",
            "shadow model: 83  epoch: 17  loss= 1.1332659721374512\n",
            "shadow model: 83  epoch: 18  loss= 1.180038571357727\n",
            "shadow model: 83  epoch: 19  loss= 1.0427141189575195\n",
            "shadow model: 83  epoch: 20  loss= 1.036496877670288\n",
            "shadow model: 83  epoch: 21  loss= 1.117602825164795\n",
            "shadow model: 83  epoch: 22  loss= 1.0449198484420776\n",
            "shadow model: 83  epoch: 23  loss= 0.7527098655700684\n",
            "shadow model: 83  epoch: 24  loss= 0.65635085105896\n",
            "shadow model: 83  epoch: 25  loss= 0.7193715572357178\n",
            "shadow model: 83  epoch: 26  loss= 0.5489530563354492\n",
            "shadow model: 83  epoch: 27  loss= 0.6088163256645203\n",
            "shadow model: 83  epoch: 28  loss= 0.6441017985343933\n",
            "shadow model: 83  epoch: 29  loss= 0.5065096020698547\n",
            "shadow model: 83  epoch: 30  loss= 0.5220410823822021\n",
            "shadow model: 83  epoch: 31  loss= 0.5600980520248413\n",
            "shadow model: 83  epoch: 32  loss= 0.6697616577148438\n",
            "shadow model: 83  epoch: 33  loss= 0.37446528673171997\n",
            "shadow model: 83  epoch: 34  loss= 0.7258874773979187\n",
            "shadow model: 83  epoch: 35  loss= 0.35627812147140503\n",
            "shadow model: 83  epoch: 36  loss= 0.4259016215801239\n",
            "shadow model: 83  epoch: 37  loss= 0.41385653614997864\n",
            "shadow model: 83  epoch: 38  loss= 0.35362234711647034\n",
            "shadow model: 83  epoch: 39  loss= 0.3274148106575012\n",
            "shadow model: 83  epoch: 40  loss= 0.305629163980484\n",
            "shadow model: 83  epoch: 41  loss= 0.3312718868255615\n",
            "shadow model: 83  epoch: 42  loss= 0.2917385697364807\n",
            "shadow model: 83  epoch: 43  loss= 0.2607854902744293\n",
            "shadow model: 83  epoch: 44  loss= 0.27248454093933105\n",
            "shadow model: 83  epoch: 45  loss= 0.43016770482063293\n",
            "shadow model: 83  epoch: 46  loss= 0.2157551795244217\n",
            "shadow model: 83  epoch: 47  loss= 0.46937096118927\n",
            "shadow model: 83  epoch: 48  loss= 0.2773840129375458\n",
            "shadow model: 83  epoch: 49  loss= 0.3383041024208069\n",
            "shadow model: 83  epoch: 50  loss= 0.2398630827665329\n",
            "shadow model: 83  epoch: 51  loss= 0.2060888111591339\n",
            "shadow model: 83  epoch: 52  loss= 0.4689713716506958\n",
            "shadow model: 83  epoch: 53  loss= 0.3019900918006897\n",
            "shadow model: 83  epoch: 54  loss= 0.17320872843265533\n",
            "shadow model: 83  epoch: 55  loss= 0.13270416855812073\n",
            "shadow model: 83  epoch: 56  loss= 0.15402480959892273\n",
            "shadow model: 83  epoch: 57  loss= 0.16438302397727966\n",
            "shadow model: 83  epoch: 58  loss= 0.12382322549819946\n",
            "shadow model: 83  epoch: 59  loss= 0.24294547736644745\n",
            "shadow model: 83  epoch: 60  loss= 0.1331249177455902\n",
            "shadow model: 83  epoch: 61  loss= 0.22705237567424774\n",
            "shadow model: 83  epoch: 62  loss= 0.14574041962623596\n",
            "shadow model: 83  epoch: 63  loss= 0.14241836965084076\n",
            "shadow model: 83  epoch: 64  loss= 0.2798135578632355\n",
            "shadow model: 83  epoch: 65  loss= 0.1632053256034851\n",
            "shadow model: 83  epoch: 66  loss= 0.09774719923734665\n",
            "shadow model: 83  epoch: 67  loss= 0.06934478878974915\n",
            "shadow model: 83  epoch: 68  loss= 0.12465663254261017\n",
            "shadow model: 83  epoch: 69  loss= 0.24245451390743256\n",
            "shadow model: 83  epoch: 70  loss= 0.1329682618379593\n",
            "shadow model: 83  epoch: 71  loss= 0.08005502074956894\n",
            "shadow model: 83  epoch: 72  loss= 0.24938853085041046\n",
            "shadow model: 83  epoch: 73  loss= 0.11806678771972656\n",
            "shadow model: 83  epoch: 74  loss= 0.15355589985847473\n",
            "shadow model: 83  epoch: 75  loss= 0.07611088454723358\n",
            "shadow model: 83  epoch: 76  loss= 0.16121314465999603\n",
            "shadow model: 83  epoch: 77  loss= 0.23219749331474304\n",
            "shadow model: 83  epoch: 78  loss= 0.10214752703905106\n",
            "shadow model: 83  epoch: 79  loss= 0.08443795889616013\n",
            "shadow model: 83  epoch: 80  loss= 0.04450749233365059\n",
            "shadow model: 83  epoch: 81  loss= 0.1665586233139038\n",
            "shadow model: 83  epoch: 82  loss= 0.1524132639169693\n",
            "shadow model: 83  epoch: 83  loss= 0.061489254236221313\n",
            "shadow model: 83  epoch: 84  loss= 0.11283503472805023\n",
            "shadow model: 83  epoch: 85  loss= 0.14932365715503693\n",
            "shadow model: 83  epoch: 86  loss= 0.08702895045280457\n",
            "shadow model: 83  epoch: 87  loss= 0.16413839161396027\n",
            "shadow model: 83  epoch: 88  loss= 0.1384415179491043\n",
            "shadow model: 83  epoch: 89  loss= 0.07922647148370743\n",
            "shadow model: 83  epoch: 90  loss= 0.037883054465055466\n",
            "shadow model: 83  epoch: 91  loss= 0.09181730449199677\n",
            "shadow model: 83  epoch: 92  loss= 0.13073121011257172\n",
            "shadow model: 83  epoch: 93  loss= 0.030100645497441292\n",
            "shadow model: 83  epoch: 94  loss= 0.06813213974237442\n",
            "shadow model: 83  epoch: 95  loss= 0.06970763951539993\n",
            "shadow model: 83  epoch: 96  loss= 0.0905289351940155\n",
            "shadow model: 83  epoch: 97  loss= 0.10296909511089325\n",
            "shadow model: 83  epoch: 98  loss= 0.10830884426832199\n",
            "shadow model: 83  epoch: 99  loss= 0.07637304067611694\n",
            "shadow model: 83  epoch: 100  loss= 0.05922190099954605\n",
            "shadow model: 83  epoch: 101  loss= 0.10920559614896774\n",
            "shadow model: 83  epoch: 102  loss= 0.16966353356838226\n",
            "shadow model: 83  epoch: 103  loss= 0.09424331039190292\n",
            "shadow model: 83  epoch: 104  loss= 0.05877504125237465\n",
            "shadow model: 83  epoch: 105  loss= 0.12571997940540314\n",
            "shadow model: 83  epoch: 106  loss= 0.07474210858345032\n",
            "shadow model: 83  epoch: 107  loss= 0.0727461725473404\n",
            "shadow model: 83  epoch: 108  loss= 0.03178996220231056\n",
            "shadow model: 83  epoch: 109  loss= 0.10482721030712128\n",
            "shadow model: 83  epoch: 110  loss= 0.0721898153424263\n",
            "shadow model: 83  epoch: 111  loss= 0.058745212852954865\n",
            "shadow model: 83  epoch: 112  loss= 0.0790993720293045\n",
            "shadow model: 83  epoch: 113  loss= 0.05654864385724068\n",
            "shadow model: 83  epoch: 114  loss= 0.07574417442083359\n",
            "shadow model: 83  epoch: 115  loss= 0.05986041948199272\n",
            "shadow model: 83  epoch: 116  loss= 0.16447916626930237\n",
            "shadow model: 83  epoch: 117  loss= 0.04945546016097069\n",
            "shadow model: 83  epoch: 118  loss= 0.07614044100046158\n",
            "shadow model: 83  epoch: 119  loss= 0.10775814950466156\n",
            "shadow model: 83  epoch: 120  loss= 0.1388416439294815\n",
            "shadow model: 83  epoch: 121  loss= 0.03154483437538147\n",
            "shadow model: 83  epoch: 122  loss= 0.10068606585264206\n",
            "shadow model: 83  epoch: 123  loss= 0.13000664114952087\n",
            "shadow model: 83  epoch: 124  loss= 0.06808645278215408\n",
            "shadow model: 83  epoch: 125  loss= 0.06594589352607727\n",
            "shadow model: 83  epoch: 126  loss= 0.05133358761668205\n",
            "shadow model: 83  epoch: 127  loss= 0.02057717554271221\n",
            "shadow model: 83  epoch: 128  loss= 0.08793976902961731\n",
            "shadow model: 83  epoch: 129  loss= 0.08310766518115997\n",
            "shadow model: 83  epoch: 130  loss= 0.08813627064228058\n",
            "shadow model: 83  epoch: 131  loss= 0.03647314012050629\n",
            "shadow model: 83  epoch: 132  loss= 0.08767340332269669\n",
            "shadow model: 83  epoch: 133  loss= 0.050110336393117905\n",
            "shadow model: 83  epoch: 134  loss= 0.0899205431342125\n",
            "shadow model: 83  epoch: 135  loss= 0.04504767060279846\n",
            "shadow model: 83  epoch: 136  loss= 0.18108797073364258\n",
            "shadow model: 83  epoch: 137  loss= 0.04015252739191055\n",
            "shadow model: 83  epoch: 138  loss= 0.050929732620716095\n",
            "shadow model: 83  epoch: 139  loss= 0.01812281645834446\n",
            "shadow model: 83  epoch: 140  loss= 0.04636497423052788\n",
            "shadow model: 83  epoch: 141  loss= 0.045448966324329376\n",
            "shadow model: 83  epoch: 142  loss= 0.08271995186805725\n",
            "shadow model: 83  epoch: 143  loss= 0.03198179602622986\n",
            "shadow model: 83  epoch: 144  loss= 0.041094955056905746\n",
            "shadow model: 83  epoch: 145  loss= 0.09134005755186081\n",
            "shadow model: 83  epoch: 146  loss= 0.08944888412952423\n",
            "shadow model: 83  epoch: 147  loss= 0.02147522382438183\n",
            "shadow model: 83  epoch: 148  loss= 0.11225172877311707\n",
            "shadow model: 83  epoch: 149  loss= 0.07322198152542114\n",
            "\n",
            "shadow model: 84  epoch: 0  loss= 2.315884828567505\n",
            "shadow model: 84  epoch: 1  loss= 2.283616065979004\n",
            "shadow model: 84  epoch: 2  loss= 2.2349581718444824\n",
            "shadow model: 84  epoch: 3  loss= 2.2399790287017822\n",
            "shadow model: 84  epoch: 4  loss= 2.1479876041412354\n",
            "shadow model: 84  epoch: 5  loss= 2.0714054107666016\n",
            "shadow model: 84  epoch: 6  loss= 1.8400152921676636\n",
            "shadow model: 84  epoch: 7  loss= 1.915381669998169\n",
            "shadow model: 84  epoch: 8  loss= 1.8850020170211792\n",
            "shadow model: 84  epoch: 9  loss= 1.9201122522354126\n",
            "shadow model: 84  epoch: 10  loss= 1.8537155389785767\n",
            "shadow model: 84  epoch: 11  loss= 1.5823471546173096\n",
            "shadow model: 84  epoch: 12  loss= 1.6980180740356445\n",
            "shadow model: 84  epoch: 13  loss= 1.5986077785491943\n",
            "shadow model: 84  epoch: 14  loss= 1.2735217809677124\n",
            "shadow model: 84  epoch: 15  loss= 1.5271872282028198\n",
            "shadow model: 84  epoch: 16  loss= 1.2073328495025635\n",
            "shadow model: 84  epoch: 17  loss= 1.2243812084197998\n",
            "shadow model: 84  epoch: 18  loss= 1.280727505683899\n",
            "shadow model: 84  epoch: 19  loss= 1.1107771396636963\n",
            "shadow model: 84  epoch: 20  loss= 1.0101613998413086\n",
            "shadow model: 84  epoch: 21  loss= 1.0785112380981445\n",
            "shadow model: 84  epoch: 22  loss= 0.9135865569114685\n",
            "shadow model: 84  epoch: 23  loss= 1.0288678407669067\n",
            "shadow model: 84  epoch: 24  loss= 0.9994339346885681\n",
            "shadow model: 84  epoch: 25  loss= 0.8142045736312866\n",
            "shadow model: 84  epoch: 26  loss= 0.9600022435188293\n",
            "shadow model: 84  epoch: 27  loss= 0.9194055795669556\n",
            "shadow model: 84  epoch: 28  loss= 0.5894604921340942\n",
            "shadow model: 84  epoch: 29  loss= 0.8013197779655457\n",
            "shadow model: 84  epoch: 30  loss= 0.5825284719467163\n",
            "shadow model: 84  epoch: 31  loss= 0.5088968873023987\n",
            "shadow model: 84  epoch: 32  loss= 0.6875401139259338\n",
            "shadow model: 84  epoch: 33  loss= 0.5453306436538696\n",
            "shadow model: 84  epoch: 34  loss= 0.661730170249939\n",
            "shadow model: 84  epoch: 35  loss= 0.57452791929245\n",
            "shadow model: 84  epoch: 36  loss= 0.35023024678230286\n",
            "shadow model: 84  epoch: 37  loss= 0.45656412839889526\n",
            "shadow model: 84  epoch: 38  loss= 0.4286896288394928\n",
            "shadow model: 84  epoch: 39  loss= 0.35208287835121155\n",
            "shadow model: 84  epoch: 40  loss= 0.38748982548713684\n",
            "shadow model: 84  epoch: 41  loss= 0.21321697533130646\n",
            "shadow model: 84  epoch: 42  loss= 0.369318425655365\n",
            "shadow model: 84  epoch: 43  loss= 0.3553311228752136\n",
            "shadow model: 84  epoch: 44  loss= 0.32858753204345703\n",
            "shadow model: 84  epoch: 45  loss= 0.3864673674106598\n",
            "shadow model: 84  epoch: 46  loss= 0.38927897810935974\n",
            "shadow model: 84  epoch: 47  loss= 0.3516935408115387\n",
            "shadow model: 84  epoch: 48  loss= 0.2186218947172165\n",
            "shadow model: 84  epoch: 49  loss= 0.25305184721946716\n",
            "shadow model: 84  epoch: 50  loss= 0.2728922963142395\n",
            "shadow model: 84  epoch: 51  loss= 0.10359836369752884\n",
            "shadow model: 84  epoch: 52  loss= 0.30243614315986633\n",
            "shadow model: 84  epoch: 53  loss= 0.1910548210144043\n",
            "shadow model: 84  epoch: 54  loss= 0.26827242970466614\n",
            "shadow model: 84  epoch: 55  loss= 0.2973337471485138\n",
            "shadow model: 84  epoch: 56  loss= 0.16653825342655182\n",
            "shadow model: 84  epoch: 57  loss= 0.20727503299713135\n",
            "shadow model: 84  epoch: 58  loss= 0.1612837165594101\n",
            "shadow model: 84  epoch: 59  loss= 0.1850784718990326\n",
            "shadow model: 84  epoch: 60  loss= 0.2521362006664276\n",
            "shadow model: 84  epoch: 61  loss= 0.23518550395965576\n",
            "shadow model: 84  epoch: 62  loss= 0.3280530869960785\n",
            "shadow model: 84  epoch: 63  loss= 0.13142147660255432\n",
            "shadow model: 84  epoch: 64  loss= 0.14589987695217133\n",
            "shadow model: 84  epoch: 65  loss= 0.1924109011888504\n",
            "shadow model: 84  epoch: 66  loss= 0.21077631413936615\n",
            "shadow model: 84  epoch: 67  loss= 0.380042165517807\n",
            "shadow model: 84  epoch: 68  loss= 0.13621267676353455\n",
            "shadow model: 84  epoch: 69  loss= 0.13187900185585022\n",
            "shadow model: 84  epoch: 70  loss= 0.19224192202091217\n",
            "shadow model: 84  epoch: 71  loss= 0.17996326088905334\n",
            "shadow model: 84  epoch: 72  loss= 0.1986745297908783\n",
            "shadow model: 84  epoch: 73  loss= 0.11427859961986542\n",
            "shadow model: 84  epoch: 74  loss= 0.11963795870542526\n",
            "shadow model: 84  epoch: 75  loss= 0.18933159112930298\n",
            "shadow model: 84  epoch: 76  loss= 0.0877072885632515\n",
            "shadow model: 84  epoch: 77  loss= 0.0997808575630188\n",
            "shadow model: 84  epoch: 78  loss= 0.150696262717247\n",
            "shadow model: 84  epoch: 79  loss= 0.1429014354944229\n",
            "shadow model: 84  epoch: 80  loss= 0.10882751643657684\n",
            "shadow model: 84  epoch: 81  loss= 0.0537821426987648\n",
            "shadow model: 84  epoch: 82  loss= 0.021468641236424446\n",
            "shadow model: 84  epoch: 83  loss= 0.11626631021499634\n",
            "shadow model: 84  epoch: 84  loss= 0.09085234254598618\n",
            "shadow model: 84  epoch: 85  loss= 0.10058192908763885\n",
            "shadow model: 84  epoch: 86  loss= 0.07842779904603958\n",
            "shadow model: 84  epoch: 87  loss= 0.045438263565301895\n",
            "shadow model: 84  epoch: 88  loss= 0.10315192490816116\n",
            "shadow model: 84  epoch: 89  loss= 0.12117115408182144\n",
            "shadow model: 84  epoch: 90  loss= 0.11668563634157181\n",
            "shadow model: 84  epoch: 91  loss= 0.15418682992458344\n",
            "shadow model: 84  epoch: 92  loss= 0.07261396944522858\n",
            "shadow model: 84  epoch: 93  loss= 0.0713195875287056\n",
            "shadow model: 84  epoch: 94  loss= 0.15709428489208221\n",
            "shadow model: 84  epoch: 95  loss= 0.05952024832367897\n",
            "shadow model: 84  epoch: 96  loss= 0.06788342446088791\n",
            "shadow model: 84  epoch: 97  loss= 0.0735672190785408\n",
            "shadow model: 84  epoch: 98  loss= 0.09196194261312485\n",
            "shadow model: 84  epoch: 99  loss= 0.1725783348083496\n",
            "shadow model: 84  epoch: 100  loss= 0.05790922790765762\n",
            "shadow model: 84  epoch: 101  loss= 0.13826215267181396\n",
            "shadow model: 84  epoch: 102  loss= 0.07694285362958908\n",
            "shadow model: 84  epoch: 103  loss= 0.15902985632419586\n",
            "shadow model: 84  epoch: 104  loss= 0.08278782665729523\n",
            "shadow model: 84  epoch: 105  loss= 0.07066803425550461\n",
            "shadow model: 84  epoch: 106  loss= 0.12034803628921509\n",
            "shadow model: 84  epoch: 107  loss= 0.07614291459321976\n",
            "shadow model: 84  epoch: 108  loss= 0.08124331384897232\n",
            "shadow model: 84  epoch: 109  loss= 0.04940247908234596\n",
            "shadow model: 84  epoch: 110  loss= 0.08435747772455215\n",
            "shadow model: 84  epoch: 111  loss= 0.10851936787366867\n",
            "shadow model: 84  epoch: 112  loss= 0.04709811136126518\n",
            "shadow model: 84  epoch: 113  loss= 0.049061696976423264\n",
            "shadow model: 84  epoch: 114  loss= 0.056583333760499954\n",
            "shadow model: 84  epoch: 115  loss= 0.06630858778953552\n",
            "shadow model: 84  epoch: 116  loss= 0.09728604555130005\n",
            "shadow model: 84  epoch: 117  loss= 0.04205060005187988\n",
            "shadow model: 84  epoch: 118  loss= 0.026725463569164276\n",
            "shadow model: 84  epoch: 119  loss= 0.042909394949674606\n",
            "shadow model: 84  epoch: 120  loss= 0.018945185467600822\n",
            "shadow model: 84  epoch: 121  loss= 0.03385733813047409\n",
            "shadow model: 84  epoch: 122  loss= 0.08161667734384537\n",
            "shadow model: 84  epoch: 123  loss= 0.06717624515295029\n",
            "shadow model: 84  epoch: 124  loss= 0.03646692633628845\n",
            "shadow model: 84  epoch: 125  loss= 0.05401117727160454\n",
            "shadow model: 84  epoch: 126  loss= 0.07331530749797821\n",
            "shadow model: 84  epoch: 127  loss= 0.04193322733044624\n",
            "shadow model: 84  epoch: 128  loss= 0.03444879874587059\n",
            "shadow model: 84  epoch: 129  loss= 0.006656716112047434\n",
            "shadow model: 84  epoch: 130  loss= 0.05454098805785179\n",
            "shadow model: 84  epoch: 131  loss= 0.032641395926475525\n",
            "shadow model: 84  epoch: 132  loss= 0.015216666273772717\n",
            "shadow model: 84  epoch: 133  loss= 0.024365277960896492\n",
            "shadow model: 84  epoch: 134  loss= 0.041123583912849426\n",
            "shadow model: 84  epoch: 135  loss= 0.029110075905919075\n",
            "shadow model: 84  epoch: 136  loss= 0.08768926560878754\n",
            "shadow model: 84  epoch: 137  loss= 0.07963088154792786\n",
            "shadow model: 84  epoch: 138  loss= 0.03903837129473686\n",
            "shadow model: 84  epoch: 139  loss= 0.14221327006816864\n",
            "shadow model: 84  epoch: 140  loss= 0.01706545054912567\n",
            "shadow model: 84  epoch: 141  loss= 0.036583613604307175\n",
            "shadow model: 84  epoch: 142  loss= 0.032258547842502594\n",
            "shadow model: 84  epoch: 143  loss= 0.04208021238446236\n",
            "shadow model: 84  epoch: 144  loss= 0.04600690305233002\n",
            "shadow model: 84  epoch: 145  loss= 0.07703674584627151\n",
            "shadow model: 84  epoch: 146  loss= 0.022630823776125908\n",
            "shadow model: 84  epoch: 147  loss= 0.01224570907652378\n",
            "shadow model: 84  epoch: 148  loss= 0.0139412060379982\n",
            "shadow model: 84  epoch: 149  loss= 0.07857439666986465\n",
            "\n",
            "shadow model: 85  epoch: 0  loss= 2.310419797897339\n",
            "shadow model: 85  epoch: 1  loss= 2.2698309421539307\n",
            "shadow model: 85  epoch: 2  loss= 2.2007546424865723\n",
            "shadow model: 85  epoch: 3  loss= 2.111191749572754\n",
            "shadow model: 85  epoch: 4  loss= 2.137808322906494\n",
            "shadow model: 85  epoch: 5  loss= 1.939324140548706\n",
            "shadow model: 85  epoch: 6  loss= 1.7599250078201294\n",
            "shadow model: 85  epoch: 7  loss= 1.842414379119873\n",
            "shadow model: 85  epoch: 8  loss= 1.6947873830795288\n",
            "shadow model: 85  epoch: 9  loss= 1.8766615390777588\n",
            "shadow model: 85  epoch: 10  loss= 1.565067172050476\n",
            "shadow model: 85  epoch: 11  loss= 1.5992250442504883\n",
            "shadow model: 85  epoch: 12  loss= 1.6033300161361694\n",
            "shadow model: 85  epoch: 13  loss= 1.7168426513671875\n",
            "shadow model: 85  epoch: 14  loss= 1.1873334646224976\n",
            "shadow model: 85  epoch: 15  loss= 1.459298014640808\n",
            "shadow model: 85  epoch: 16  loss= 1.078970193862915\n",
            "shadow model: 85  epoch: 17  loss= 1.1477210521697998\n",
            "shadow model: 85  epoch: 18  loss= 1.1476939916610718\n",
            "shadow model: 85  epoch: 19  loss= 1.1397658586502075\n",
            "shadow model: 85  epoch: 20  loss= 1.0907036066055298\n",
            "shadow model: 85  epoch: 21  loss= 1.2703355550765991\n",
            "shadow model: 85  epoch: 22  loss= 0.8107795119285583\n",
            "shadow model: 85  epoch: 23  loss= 0.7189081907272339\n",
            "shadow model: 85  epoch: 24  loss= 0.9135469198226929\n",
            "shadow model: 85  epoch: 25  loss= 0.9634345769882202\n",
            "shadow model: 85  epoch: 26  loss= 0.6325325965881348\n",
            "shadow model: 85  epoch: 27  loss= 0.722256064414978\n",
            "shadow model: 85  epoch: 28  loss= 0.7505196332931519\n",
            "shadow model: 85  epoch: 29  loss= 0.7309713363647461\n",
            "shadow model: 85  epoch: 30  loss= 0.5762546062469482\n",
            "shadow model: 85  epoch: 31  loss= 0.5125178098678589\n",
            "shadow model: 85  epoch: 32  loss= 0.42621615529060364\n",
            "shadow model: 85  epoch: 33  loss= 0.5766403675079346\n",
            "shadow model: 85  epoch: 34  loss= 0.45529288053512573\n",
            "shadow model: 85  epoch: 35  loss= 0.3396529257297516\n",
            "shadow model: 85  epoch: 36  loss= 0.5069059133529663\n",
            "shadow model: 85  epoch: 37  loss= 0.3737868368625641\n",
            "shadow model: 85  epoch: 38  loss= 0.38664788007736206\n",
            "shadow model: 85  epoch: 39  loss= 0.25602468848228455\n",
            "shadow model: 85  epoch: 40  loss= 0.305774986743927\n",
            "shadow model: 85  epoch: 41  loss= 0.3453013002872467\n",
            "shadow model: 85  epoch: 42  loss= 0.2219778448343277\n",
            "shadow model: 85  epoch: 43  loss= 0.43710386753082275\n",
            "shadow model: 85  epoch: 44  loss= 0.22180593013763428\n",
            "shadow model: 85  epoch: 45  loss= 0.36053839325904846\n",
            "shadow model: 85  epoch: 46  loss= 0.29432401061058044\n",
            "shadow model: 85  epoch: 47  loss= 0.2993983030319214\n",
            "shadow model: 85  epoch: 48  loss= 0.24128860235214233\n",
            "shadow model: 85  epoch: 49  loss= 0.39383670687675476\n",
            "shadow model: 85  epoch: 50  loss= 0.2562839984893799\n",
            "shadow model: 85  epoch: 51  loss= 0.335232138633728\n",
            "shadow model: 85  epoch: 52  loss= 0.16448506712913513\n",
            "shadow model: 85  epoch: 53  loss= 0.24875444173812866\n",
            "shadow model: 85  epoch: 54  loss= 0.18564556539058685\n",
            "shadow model: 85  epoch: 55  loss= 0.2433832436800003\n",
            "shadow model: 85  epoch: 56  loss= 0.16057921946048737\n",
            "shadow model: 85  epoch: 57  loss= 0.1584506630897522\n",
            "shadow model: 85  epoch: 58  loss= 0.17056624591350555\n",
            "shadow model: 85  epoch: 59  loss= 0.24975024163722992\n",
            "shadow model: 85  epoch: 60  loss= 0.1997881382703781\n",
            "shadow model: 85  epoch: 61  loss= 0.17814499139785767\n",
            "shadow model: 85  epoch: 62  loss= 0.1882183700799942\n",
            "shadow model: 85  epoch: 63  loss= 0.26029306650161743\n",
            "shadow model: 85  epoch: 64  loss= 0.24897611141204834\n",
            "shadow model: 85  epoch: 65  loss= 0.09112370014190674\n",
            "shadow model: 85  epoch: 66  loss= 0.20537708699703217\n",
            "shadow model: 85  epoch: 67  loss= 0.13220496475696564\n",
            "shadow model: 85  epoch: 68  loss= 0.22919407486915588\n",
            "shadow model: 85  epoch: 69  loss= 0.18658225238323212\n",
            "shadow model: 85  epoch: 70  loss= 0.06259587407112122\n",
            "shadow model: 85  epoch: 71  loss= 0.0664227306842804\n",
            "shadow model: 85  epoch: 72  loss= 0.09706223011016846\n",
            "shadow model: 85  epoch: 73  loss= 0.17369118332862854\n",
            "shadow model: 85  epoch: 74  loss= 0.10626418143510818\n",
            "shadow model: 85  epoch: 75  loss= 0.15808089077472687\n",
            "shadow model: 85  epoch: 76  loss= 0.0537007711827755\n",
            "shadow model: 85  epoch: 77  loss= 0.17487597465515137\n",
            "shadow model: 85  epoch: 78  loss= 0.0967329666018486\n",
            "shadow model: 85  epoch: 79  loss= 0.09495735168457031\n",
            "shadow model: 85  epoch: 80  loss= 0.06046728417277336\n",
            "shadow model: 85  epoch: 81  loss= 0.14276622235774994\n",
            "shadow model: 85  epoch: 82  loss= 0.019122663885354996\n",
            "shadow model: 85  epoch: 83  loss= 0.05376386269927025\n",
            "shadow model: 85  epoch: 84  loss= 0.09319525957107544\n",
            "shadow model: 85  epoch: 85  loss= 0.07860489934682846\n",
            "shadow model: 85  epoch: 86  loss= 0.10752933472394943\n",
            "shadow model: 85  epoch: 87  loss= 0.10264076292514801\n",
            "shadow model: 85  epoch: 88  loss= 0.03719160705804825\n",
            "shadow model: 85  epoch: 89  loss= 0.04986632615327835\n",
            "shadow model: 85  epoch: 90  loss= 0.12024620920419693\n",
            "shadow model: 85  epoch: 91  loss= 0.12102669477462769\n",
            "shadow model: 85  epoch: 92  loss= 0.13810241222381592\n",
            "shadow model: 85  epoch: 93  loss= 0.12528011202812195\n",
            "shadow model: 85  epoch: 94  loss= 0.1821809560060501\n",
            "shadow model: 85  epoch: 95  loss= 0.05970758944749832\n",
            "shadow model: 85  epoch: 96  loss= 0.07256817072629929\n",
            "shadow model: 85  epoch: 97  loss= 0.12905307114124298\n",
            "shadow model: 85  epoch: 98  loss= 0.1914176344871521\n",
            "shadow model: 85  epoch: 99  loss= 0.06335906684398651\n",
            "shadow model: 85  epoch: 100  loss= 0.1464862823486328\n",
            "shadow model: 85  epoch: 101  loss= 0.039159778505563736\n",
            "shadow model: 85  epoch: 102  loss= 0.13495256006717682\n",
            "shadow model: 85  epoch: 103  loss= 0.022078944370150566\n",
            "shadow model: 85  epoch: 104  loss= 0.04497416317462921\n",
            "shadow model: 85  epoch: 105  loss= 0.10079652070999146\n",
            "shadow model: 85  epoch: 106  loss= 0.11877649277448654\n",
            "shadow model: 85  epoch: 107  loss= 0.08699467778205872\n",
            "shadow model: 85  epoch: 108  loss= 0.17756302654743195\n",
            "shadow model: 85  epoch: 109  loss= 0.06124527007341385\n",
            "shadow model: 85  epoch: 110  loss= 0.020684780552983284\n",
            "shadow model: 85  epoch: 111  loss= 0.09445616602897644\n",
            "shadow model: 85  epoch: 112  loss= 0.16819164156913757\n",
            "shadow model: 85  epoch: 113  loss= 0.08714216202497482\n",
            "shadow model: 85  epoch: 114  loss= 0.02844514325261116\n",
            "shadow model: 85  epoch: 115  loss= 0.09541027992963791\n",
            "shadow model: 85  epoch: 116  loss= 0.11253461986780167\n",
            "shadow model: 85  epoch: 117  loss= 0.04946420341730118\n",
            "shadow model: 85  epoch: 118  loss= 0.18651233613491058\n",
            "shadow model: 85  epoch: 119  loss= 0.03954150527715683\n",
            "shadow model: 85  epoch: 120  loss= 0.11024274677038193\n",
            "shadow model: 85  epoch: 121  loss= 0.06611653417348862\n",
            "shadow model: 85  epoch: 122  loss= 0.07462844252586365\n",
            "shadow model: 85  epoch: 123  loss= 0.07765933871269226\n",
            "shadow model: 85  epoch: 124  loss= 0.07730180025100708\n",
            "shadow model: 85  epoch: 125  loss= 0.06468742340803146\n",
            "shadow model: 85  epoch: 126  loss= 0.059980276972055435\n",
            "shadow model: 85  epoch: 127  loss= 0.06973643600940704\n",
            "shadow model: 85  epoch: 128  loss= 0.043644197285175323\n",
            "shadow model: 85  epoch: 129  loss= 0.07591670006513596\n",
            "shadow model: 85  epoch: 130  loss= 0.08242963999509811\n",
            "shadow model: 85  epoch: 131  loss= 0.047497332096099854\n",
            "shadow model: 85  epoch: 132  loss= 0.10989554971456528\n",
            "shadow model: 85  epoch: 133  loss= 0.08241918683052063\n",
            "shadow model: 85  epoch: 134  loss= 0.051620323210954666\n",
            "shadow model: 85  epoch: 135  loss= 0.05294281989336014\n",
            "shadow model: 85  epoch: 136  loss= 0.0411188080906868\n",
            "shadow model: 85  epoch: 137  loss= 0.07442726194858551\n",
            "shadow model: 85  epoch: 138  loss= 0.040454357862472534\n",
            "shadow model: 85  epoch: 139  loss= 0.1368500143289566\n",
            "shadow model: 85  epoch: 140  loss= 0.07732222974300385\n",
            "shadow model: 85  epoch: 141  loss= 0.051207706332206726\n",
            "shadow model: 85  epoch: 142  loss= 0.031206300482153893\n",
            "shadow model: 85  epoch: 143  loss= 0.11336484551429749\n",
            "shadow model: 85  epoch: 144  loss= 0.07530824095010757\n",
            "shadow model: 85  epoch: 145  loss= 0.044861726462841034\n",
            "shadow model: 85  epoch: 146  loss= 0.1398141086101532\n",
            "shadow model: 85  epoch: 147  loss= 0.14997345209121704\n",
            "shadow model: 85  epoch: 148  loss= 0.1060677245259285\n",
            "shadow model: 85  epoch: 149  loss= 0.0647769421339035\n",
            "\n",
            "shadow model: 86  epoch: 0  loss= 2.29788875579834\n",
            "shadow model: 86  epoch: 1  loss= 2.3009800910949707\n",
            "shadow model: 86  epoch: 2  loss= 2.3032546043395996\n",
            "shadow model: 86  epoch: 3  loss= 2.205172061920166\n",
            "shadow model: 86  epoch: 4  loss= 2.1173689365386963\n",
            "shadow model: 86  epoch: 5  loss= 2.0794591903686523\n",
            "shadow model: 86  epoch: 6  loss= 2.0140442848205566\n",
            "shadow model: 86  epoch: 7  loss= 2.0025076866149902\n",
            "shadow model: 86  epoch: 8  loss= 1.947302222251892\n",
            "shadow model: 86  epoch: 9  loss= 1.945502758026123\n",
            "shadow model: 86  epoch: 10  loss= 1.9190460443496704\n",
            "shadow model: 86  epoch: 11  loss= 1.7933152914047241\n",
            "shadow model: 86  epoch: 12  loss= 1.6739099025726318\n",
            "shadow model: 86  epoch: 13  loss= 1.6618326902389526\n",
            "shadow model: 86  epoch: 14  loss= 1.3717387914657593\n",
            "shadow model: 86  epoch: 15  loss= 1.5067046880722046\n",
            "shadow model: 86  epoch: 16  loss= 1.326003074645996\n",
            "shadow model: 86  epoch: 17  loss= 1.145875096321106\n",
            "shadow model: 86  epoch: 18  loss= 1.2875136137008667\n",
            "shadow model: 86  epoch: 19  loss= 1.2616941928863525\n",
            "shadow model: 86  epoch: 20  loss= 1.076053261756897\n",
            "shadow model: 86  epoch: 21  loss= 0.9448232054710388\n",
            "shadow model: 86  epoch: 22  loss= 0.91295325756073\n",
            "shadow model: 86  epoch: 23  loss= 0.5644916296005249\n",
            "shadow model: 86  epoch: 24  loss= 0.8515326380729675\n",
            "shadow model: 86  epoch: 25  loss= 0.7538195848464966\n",
            "shadow model: 86  epoch: 26  loss= 0.6541554927825928\n",
            "shadow model: 86  epoch: 27  loss= 0.6489022970199585\n",
            "shadow model: 86  epoch: 28  loss= 0.7567074298858643\n",
            "shadow model: 86  epoch: 29  loss= 0.6147328615188599\n",
            "shadow model: 86  epoch: 30  loss= 0.6174782514572144\n",
            "shadow model: 86  epoch: 31  loss= 0.7483803033828735\n",
            "shadow model: 86  epoch: 32  loss= 0.45478740334510803\n",
            "shadow model: 86  epoch: 33  loss= 0.4922741651535034\n",
            "shadow model: 86  epoch: 34  loss= 0.41788601875305176\n",
            "shadow model: 86  epoch: 35  loss= 0.6018467545509338\n",
            "shadow model: 86  epoch: 36  loss= 0.44011208415031433\n",
            "shadow model: 86  epoch: 37  loss= 0.3654790222644806\n",
            "shadow model: 86  epoch: 38  loss= 0.4945588707923889\n",
            "shadow model: 86  epoch: 39  loss= 0.3376806676387787\n",
            "shadow model: 86  epoch: 40  loss= 0.5233243107795715\n",
            "shadow model: 86  epoch: 41  loss= 0.4394909739494324\n",
            "shadow model: 86  epoch: 42  loss= 0.3590872585773468\n",
            "shadow model: 86  epoch: 43  loss= 0.4592891335487366\n",
            "shadow model: 86  epoch: 44  loss= 0.3535546660423279\n",
            "shadow model: 86  epoch: 45  loss= 0.34464743733406067\n",
            "shadow model: 86  epoch: 46  loss= 0.38620585203170776\n",
            "shadow model: 86  epoch: 47  loss= 0.3795444965362549\n",
            "shadow model: 86  epoch: 48  loss= 0.2205275446176529\n",
            "shadow model: 86  epoch: 49  loss= 0.4086860120296478\n",
            "shadow model: 86  epoch: 50  loss= 0.15950347483158112\n",
            "shadow model: 86  epoch: 51  loss= 0.2936757802963257\n",
            "shadow model: 86  epoch: 52  loss= 0.220870703458786\n",
            "shadow model: 86  epoch: 53  loss= 0.29962652921676636\n",
            "shadow model: 86  epoch: 54  loss= 0.22749339044094086\n",
            "shadow model: 86  epoch: 55  loss= 0.3018542528152466\n",
            "shadow model: 86  epoch: 56  loss= 0.2272370606660843\n",
            "shadow model: 86  epoch: 57  loss= 0.22321717441082\n",
            "shadow model: 86  epoch: 58  loss= 0.2631136476993561\n",
            "shadow model: 86  epoch: 59  loss= 0.196779265999794\n",
            "shadow model: 86  epoch: 60  loss= 0.10308345407247543\n",
            "shadow model: 86  epoch: 61  loss= 0.17747762799263\n",
            "shadow model: 86  epoch: 62  loss= 0.20633864402770996\n",
            "shadow model: 86  epoch: 63  loss= 0.16471657156944275\n",
            "shadow model: 86  epoch: 64  loss= 0.17210404574871063\n",
            "shadow model: 86  epoch: 65  loss= 0.1824241429567337\n",
            "shadow model: 86  epoch: 66  loss= 0.2160228043794632\n",
            "shadow model: 86  epoch: 67  loss= 0.16851253807544708\n",
            "shadow model: 86  epoch: 68  loss= 0.11591855436563492\n",
            "shadow model: 86  epoch: 69  loss= 0.1587989628314972\n",
            "shadow model: 86  epoch: 70  loss= 0.10251040756702423\n",
            "shadow model: 86  epoch: 71  loss= 0.16374172270298004\n",
            "shadow model: 86  epoch: 72  loss= 0.14949855208396912\n",
            "shadow model: 86  epoch: 73  loss= 0.1527179330587387\n",
            "shadow model: 86  epoch: 74  loss= 0.11791501939296722\n",
            "shadow model: 86  epoch: 75  loss= 0.18329820036888123\n",
            "shadow model: 86  epoch: 76  loss= 0.16298748552799225\n",
            "shadow model: 86  epoch: 77  loss= 0.09135487675666809\n",
            "shadow model: 86  epoch: 78  loss= 0.2327868938446045\n",
            "shadow model: 86  epoch: 79  loss= 0.21622945368289948\n",
            "shadow model: 86  epoch: 80  loss= 0.14638224244117737\n",
            "shadow model: 86  epoch: 81  loss= 0.22551818192005157\n",
            "shadow model: 86  epoch: 82  loss= 0.09570949524641037\n",
            "shadow model: 86  epoch: 83  loss= 0.20860230922698975\n",
            "shadow model: 86  epoch: 84  loss= 0.22741353511810303\n",
            "shadow model: 86  epoch: 85  loss= 0.16054990887641907\n",
            "shadow model: 86  epoch: 86  loss= 0.09625444561243057\n",
            "shadow model: 86  epoch: 87  loss= 0.14206938445568085\n",
            "shadow model: 86  epoch: 88  loss= 0.18453076481819153\n",
            "shadow model: 86  epoch: 89  loss= 0.13030271232128143\n",
            "shadow model: 86  epoch: 90  loss= 0.03566873446106911\n",
            "shadow model: 86  epoch: 91  loss= 0.1469682902097702\n",
            "shadow model: 86  epoch: 92  loss= 0.08689459413290024\n",
            "shadow model: 86  epoch: 93  loss= 0.08199810236692429\n",
            "shadow model: 86  epoch: 94  loss= 0.12870386242866516\n",
            "shadow model: 86  epoch: 95  loss= 0.08687566220760345\n",
            "shadow model: 86  epoch: 96  loss= 0.1628796011209488\n",
            "shadow model: 86  epoch: 97  loss= 0.26241904497146606\n",
            "shadow model: 86  epoch: 98  loss= 0.12208617478609085\n",
            "shadow model: 86  epoch: 99  loss= 0.16286137700080872\n",
            "shadow model: 86  epoch: 100  loss= 0.11453304439783096\n",
            "shadow model: 86  epoch: 101  loss= 0.02951642870903015\n",
            "shadow model: 86  epoch: 102  loss= 0.06635404378175735\n",
            "shadow model: 86  epoch: 103  loss= 0.05050162225961685\n",
            "shadow model: 86  epoch: 104  loss= 0.12152551114559174\n",
            "shadow model: 86  epoch: 105  loss= 0.15544138848781586\n",
            "shadow model: 86  epoch: 106  loss= 0.06174711510539055\n",
            "shadow model: 86  epoch: 107  loss= 0.1297910213470459\n",
            "shadow model: 86  epoch: 108  loss= 0.08915311843156815\n",
            "shadow model: 86  epoch: 109  loss= 0.08241294324398041\n",
            "shadow model: 86  epoch: 110  loss= 0.05228123068809509\n",
            "shadow model: 86  epoch: 111  loss= 0.14357180893421173\n",
            "shadow model: 86  epoch: 112  loss= 0.06391642987728119\n",
            "shadow model: 86  epoch: 113  loss= 0.09972905367612839\n",
            "shadow model: 86  epoch: 114  loss= 0.03941516578197479\n",
            "shadow model: 86  epoch: 115  loss= 0.07703498750925064\n",
            "shadow model: 86  epoch: 116  loss= 0.07908763736486435\n",
            "shadow model: 86  epoch: 117  loss= 0.07944469153881073\n",
            "shadow model: 86  epoch: 118  loss= 0.09944187849760056\n",
            "shadow model: 86  epoch: 119  loss= 0.07603935897350311\n",
            "shadow model: 86  epoch: 120  loss= 0.19818106293678284\n",
            "shadow model: 86  epoch: 121  loss= 0.09717746078968048\n",
            "shadow model: 86  epoch: 122  loss= 0.0924636721611023\n",
            "shadow model: 86  epoch: 123  loss= 0.07176081091165543\n",
            "shadow model: 86  epoch: 124  loss= 0.050191376358270645\n",
            "shadow model: 86  epoch: 125  loss= 0.1040494292974472\n",
            "shadow model: 86  epoch: 126  loss= 0.060020964592695236\n",
            "shadow model: 86  epoch: 127  loss= 0.06387969851493835\n",
            "shadow model: 86  epoch: 128  loss= 0.12214701622724533\n",
            "shadow model: 86  epoch: 129  loss= 0.16811537742614746\n",
            "shadow model: 86  epoch: 130  loss= 0.08106434345245361\n",
            "shadow model: 86  epoch: 131  loss= 0.18129514157772064\n",
            "shadow model: 86  epoch: 132  loss= 0.1177511140704155\n",
            "shadow model: 86  epoch: 133  loss= 0.1860526204109192\n",
            "shadow model: 86  epoch: 134  loss= 0.09090529382228851\n",
            "shadow model: 86  epoch: 135  loss= 0.08906392753124237\n",
            "shadow model: 86  epoch: 136  loss= 0.08291658014059067\n",
            "shadow model: 86  epoch: 137  loss= 0.1146668940782547\n",
            "shadow model: 86  epoch: 138  loss= 0.00798660796135664\n",
            "shadow model: 86  epoch: 139  loss= 0.06791697442531586\n",
            "shadow model: 86  epoch: 140  loss= 0.05545235052704811\n",
            "shadow model: 86  epoch: 141  loss= 0.05565829202532768\n",
            "shadow model: 86  epoch: 142  loss= 0.15267117321491241\n",
            "shadow model: 86  epoch: 143  loss= 0.0691656693816185\n",
            "shadow model: 86  epoch: 144  loss= 0.037028584629297256\n",
            "shadow model: 86  epoch: 145  loss= 0.09364059567451477\n",
            "shadow model: 86  epoch: 146  loss= 0.07918591797351837\n",
            "shadow model: 86  epoch: 147  loss= 0.02451484650373459\n",
            "shadow model: 86  epoch: 148  loss= 0.15273921191692352\n",
            "shadow model: 86  epoch: 149  loss= 0.10667961090803146\n",
            "\n",
            "shadow model: 87  epoch: 0  loss= 2.2753219604492188\n",
            "shadow model: 87  epoch: 1  loss= 2.200105905532837\n",
            "shadow model: 87  epoch: 2  loss= 2.123915672302246\n",
            "shadow model: 87  epoch: 3  loss= 2.0864264965057373\n",
            "shadow model: 87  epoch: 4  loss= 2.0934579372406006\n",
            "shadow model: 87  epoch: 5  loss= 1.9968441724777222\n",
            "shadow model: 87  epoch: 6  loss= 1.9901158809661865\n",
            "shadow model: 87  epoch: 7  loss= 1.8950164318084717\n",
            "shadow model: 87  epoch: 8  loss= 1.8543728590011597\n",
            "shadow model: 87  epoch: 9  loss= 1.763112187385559\n",
            "shadow model: 87  epoch: 10  loss= 1.7101340293884277\n",
            "shadow model: 87  epoch: 11  loss= 1.766417384147644\n",
            "shadow model: 87  epoch: 12  loss= 1.3450089693069458\n",
            "shadow model: 87  epoch: 13  loss= 1.6555349826812744\n",
            "shadow model: 87  epoch: 14  loss= 1.5083487033843994\n",
            "shadow model: 87  epoch: 15  loss= 1.39119553565979\n",
            "shadow model: 87  epoch: 16  loss= 1.2844412326812744\n",
            "shadow model: 87  epoch: 17  loss= 1.2550359964370728\n",
            "shadow model: 87  epoch: 18  loss= 1.4790841341018677\n",
            "shadow model: 87  epoch: 19  loss= 1.2059732675552368\n",
            "shadow model: 87  epoch: 20  loss= 1.1919926404953003\n",
            "shadow model: 87  epoch: 21  loss= 1.1578139066696167\n",
            "shadow model: 87  epoch: 22  loss= 0.9742646813392639\n",
            "shadow model: 87  epoch: 23  loss= 1.008839726448059\n",
            "shadow model: 87  epoch: 24  loss= 0.7626097798347473\n",
            "shadow model: 87  epoch: 25  loss= 0.9619579911231995\n",
            "shadow model: 87  epoch: 26  loss= 0.9578256607055664\n",
            "shadow model: 87  epoch: 27  loss= 0.8053964972496033\n",
            "shadow model: 87  epoch: 28  loss= 1.0720692873001099\n",
            "shadow model: 87  epoch: 29  loss= 0.7188606858253479\n",
            "shadow model: 87  epoch: 30  loss= 0.6146245002746582\n",
            "shadow model: 87  epoch: 31  loss= 0.7516814470291138\n",
            "shadow model: 87  epoch: 32  loss= 0.6241366863250732\n",
            "shadow model: 87  epoch: 33  loss= 0.6362049579620361\n",
            "shadow model: 87  epoch: 34  loss= 0.46725043654441833\n",
            "shadow model: 87  epoch: 35  loss= 0.7375195622444153\n",
            "shadow model: 87  epoch: 36  loss= 0.5512515902519226\n",
            "shadow model: 87  epoch: 37  loss= 0.5883849263191223\n",
            "shadow model: 87  epoch: 38  loss= 0.42275771498680115\n",
            "shadow model: 87  epoch: 39  loss= 0.6563931107521057\n",
            "shadow model: 87  epoch: 40  loss= 0.647782027721405\n",
            "shadow model: 87  epoch: 41  loss= 0.4309060275554657\n",
            "shadow model: 87  epoch: 42  loss= 0.49601829051971436\n",
            "shadow model: 87  epoch: 43  loss= 0.4301956295967102\n",
            "shadow model: 87  epoch: 44  loss= 0.40740302205085754\n",
            "shadow model: 87  epoch: 45  loss= 0.6773608922958374\n",
            "shadow model: 87  epoch: 46  loss= 0.33632925152778625\n",
            "shadow model: 87  epoch: 47  loss= 0.43749240040779114\n",
            "shadow model: 87  epoch: 48  loss= 0.32005783915519714\n",
            "shadow model: 87  epoch: 49  loss= 0.3957015573978424\n",
            "shadow model: 87  epoch: 50  loss= 0.35082143545150757\n",
            "shadow model: 87  epoch: 51  loss= 0.30614131689071655\n",
            "shadow model: 87  epoch: 52  loss= 0.3980754315853119\n",
            "shadow model: 87  epoch: 53  loss= 0.4204327464103699\n",
            "shadow model: 87  epoch: 54  loss= 0.34646743535995483\n",
            "shadow model: 87  epoch: 55  loss= 0.19146603345870972\n",
            "shadow model: 87  epoch: 56  loss= 0.1523320972919464\n",
            "shadow model: 87  epoch: 57  loss= 0.31663286685943604\n",
            "shadow model: 87  epoch: 58  loss= 0.37094947695732117\n",
            "shadow model: 87  epoch: 59  loss= 0.19790397584438324\n",
            "shadow model: 87  epoch: 60  loss= 0.2551288306713104\n",
            "shadow model: 87  epoch: 61  loss= 0.3516414165496826\n",
            "shadow model: 87  epoch: 62  loss= 0.17310909926891327\n",
            "shadow model: 87  epoch: 63  loss= 0.30644071102142334\n",
            "shadow model: 87  epoch: 64  loss= 0.29692623019218445\n",
            "shadow model: 87  epoch: 65  loss= 0.21677015721797943\n",
            "shadow model: 87  epoch: 66  loss= 0.19305239617824554\n",
            "shadow model: 87  epoch: 67  loss= 0.3016107380390167\n",
            "shadow model: 87  epoch: 68  loss= 0.19211895763874054\n",
            "shadow model: 87  epoch: 69  loss= 0.24082420766353607\n",
            "shadow model: 87  epoch: 70  loss= 0.21088746190071106\n",
            "shadow model: 87  epoch: 71  loss= 0.39201557636260986\n",
            "shadow model: 87  epoch: 72  loss= 0.24790039658546448\n",
            "shadow model: 87  epoch: 73  loss= 0.14926373958587646\n",
            "shadow model: 87  epoch: 74  loss= 0.16873739659786224\n",
            "shadow model: 87  epoch: 75  loss= 0.17993852496147156\n",
            "shadow model: 87  epoch: 76  loss= 0.17738410830497742\n",
            "shadow model: 87  epoch: 77  loss= 0.1397646963596344\n",
            "shadow model: 87  epoch: 78  loss= 0.1424059122800827\n",
            "shadow model: 87  epoch: 79  loss= 0.20819462835788727\n",
            "shadow model: 87  epoch: 80  loss= 0.20320521295070648\n",
            "shadow model: 87  epoch: 81  loss= 0.22943681478500366\n",
            "shadow model: 87  epoch: 82  loss= 0.2483540177345276\n",
            "shadow model: 87  epoch: 83  loss= 0.18567520380020142\n",
            "shadow model: 87  epoch: 84  loss= 0.12332722544670105\n",
            "shadow model: 87  epoch: 85  loss= 0.13668133318424225\n",
            "shadow model: 87  epoch: 86  loss= 0.22621700167655945\n",
            "shadow model: 87  epoch: 87  loss= 0.1744629293680191\n",
            "shadow model: 87  epoch: 88  loss= 0.17086854577064514\n",
            "shadow model: 87  epoch: 89  loss= 0.21933303773403168\n",
            "shadow model: 87  epoch: 90  loss= 0.2785189151763916\n",
            "shadow model: 87  epoch: 91  loss= 0.1971617192029953\n",
            "shadow model: 87  epoch: 92  loss= 0.1581459939479828\n",
            "shadow model: 87  epoch: 93  loss= 0.14672303199768066\n",
            "shadow model: 87  epoch: 94  loss= 0.13761909306049347\n",
            "shadow model: 87  epoch: 95  loss= 0.18065927922725677\n",
            "shadow model: 87  epoch: 96  loss= 0.24468547105789185\n",
            "shadow model: 87  epoch: 97  loss= 0.1246267706155777\n",
            "shadow model: 87  epoch: 98  loss= 0.12909464538097382\n",
            "shadow model: 87  epoch: 99  loss= 0.2176344394683838\n",
            "shadow model: 87  epoch: 100  loss= 0.11407040804624557\n",
            "shadow model: 87  epoch: 101  loss= 0.11150995641946793\n",
            "shadow model: 87  epoch: 102  loss= 0.07064725458621979\n",
            "shadow model: 87  epoch: 103  loss= 0.17499513924121857\n",
            "shadow model: 87  epoch: 104  loss= 0.1410045623779297\n",
            "shadow model: 87  epoch: 105  loss= 0.20951643586158752\n",
            "shadow model: 87  epoch: 106  loss= 0.10745584964752197\n",
            "shadow model: 87  epoch: 107  loss= 0.1955035924911499\n",
            "shadow model: 87  epoch: 108  loss= 0.20343419909477234\n",
            "shadow model: 87  epoch: 109  loss= 0.09872601926326752\n",
            "shadow model: 87  epoch: 110  loss= 0.1432388871908188\n",
            "shadow model: 87  epoch: 111  loss= 0.11797093600034714\n",
            "shadow model: 87  epoch: 112  loss= 0.12607403099536896\n",
            "shadow model: 87  epoch: 113  loss= 0.08279351890087128\n",
            "shadow model: 87  epoch: 114  loss= 0.11150729656219482\n",
            "shadow model: 87  epoch: 115  loss= 0.16849830746650696\n",
            "shadow model: 87  epoch: 116  loss= 0.07116853445768356\n",
            "shadow model: 87  epoch: 117  loss= 0.1774580478668213\n",
            "shadow model: 87  epoch: 118  loss= 0.1281926929950714\n",
            "shadow model: 87  epoch: 119  loss= 0.03080453909933567\n",
            "shadow model: 87  epoch: 120  loss= 0.1778842955827713\n",
            "shadow model: 87  epoch: 121  loss= 0.10940996557474136\n",
            "shadow model: 87  epoch: 122  loss= 0.1612250804901123\n",
            "shadow model: 87  epoch: 123  loss= 0.0959143415093422\n",
            "shadow model: 87  epoch: 124  loss= 0.2577451169490814\n",
            "shadow model: 87  epoch: 125  loss= 0.10801652073860168\n",
            "shadow model: 87  epoch: 126  loss= 0.16090594232082367\n",
            "shadow model: 87  epoch: 127  loss= 0.09937544167041779\n",
            "shadow model: 87  epoch: 128  loss= 0.34485939145088196\n",
            "shadow model: 87  epoch: 129  loss= 0.12651386857032776\n",
            "shadow model: 87  epoch: 130  loss= 0.08871915936470032\n",
            "shadow model: 87  epoch: 131  loss= 0.12707187235355377\n",
            "shadow model: 87  epoch: 132  loss= 0.13775192201137543\n",
            "shadow model: 87  epoch: 133  loss= 0.10051406919956207\n",
            "shadow model: 87  epoch: 134  loss= 0.045335520058870316\n",
            "shadow model: 87  epoch: 135  loss= 0.11688732355833054\n",
            "shadow model: 87  epoch: 136  loss= 0.0970727801322937\n",
            "shadow model: 87  epoch: 137  loss= 0.1515800952911377\n",
            "shadow model: 87  epoch: 138  loss= 0.05284629017114639\n",
            "shadow model: 87  epoch: 139  loss= 0.05429023131728172\n",
            "shadow model: 87  epoch: 140  loss= 0.2693699598312378\n",
            "shadow model: 87  epoch: 141  loss= 0.1777864396572113\n",
            "shadow model: 87  epoch: 142  loss= 0.15489263832569122\n",
            "shadow model: 87  epoch: 143  loss= 0.12018807977437973\n",
            "shadow model: 87  epoch: 144  loss= 0.14402508735656738\n",
            "shadow model: 87  epoch: 145  loss= 0.0415191613137722\n",
            "shadow model: 87  epoch: 146  loss= 0.10496169328689575\n",
            "shadow model: 87  epoch: 147  loss= 0.153262659907341\n",
            "shadow model: 87  epoch: 148  loss= 0.07475053519010544\n",
            "shadow model: 87  epoch: 149  loss= 0.038672130554914474\n",
            "\n",
            "shadow model: 88  epoch: 0  loss= 2.301974058151245\n",
            "shadow model: 88  epoch: 1  loss= 2.247731924057007\n",
            "shadow model: 88  epoch: 2  loss= 2.157541513442993\n",
            "shadow model: 88  epoch: 3  loss= 2.1434950828552246\n",
            "shadow model: 88  epoch: 4  loss= 2.070747137069702\n",
            "shadow model: 88  epoch: 5  loss= 2.008842706680298\n",
            "shadow model: 88  epoch: 6  loss= 2.0353951454162598\n",
            "shadow model: 88  epoch: 7  loss= 2.002103090286255\n",
            "shadow model: 88  epoch: 8  loss= 1.7249445915222168\n",
            "shadow model: 88  epoch: 9  loss= 1.6338465213775635\n",
            "shadow model: 88  epoch: 10  loss= 1.8876937627792358\n",
            "shadow model: 88  epoch: 11  loss= 1.6551401615142822\n",
            "shadow model: 88  epoch: 12  loss= 1.662812352180481\n",
            "shadow model: 88  epoch: 13  loss= 1.3486241102218628\n",
            "shadow model: 88  epoch: 14  loss= 1.4274790287017822\n",
            "shadow model: 88  epoch: 15  loss= 1.3995801210403442\n",
            "shadow model: 88  epoch: 16  loss= 1.2652713060379028\n",
            "shadow model: 88  epoch: 17  loss= 1.0327868461608887\n",
            "shadow model: 88  epoch: 18  loss= 1.114011287689209\n",
            "shadow model: 88  epoch: 19  loss= 1.055257797241211\n",
            "shadow model: 88  epoch: 20  loss= 1.1748052835464478\n",
            "shadow model: 88  epoch: 21  loss= 0.9652832746505737\n",
            "shadow model: 88  epoch: 22  loss= 0.7789631485939026\n",
            "shadow model: 88  epoch: 23  loss= 0.6632170081138611\n",
            "shadow model: 88  epoch: 24  loss= 0.559224009513855\n",
            "shadow model: 88  epoch: 25  loss= 0.5523068308830261\n",
            "shadow model: 88  epoch: 26  loss= 0.5691702365875244\n",
            "shadow model: 88  epoch: 27  loss= 0.6766019463539124\n",
            "shadow model: 88  epoch: 28  loss= 0.5912463068962097\n",
            "shadow model: 88  epoch: 29  loss= 0.6713882088661194\n",
            "shadow model: 88  epoch: 30  loss= 0.5955953598022461\n",
            "shadow model: 88  epoch: 31  loss= 0.5173804759979248\n",
            "shadow model: 88  epoch: 32  loss= 0.3181595802307129\n",
            "shadow model: 88  epoch: 33  loss= 0.3983130156993866\n",
            "shadow model: 88  epoch: 34  loss= 0.4388376772403717\n",
            "shadow model: 88  epoch: 35  loss= 0.32816827297210693\n",
            "shadow model: 88  epoch: 36  loss= 0.33180615305900574\n",
            "shadow model: 88  epoch: 37  loss= 0.4656308591365814\n",
            "shadow model: 88  epoch: 38  loss= 0.3718510568141937\n",
            "shadow model: 88  epoch: 39  loss= 0.32761067152023315\n",
            "shadow model: 88  epoch: 40  loss= 0.29708781838417053\n",
            "shadow model: 88  epoch: 41  loss= 0.35715511441230774\n",
            "shadow model: 88  epoch: 42  loss= 0.19016191363334656\n",
            "shadow model: 88  epoch: 43  loss= 0.1963844746351242\n",
            "shadow model: 88  epoch: 44  loss= 0.33315661549568176\n",
            "shadow model: 88  epoch: 45  loss= 0.24096910655498505\n",
            "shadow model: 88  epoch: 46  loss= 0.14266103506088257\n",
            "shadow model: 88  epoch: 47  loss= 0.24435749650001526\n",
            "shadow model: 88  epoch: 48  loss= 0.22519806027412415\n",
            "shadow model: 88  epoch: 49  loss= 0.2661648690700531\n",
            "shadow model: 88  epoch: 50  loss= 0.19350484013557434\n",
            "shadow model: 88  epoch: 51  loss= 0.14426423609256744\n",
            "shadow model: 88  epoch: 52  loss= 0.25044405460357666\n",
            "shadow model: 88  epoch: 53  loss= 0.18114477396011353\n",
            "shadow model: 88  epoch: 54  loss= 0.17248302698135376\n",
            "shadow model: 88  epoch: 55  loss= 0.10728545486927032\n",
            "shadow model: 88  epoch: 56  loss= 0.13093329966068268\n",
            "shadow model: 88  epoch: 57  loss= 0.24427874386310577\n",
            "shadow model: 88  epoch: 58  loss= 0.22053907811641693\n",
            "shadow model: 88  epoch: 59  loss= 0.14514799416065216\n",
            "shadow model: 88  epoch: 60  loss= 0.22981597483158112\n",
            "shadow model: 88  epoch: 61  loss= 0.1082889661192894\n",
            "shadow model: 88  epoch: 62  loss= 0.12526415288448334\n",
            "shadow model: 88  epoch: 63  loss= 0.1567172110080719\n",
            "shadow model: 88  epoch: 64  loss= 0.10059848427772522\n",
            "shadow model: 88  epoch: 65  loss= 0.07217657566070557\n",
            "shadow model: 88  epoch: 66  loss= 0.06611690670251846\n",
            "shadow model: 88  epoch: 67  loss= 0.19240877032279968\n",
            "shadow model: 88  epoch: 68  loss= 0.10119751840829849\n",
            "shadow model: 88  epoch: 69  loss= 0.1829523742198944\n",
            "shadow model: 88  epoch: 70  loss= 0.07450024038553238\n",
            "shadow model: 88  epoch: 71  loss= 0.11482290923595428\n",
            "shadow model: 88  epoch: 72  loss= 0.08286039531230927\n",
            "shadow model: 88  epoch: 73  loss= 0.054661672562360764\n",
            "shadow model: 88  epoch: 74  loss= 0.11641055345535278\n",
            "shadow model: 88  epoch: 75  loss= 0.06732967495918274\n",
            "shadow model: 88  epoch: 76  loss= 0.09591078013181686\n",
            "shadow model: 88  epoch: 77  loss= 0.07393602281808853\n",
            "shadow model: 88  epoch: 78  loss= 0.12138427048921585\n",
            "shadow model: 88  epoch: 79  loss= 0.16436359286308289\n",
            "shadow model: 88  epoch: 80  loss= 0.07152058929204941\n",
            "shadow model: 88  epoch: 81  loss= 0.03618921339511871\n",
            "shadow model: 88  epoch: 82  loss= 0.1399173140525818\n",
            "shadow model: 88  epoch: 83  loss= 0.20854070782661438\n",
            "shadow model: 88  epoch: 84  loss= 0.15787842869758606\n",
            "shadow model: 88  epoch: 85  loss= 0.12660221755504608\n",
            "shadow model: 88  epoch: 86  loss= 0.04865538701415062\n",
            "shadow model: 88  epoch: 87  loss= 0.054984673857688904\n",
            "shadow model: 88  epoch: 88  loss= 0.088009312748909\n",
            "shadow model: 88  epoch: 89  loss= 0.0828176885843277\n",
            "shadow model: 88  epoch: 90  loss= 0.05218223109841347\n",
            "shadow model: 88  epoch: 91  loss= 0.14663589000701904\n",
            "shadow model: 88  epoch: 92  loss= 0.06747818738222122\n",
            "shadow model: 88  epoch: 93  loss= 0.14764563739299774\n",
            "shadow model: 88  epoch: 94  loss= 0.13592930138111115\n",
            "shadow model: 88  epoch: 95  loss= 0.06946534663438797\n",
            "shadow model: 88  epoch: 96  loss= 0.11255155503749847\n",
            "shadow model: 88  epoch: 97  loss= 0.07631539553403854\n",
            "shadow model: 88  epoch: 98  loss= 0.09913858771324158\n",
            "shadow model: 88  epoch: 99  loss= 0.05418260768055916\n",
            "shadow model: 88  epoch: 100  loss= 0.027947314083576202\n",
            "shadow model: 88  epoch: 101  loss= 0.07034654170274734\n",
            "shadow model: 88  epoch: 102  loss= 0.13662944734096527\n",
            "shadow model: 88  epoch: 103  loss= 0.053912460803985596\n",
            "shadow model: 88  epoch: 104  loss= 0.14233747124671936\n",
            "shadow model: 88  epoch: 105  loss= 0.11674492061138153\n",
            "shadow model: 88  epoch: 106  loss= 0.14180338382720947\n",
            "shadow model: 88  epoch: 107  loss= 0.09056084603071213\n",
            "shadow model: 88  epoch: 108  loss= 0.05444468930363655\n",
            "shadow model: 88  epoch: 109  loss= 0.08316569775342941\n",
            "shadow model: 88  epoch: 110  loss= 0.04596920683979988\n",
            "shadow model: 88  epoch: 111  loss= 0.10968475043773651\n",
            "shadow model: 88  epoch: 112  loss= 0.10137573629617691\n",
            "shadow model: 88  epoch: 113  loss= 0.06194029003381729\n",
            "shadow model: 88  epoch: 114  loss= 0.06681319326162338\n",
            "shadow model: 88  epoch: 115  loss= 0.06520643085241318\n",
            "shadow model: 88  epoch: 116  loss= 0.129143625497818\n",
            "shadow model: 88  epoch: 117  loss= 0.07569974660873413\n",
            "shadow model: 88  epoch: 118  loss= 0.06152918562293053\n",
            "shadow model: 88  epoch: 119  loss= 0.04990295693278313\n",
            "shadow model: 88  epoch: 120  loss= 0.021787434816360474\n",
            "shadow model: 88  epoch: 121  loss= 0.06240516155958176\n",
            "shadow model: 88  epoch: 122  loss= 0.14625877141952515\n",
            "shadow model: 88  epoch: 123  loss= 0.08822788298130035\n",
            "shadow model: 88  epoch: 124  loss= 0.0839979350566864\n",
            "shadow model: 88  epoch: 125  loss= 0.08700590580701828\n",
            "shadow model: 88  epoch: 126  loss= 0.014898265711963177\n",
            "shadow model: 88  epoch: 127  loss= 0.062255874276161194\n",
            "shadow model: 88  epoch: 128  loss= 0.04533624276518822\n",
            "shadow model: 88  epoch: 129  loss= 0.01807492785155773\n",
            "shadow model: 88  epoch: 130  loss= 0.05130144581198692\n",
            "shadow model: 88  epoch: 131  loss= 0.037062518298625946\n",
            "shadow model: 88  epoch: 132  loss= 0.033993206918239594\n",
            "shadow model: 88  epoch: 133  loss= 0.04996037483215332\n",
            "shadow model: 88  epoch: 134  loss= 0.007516778074204922\n",
            "shadow model: 88  epoch: 135  loss= 0.010040967725217342\n",
            "shadow model: 88  epoch: 136  loss= 0.028037937358021736\n",
            "shadow model: 88  epoch: 137  loss= 0.10116827487945557\n",
            "shadow model: 88  epoch: 138  loss= 0.04299391806125641\n",
            "shadow model: 88  epoch: 139  loss= 0.035141292959451675\n",
            "shadow model: 88  epoch: 140  loss= 0.103358194231987\n",
            "shadow model: 88  epoch: 141  loss= 0.11514095962047577\n",
            "shadow model: 88  epoch: 142  loss= 0.08979512006044388\n",
            "shadow model: 88  epoch: 143  loss= 0.06618078798055649\n",
            "shadow model: 88  epoch: 144  loss= 0.011164480820298195\n",
            "shadow model: 88  epoch: 145  loss= 0.08878600597381592\n",
            "shadow model: 88  epoch: 146  loss= 0.08119215071201324\n",
            "shadow model: 88  epoch: 147  loss= 0.125328928232193\n",
            "shadow model: 88  epoch: 148  loss= 0.07496094703674316\n",
            "shadow model: 88  epoch: 149  loss= 0.049158815294504166\n",
            "\n",
            "shadow model: 89  epoch: 0  loss= 2.3306894302368164\n",
            "shadow model: 89  epoch: 1  loss= 2.3099803924560547\n",
            "shadow model: 89  epoch: 2  loss= 2.2265446186065674\n",
            "shadow model: 89  epoch: 3  loss= 2.1577374935150146\n",
            "shadow model: 89  epoch: 4  loss= 2.0801570415496826\n",
            "shadow model: 89  epoch: 5  loss= 2.1160693168640137\n",
            "shadow model: 89  epoch: 6  loss= 1.941087007522583\n",
            "shadow model: 89  epoch: 7  loss= 1.8692784309387207\n",
            "shadow model: 89  epoch: 8  loss= 1.9969141483306885\n",
            "shadow model: 89  epoch: 9  loss= 1.8307820558547974\n",
            "shadow model: 89  epoch: 10  loss= 1.6193791627883911\n",
            "shadow model: 89  epoch: 11  loss= 1.6101816892623901\n",
            "shadow model: 89  epoch: 12  loss= 1.5039499998092651\n",
            "shadow model: 89  epoch: 13  loss= 1.4585366249084473\n",
            "shadow model: 89  epoch: 14  loss= 1.4695490598678589\n",
            "shadow model: 89  epoch: 15  loss= 1.522220492362976\n",
            "shadow model: 89  epoch: 16  loss= 1.352346658706665\n",
            "shadow model: 89  epoch: 17  loss= 1.278931975364685\n",
            "shadow model: 89  epoch: 18  loss= 1.1609748601913452\n",
            "shadow model: 89  epoch: 19  loss= 1.1197454929351807\n",
            "shadow model: 89  epoch: 20  loss= 1.2087557315826416\n",
            "shadow model: 89  epoch: 21  loss= 1.115707278251648\n",
            "shadow model: 89  epoch: 22  loss= 1.0800708532333374\n",
            "shadow model: 89  epoch: 23  loss= 0.8236467242240906\n",
            "shadow model: 89  epoch: 24  loss= 0.9762440323829651\n",
            "shadow model: 89  epoch: 25  loss= 0.6628386974334717\n",
            "shadow model: 89  epoch: 26  loss= 0.6254206895828247\n",
            "shadow model: 89  epoch: 27  loss= 0.7531957626342773\n",
            "shadow model: 89  epoch: 28  loss= 0.8049208521842957\n",
            "shadow model: 89  epoch: 29  loss= 0.5896376967430115\n",
            "shadow model: 89  epoch: 30  loss= 0.8660958409309387\n",
            "shadow model: 89  epoch: 31  loss= 0.6449673175811768\n",
            "shadow model: 89  epoch: 32  loss= 0.5340453386306763\n",
            "shadow model: 89  epoch: 33  loss= 0.5839443802833557\n",
            "shadow model: 89  epoch: 34  loss= 0.5250045657157898\n",
            "shadow model: 89  epoch: 35  loss= 0.3854343891143799\n",
            "shadow model: 89  epoch: 36  loss= 0.4489622712135315\n",
            "shadow model: 89  epoch: 37  loss= 0.48617082834243774\n",
            "shadow model: 89  epoch: 38  loss= 0.3500054180622101\n",
            "shadow model: 89  epoch: 39  loss= 0.21168583631515503\n",
            "shadow model: 89  epoch: 40  loss= 0.3509913682937622\n",
            "shadow model: 89  epoch: 41  loss= 0.41140374541282654\n",
            "shadow model: 89  epoch: 42  loss= 0.28446635603904724\n",
            "shadow model: 89  epoch: 43  loss= 0.16144387423992157\n",
            "shadow model: 89  epoch: 44  loss= 0.4591226875782013\n",
            "shadow model: 89  epoch: 45  loss= 0.2782767117023468\n",
            "shadow model: 89  epoch: 46  loss= 0.4259050190448761\n",
            "shadow model: 89  epoch: 47  loss= 0.3448083996772766\n",
            "shadow model: 89  epoch: 48  loss= 0.4139414429664612\n",
            "shadow model: 89  epoch: 49  loss= 0.27602654695510864\n",
            "shadow model: 89  epoch: 50  loss= 0.32277631759643555\n",
            "shadow model: 89  epoch: 51  loss= 0.2099367082118988\n",
            "shadow model: 89  epoch: 52  loss= 0.1936940997838974\n",
            "shadow model: 89  epoch: 53  loss= 0.2346091866493225\n",
            "shadow model: 89  epoch: 54  loss= 0.17953643202781677\n",
            "shadow model: 89  epoch: 55  loss= 0.18984675407409668\n",
            "shadow model: 89  epoch: 56  loss= 0.15605884790420532\n",
            "shadow model: 89  epoch: 57  loss= 0.3190981149673462\n",
            "shadow model: 89  epoch: 58  loss= 0.08345936983823776\n",
            "shadow model: 89  epoch: 59  loss= 0.09282365441322327\n",
            "shadow model: 89  epoch: 60  loss= 0.14041954278945923\n",
            "shadow model: 89  epoch: 61  loss= 0.19120728969573975\n",
            "shadow model: 89  epoch: 62  loss= 0.20632337033748627\n",
            "shadow model: 89  epoch: 63  loss= 0.21486350893974304\n",
            "shadow model: 89  epoch: 64  loss= 0.10522805154323578\n",
            "shadow model: 89  epoch: 65  loss= 0.16119922697544098\n",
            "shadow model: 89  epoch: 66  loss= 0.13458117842674255\n",
            "shadow model: 89  epoch: 67  loss= 0.09951060265302658\n",
            "shadow model: 89  epoch: 68  loss= 0.10409486293792725\n",
            "shadow model: 89  epoch: 69  loss= 0.11415830254554749\n",
            "shadow model: 89  epoch: 70  loss= 0.16695402562618256\n",
            "shadow model: 89  epoch: 71  loss= 0.1914585530757904\n",
            "shadow model: 89  epoch: 72  loss= 0.14367948472499847\n",
            "shadow model: 89  epoch: 73  loss= 0.13511492311954498\n",
            "shadow model: 89  epoch: 74  loss= 0.1936710923910141\n",
            "shadow model: 89  epoch: 75  loss= 0.10285665839910507\n",
            "shadow model: 89  epoch: 76  loss= 0.2187928557395935\n",
            "shadow model: 89  epoch: 77  loss= 0.22457680106163025\n",
            "shadow model: 89  epoch: 78  loss= 0.079803466796875\n",
            "shadow model: 89  epoch: 79  loss= 0.12145613878965378\n",
            "shadow model: 89  epoch: 80  loss= 0.06849879026412964\n",
            "shadow model: 89  epoch: 81  loss= 0.13738538324832916\n",
            "shadow model: 89  epoch: 82  loss= 0.0882137268781662\n",
            "shadow model: 89  epoch: 83  loss= 0.04769335314631462\n",
            "shadow model: 89  epoch: 84  loss= 0.07909605652093887\n",
            "shadow model: 89  epoch: 85  loss= 0.09374694526195526\n",
            "shadow model: 89  epoch: 86  loss= 0.10784047096967697\n",
            "shadow model: 89  epoch: 87  loss= 0.13268263638019562\n",
            "shadow model: 89  epoch: 88  loss= 0.07182782143354416\n",
            "shadow model: 89  epoch: 89  loss= 0.1681842803955078\n",
            "shadow model: 89  epoch: 90  loss= 0.06339763849973679\n",
            "shadow model: 89  epoch: 91  loss= 0.10593228787183762\n",
            "shadow model: 89  epoch: 92  loss= 0.08606713265180588\n",
            "shadow model: 89  epoch: 93  loss= 0.11144628375768661\n",
            "shadow model: 89  epoch: 94  loss= 0.10765786468982697\n",
            "shadow model: 89  epoch: 95  loss= 0.10868900269269943\n",
            "shadow model: 89  epoch: 96  loss= 0.07435707747936249\n",
            "shadow model: 89  epoch: 97  loss= 0.13853496313095093\n",
            "shadow model: 89  epoch: 98  loss= 0.17478354275226593\n",
            "shadow model: 89  epoch: 99  loss= 0.17722904682159424\n",
            "shadow model: 89  epoch: 100  loss= 0.045763131231069565\n",
            "shadow model: 89  epoch: 101  loss= 0.10200123488903046\n",
            "shadow model: 89  epoch: 102  loss= 0.04298672080039978\n",
            "shadow model: 89  epoch: 103  loss= 0.1167445108294487\n",
            "shadow model: 89  epoch: 104  loss= 0.06157955527305603\n",
            "shadow model: 89  epoch: 105  loss= 0.07902351021766663\n",
            "shadow model: 89  epoch: 106  loss= 0.07901845127344131\n",
            "shadow model: 89  epoch: 107  loss= 0.08463216572999954\n",
            "shadow model: 89  epoch: 108  loss= 0.030124004930257797\n",
            "shadow model: 89  epoch: 109  loss= 0.05526212975382805\n",
            "shadow model: 89  epoch: 110  loss= 0.10804113000631332\n",
            "shadow model: 89  epoch: 111  loss= 0.12320096045732498\n",
            "shadow model: 89  epoch: 112  loss= 0.09813953191041946\n",
            "shadow model: 89  epoch: 113  loss= 0.07476404309272766\n",
            "shadow model: 89  epoch: 114  loss= 0.09937459230422974\n",
            "shadow model: 89  epoch: 115  loss= 0.034240297973155975\n",
            "shadow model: 89  epoch: 116  loss= 0.04629494249820709\n",
            "shadow model: 89  epoch: 117  loss= 0.0708768367767334\n",
            "shadow model: 89  epoch: 118  loss= 0.09800020605325699\n",
            "shadow model: 89  epoch: 119  loss= 0.019933760166168213\n",
            "shadow model: 89  epoch: 120  loss= 0.04393277317285538\n",
            "shadow model: 89  epoch: 121  loss= 0.16685067117214203\n",
            "shadow model: 89  epoch: 122  loss= 0.21536220610141754\n",
            "shadow model: 89  epoch: 123  loss= 0.1518252193927765\n",
            "shadow model: 89  epoch: 124  loss= 0.12051835656166077\n",
            "shadow model: 89  epoch: 125  loss= 0.08247064054012299\n",
            "shadow model: 89  epoch: 126  loss= 0.09296121448278427\n",
            "shadow model: 89  epoch: 127  loss= 0.038296252489089966\n",
            "shadow model: 89  epoch: 128  loss= 0.03364105895161629\n",
            "shadow model: 89  epoch: 129  loss= 0.02994515188038349\n",
            "shadow model: 89  epoch: 130  loss= 0.06446797400712967\n",
            "shadow model: 89  epoch: 131  loss= 0.07260600477457047\n",
            "shadow model: 89  epoch: 132  loss= 0.19431686401367188\n",
            "shadow model: 89  epoch: 133  loss= 0.07134465873241425\n",
            "shadow model: 89  epoch: 134  loss= 0.09204796701669693\n",
            "shadow model: 89  epoch: 135  loss= 0.05168328806757927\n",
            "shadow model: 89  epoch: 136  loss= 0.03429294750094414\n",
            "shadow model: 89  epoch: 137  loss= 0.018278010189533234\n",
            "shadow model: 89  epoch: 138  loss= 0.08481594920158386\n",
            "shadow model: 89  epoch: 139  loss= 0.0632188692688942\n",
            "shadow model: 89  epoch: 140  loss= 0.09690593183040619\n",
            "shadow model: 89  epoch: 141  loss= 0.0226758923381567\n",
            "shadow model: 89  epoch: 142  loss= 0.057652123272418976\n",
            "shadow model: 89  epoch: 143  loss= 0.06764600425958633\n",
            "shadow model: 89  epoch: 144  loss= 0.05199688673019409\n",
            "shadow model: 89  epoch: 145  loss= 0.04264989495277405\n",
            "shadow model: 89  epoch: 146  loss= 0.03394455462694168\n",
            "shadow model: 89  epoch: 147  loss= 0.07303696125745773\n",
            "shadow model: 89  epoch: 148  loss= 0.020373212173581123\n",
            "shadow model: 89  epoch: 149  loss= 0.09012950211763382\n",
            "\n",
            "shadow model: 90  epoch: 0  loss= 2.298210382461548\n",
            "shadow model: 90  epoch: 1  loss= 2.2609076499938965\n",
            "shadow model: 90  epoch: 2  loss= 2.2412214279174805\n",
            "shadow model: 90  epoch: 3  loss= 2.1432299613952637\n",
            "shadow model: 90  epoch: 4  loss= 2.0077853202819824\n",
            "shadow model: 90  epoch: 5  loss= 2.1675117015838623\n",
            "shadow model: 90  epoch: 6  loss= 2.0183088779449463\n",
            "shadow model: 90  epoch: 7  loss= 1.7510136365890503\n",
            "shadow model: 90  epoch: 8  loss= 1.7351784706115723\n",
            "shadow model: 90  epoch: 9  loss= 1.670588731765747\n",
            "shadow model: 90  epoch: 10  loss= 1.7089627981185913\n",
            "shadow model: 90  epoch: 11  loss= 1.642610788345337\n",
            "shadow model: 90  epoch: 12  loss= 1.458534598350525\n",
            "shadow model: 90  epoch: 13  loss= 1.3536101579666138\n",
            "shadow model: 90  epoch: 14  loss= 1.2232763767242432\n",
            "shadow model: 90  epoch: 15  loss= 1.3882204294204712\n",
            "shadow model: 90  epoch: 16  loss= 1.4042227268218994\n",
            "shadow model: 90  epoch: 17  loss= 1.4277106523513794\n",
            "shadow model: 90  epoch: 18  loss= 1.0743217468261719\n",
            "shadow model: 90  epoch: 19  loss= 0.8776136636734009\n",
            "shadow model: 90  epoch: 20  loss= 0.7727171778678894\n",
            "shadow model: 90  epoch: 21  loss= 0.9881641864776611\n",
            "shadow model: 90  epoch: 22  loss= 0.8080553412437439\n",
            "shadow model: 90  epoch: 23  loss= 0.7318297624588013\n",
            "shadow model: 90  epoch: 24  loss= 0.9036142826080322\n",
            "shadow model: 90  epoch: 25  loss= 0.6827850937843323\n",
            "shadow model: 90  epoch: 26  loss= 0.5794627070426941\n",
            "shadow model: 90  epoch: 27  loss= 0.5761318802833557\n",
            "shadow model: 90  epoch: 28  loss= 0.6284099221229553\n",
            "shadow model: 90  epoch: 29  loss= 0.6949864029884338\n",
            "shadow model: 90  epoch: 30  loss= 0.5026814937591553\n",
            "shadow model: 90  epoch: 31  loss= 0.264516144990921\n",
            "shadow model: 90  epoch: 32  loss= 0.43290841579437256\n",
            "shadow model: 90  epoch: 33  loss= 0.5385822057723999\n",
            "shadow model: 90  epoch: 34  loss= 0.43281182646751404\n",
            "shadow model: 90  epoch: 35  loss= 0.46290189027786255\n",
            "shadow model: 90  epoch: 36  loss= 0.4162328541278839\n",
            "shadow model: 90  epoch: 37  loss= 0.34568116068840027\n",
            "shadow model: 90  epoch: 38  loss= 0.296529084444046\n",
            "shadow model: 90  epoch: 39  loss= 0.3840201497077942\n",
            "shadow model: 90  epoch: 40  loss= 0.3521849811077118\n",
            "shadow model: 90  epoch: 41  loss= 0.25715339183807373\n",
            "shadow model: 90  epoch: 42  loss= 0.21079064905643463\n",
            "shadow model: 90  epoch: 43  loss= 0.2078397125005722\n",
            "shadow model: 90  epoch: 44  loss= 0.23615768551826477\n",
            "shadow model: 90  epoch: 45  loss= 0.21793138980865479\n",
            "shadow model: 90  epoch: 46  loss= 0.1877286434173584\n",
            "shadow model: 90  epoch: 47  loss= 0.15807421505451202\n",
            "shadow model: 90  epoch: 48  loss= 0.14174295961856842\n",
            "shadow model: 90  epoch: 49  loss= 0.13452783226966858\n",
            "shadow model: 90  epoch: 50  loss= 0.21094496548175812\n",
            "shadow model: 90  epoch: 51  loss= 0.26420485973358154\n",
            "shadow model: 90  epoch: 52  loss= 0.15464414656162262\n",
            "shadow model: 90  epoch: 53  loss= 0.15696001052856445\n",
            "shadow model: 90  epoch: 54  loss= 0.1431024670600891\n",
            "shadow model: 90  epoch: 55  loss= 0.2117653340101242\n",
            "shadow model: 90  epoch: 56  loss= 0.14596284925937653\n",
            "shadow model: 90  epoch: 57  loss= 0.24517938494682312\n",
            "shadow model: 90  epoch: 58  loss= 0.1342909038066864\n",
            "shadow model: 90  epoch: 59  loss= 0.12815521657466888\n",
            "shadow model: 90  epoch: 60  loss= 0.17801763117313385\n",
            "shadow model: 90  epoch: 61  loss= 0.1684962958097458\n",
            "shadow model: 90  epoch: 62  loss= 0.28653013706207275\n",
            "shadow model: 90  epoch: 63  loss= 0.14631669223308563\n",
            "shadow model: 90  epoch: 64  loss= 0.16043706238269806\n",
            "shadow model: 90  epoch: 65  loss= 0.09730565547943115\n",
            "shadow model: 90  epoch: 66  loss= 0.20773397386074066\n",
            "shadow model: 90  epoch: 67  loss= 0.1077570840716362\n",
            "shadow model: 90  epoch: 68  loss= 0.11382554471492767\n",
            "shadow model: 90  epoch: 69  loss= 0.13920170068740845\n",
            "shadow model: 90  epoch: 70  loss= 0.31899574398994446\n",
            "shadow model: 90  epoch: 71  loss= 0.0730605497956276\n",
            "shadow model: 90  epoch: 72  loss= 0.18916429579257965\n",
            "shadow model: 90  epoch: 73  loss= 0.13467152416706085\n",
            "shadow model: 90  epoch: 74  loss= 0.17159684002399445\n",
            "shadow model: 90  epoch: 75  loss= 0.09044672548770905\n",
            "shadow model: 90  epoch: 76  loss= 0.09172102808952332\n",
            "shadow model: 90  epoch: 77  loss= 0.10394252091646194\n",
            "shadow model: 90  epoch: 78  loss= 0.09167823940515518\n",
            "shadow model: 90  epoch: 79  loss= 0.1766606867313385\n",
            "shadow model: 90  epoch: 80  loss= 0.1174483522772789\n",
            "shadow model: 90  epoch: 81  loss= 0.12403322011232376\n",
            "shadow model: 90  epoch: 82  loss= 0.050219640135765076\n",
            "shadow model: 90  epoch: 83  loss= 0.25714507699012756\n",
            "shadow model: 90  epoch: 84  loss= 0.12579110264778137\n",
            "shadow model: 90  epoch: 85  loss= 0.05491218715906143\n",
            "shadow model: 90  epoch: 86  loss= 0.10575490444898605\n",
            "shadow model: 90  epoch: 87  loss= 0.09104926884174347\n",
            "shadow model: 90  epoch: 88  loss= 0.1656077653169632\n",
            "shadow model: 90  epoch: 89  loss= 0.08685840666294098\n",
            "shadow model: 90  epoch: 90  loss= 0.10302270948886871\n",
            "shadow model: 90  epoch: 91  loss= 0.09422513097524643\n",
            "shadow model: 90  epoch: 92  loss= 0.14795437455177307\n",
            "shadow model: 90  epoch: 93  loss= 0.18659918010234833\n",
            "shadow model: 90  epoch: 94  loss= 0.06702671945095062\n",
            "shadow model: 90  epoch: 95  loss= 0.11384773254394531\n",
            "shadow model: 90  epoch: 96  loss= 0.07522021979093552\n",
            "shadow model: 90  epoch: 97  loss= 0.034166134893894196\n",
            "shadow model: 90  epoch: 98  loss= 0.09942125529050827\n",
            "shadow model: 90  epoch: 99  loss= 0.09546594321727753\n",
            "shadow model: 90  epoch: 100  loss= 0.03484926000237465\n",
            "shadow model: 90  epoch: 101  loss= 0.0861038863658905\n",
            "shadow model: 90  epoch: 102  loss= 0.09815037995576859\n",
            "shadow model: 90  epoch: 103  loss= 0.02407119981944561\n",
            "shadow model: 90  epoch: 104  loss= 0.05835814028978348\n",
            "shadow model: 90  epoch: 105  loss= 0.09599948674440384\n",
            "shadow model: 90  epoch: 106  loss= 0.1168564185500145\n",
            "shadow model: 90  epoch: 107  loss= 0.04340365529060364\n",
            "shadow model: 90  epoch: 108  loss= 0.1430462747812271\n",
            "shadow model: 90  epoch: 109  loss= 0.07896210998296738\n",
            "shadow model: 90  epoch: 110  loss= 0.14537940919399261\n",
            "shadow model: 90  epoch: 111  loss= 0.2595714330673218\n",
            "shadow model: 90  epoch: 112  loss= 0.044521622359752655\n",
            "shadow model: 90  epoch: 113  loss= 0.07599480450153351\n",
            "shadow model: 90  epoch: 114  loss= 0.12644001841545105\n",
            "shadow model: 90  epoch: 115  loss= 0.025692468509078026\n",
            "shadow model: 90  epoch: 116  loss= 0.03926287218928337\n",
            "shadow model: 90  epoch: 117  loss= 0.06986036151647568\n",
            "shadow model: 90  epoch: 118  loss= 0.04738045111298561\n",
            "shadow model: 90  epoch: 119  loss= 0.05728793516755104\n",
            "shadow model: 90  epoch: 120  loss= 0.04618989676237106\n",
            "shadow model: 90  epoch: 121  loss= 0.04413958266377449\n",
            "shadow model: 90  epoch: 122  loss= 0.13929852843284607\n",
            "shadow model: 90  epoch: 123  loss= 0.07369724661111832\n",
            "shadow model: 90  epoch: 124  loss= 0.04614908993244171\n",
            "shadow model: 90  epoch: 125  loss= 0.04671100899577141\n",
            "shadow model: 90  epoch: 126  loss= 0.019239364191889763\n",
            "shadow model: 90  epoch: 127  loss= 0.03939526528120041\n",
            "shadow model: 90  epoch: 128  loss= 0.04521574825048447\n",
            "shadow model: 90  epoch: 129  loss= 0.13289006054401398\n",
            "shadow model: 90  epoch: 130  loss= 0.03350641578435898\n",
            "shadow model: 90  epoch: 131  loss= 0.11232439428567886\n",
            "shadow model: 90  epoch: 132  loss= 0.042752042412757874\n",
            "shadow model: 90  epoch: 133  loss= 0.12350316345691681\n",
            "shadow model: 90  epoch: 134  loss= 0.10683192312717438\n",
            "shadow model: 90  epoch: 135  loss= 0.06753207743167877\n",
            "shadow model: 90  epoch: 136  loss= 0.06025715544819832\n",
            "shadow model: 90  epoch: 137  loss= 0.04327085241675377\n",
            "shadow model: 90  epoch: 138  loss= 0.05420171841979027\n",
            "shadow model: 90  epoch: 139  loss= 0.06901782751083374\n",
            "shadow model: 90  epoch: 140  loss= 0.030776752158999443\n",
            "shadow model: 90  epoch: 141  loss= 0.010858679190278053\n",
            "shadow model: 90  epoch: 142  loss= 0.08585842698812485\n",
            "shadow model: 90  epoch: 143  loss= 0.0764954537153244\n",
            "shadow model: 90  epoch: 144  loss= 0.03568854555487633\n",
            "shadow model: 90  epoch: 145  loss= 0.11939370632171631\n",
            "shadow model: 90  epoch: 146  loss= 0.021219829097390175\n",
            "shadow model: 90  epoch: 147  loss= 0.08388485014438629\n",
            "shadow model: 90  epoch: 148  loss= 0.032926809042692184\n",
            "shadow model: 90  epoch: 149  loss= 0.034966908395290375\n",
            "\n",
            "shadow model: 91  epoch: 0  loss= 2.3311240673065186\n",
            "shadow model: 91  epoch: 1  loss= 2.2932841777801514\n",
            "shadow model: 91  epoch: 2  loss= 2.23422908782959\n",
            "shadow model: 91  epoch: 3  loss= 2.168102741241455\n",
            "shadow model: 91  epoch: 4  loss= 2.0773985385894775\n",
            "shadow model: 91  epoch: 5  loss= 2.0408241748809814\n",
            "shadow model: 91  epoch: 6  loss= 2.075256586074829\n",
            "shadow model: 91  epoch: 7  loss= 1.889133095741272\n",
            "shadow model: 91  epoch: 8  loss= 2.0142412185668945\n",
            "shadow model: 91  epoch: 9  loss= 1.958622694015503\n",
            "shadow model: 91  epoch: 10  loss= 1.8149272203445435\n",
            "shadow model: 91  epoch: 11  loss= 1.6214396953582764\n",
            "shadow model: 91  epoch: 12  loss= 1.7293524742126465\n",
            "shadow model: 91  epoch: 13  loss= 1.6804503202438354\n",
            "shadow model: 91  epoch: 14  loss= 1.6191306114196777\n",
            "shadow model: 91  epoch: 15  loss= 1.5596977472305298\n",
            "shadow model: 91  epoch: 16  loss= 1.2610799074172974\n",
            "shadow model: 91  epoch: 17  loss= 1.365839958190918\n",
            "shadow model: 91  epoch: 18  loss= 1.3452008962631226\n",
            "shadow model: 91  epoch: 19  loss= 1.1418876647949219\n",
            "shadow model: 91  epoch: 20  loss= 1.1408584117889404\n",
            "shadow model: 91  epoch: 21  loss= 1.1387732028961182\n",
            "shadow model: 91  epoch: 22  loss= 1.0432958602905273\n",
            "shadow model: 91  epoch: 23  loss= 1.162357211112976\n",
            "shadow model: 91  epoch: 24  loss= 0.8149034976959229\n",
            "shadow model: 91  epoch: 25  loss= 1.0580824613571167\n",
            "shadow model: 91  epoch: 26  loss= 0.9114621877670288\n",
            "shadow model: 91  epoch: 27  loss= 0.7900711297988892\n",
            "shadow model: 91  epoch: 28  loss= 0.8809419870376587\n",
            "shadow model: 91  epoch: 29  loss= 0.6608680486679077\n",
            "shadow model: 91  epoch: 30  loss= 0.6283838748931885\n",
            "shadow model: 91  epoch: 31  loss= 0.596580982208252\n",
            "shadow model: 91  epoch: 32  loss= 0.8162918090820312\n",
            "shadow model: 91  epoch: 33  loss= 0.5680940747261047\n",
            "shadow model: 91  epoch: 34  loss= 0.6505286693572998\n",
            "shadow model: 91  epoch: 35  loss= 0.4580550491809845\n",
            "shadow model: 91  epoch: 36  loss= 0.48457106947898865\n",
            "shadow model: 91  epoch: 37  loss= 0.34709203243255615\n",
            "shadow model: 91  epoch: 38  loss= 0.4538819193840027\n",
            "shadow model: 91  epoch: 39  loss= 0.3248938322067261\n",
            "shadow model: 91  epoch: 40  loss= 0.43789413571357727\n",
            "shadow model: 91  epoch: 41  loss= 0.36046963930130005\n",
            "shadow model: 91  epoch: 42  loss= 0.3281513452529907\n",
            "shadow model: 91  epoch: 43  loss= 0.43389424681663513\n",
            "shadow model: 91  epoch: 44  loss= 0.34917643666267395\n",
            "shadow model: 91  epoch: 45  loss= 0.25699540972709656\n",
            "shadow model: 91  epoch: 46  loss= 0.20549030601978302\n",
            "shadow model: 91  epoch: 47  loss= 0.19421976804733276\n",
            "shadow model: 91  epoch: 48  loss= 0.20064829289913177\n",
            "shadow model: 91  epoch: 49  loss= 0.37163829803466797\n",
            "shadow model: 91  epoch: 50  loss= 0.34025809168815613\n",
            "shadow model: 91  epoch: 51  loss= 0.19833864271640778\n",
            "shadow model: 91  epoch: 52  loss= 0.32885056734085083\n",
            "shadow model: 91  epoch: 53  loss= 0.22987781465053558\n",
            "shadow model: 91  epoch: 54  loss= 0.21591483056545258\n",
            "shadow model: 91  epoch: 55  loss= 0.265851229429245\n",
            "shadow model: 91  epoch: 56  loss= 0.2285483032464981\n",
            "shadow model: 91  epoch: 57  loss= 0.1513734757900238\n",
            "shadow model: 91  epoch: 58  loss= 0.13109825551509857\n",
            "shadow model: 91  epoch: 59  loss= 0.20252542197704315\n",
            "shadow model: 91  epoch: 60  loss= 0.19178830087184906\n",
            "shadow model: 91  epoch: 61  loss= 0.22538644075393677\n",
            "shadow model: 91  epoch: 62  loss= 0.14488527178764343\n",
            "shadow model: 91  epoch: 63  loss= 0.2017948478460312\n",
            "shadow model: 91  epoch: 64  loss= 0.11462337523698807\n",
            "shadow model: 91  epoch: 65  loss= 0.23054976761341095\n",
            "shadow model: 91  epoch: 66  loss= 0.21154998242855072\n",
            "shadow model: 91  epoch: 67  loss= 0.2569495737552643\n",
            "shadow model: 91  epoch: 68  loss= 0.101915642619133\n",
            "shadow model: 91  epoch: 69  loss= 0.1331910640001297\n",
            "shadow model: 91  epoch: 70  loss= 0.13964466750621796\n",
            "shadow model: 91  epoch: 71  loss= 0.2030959129333496\n",
            "shadow model: 91  epoch: 72  loss= 0.07004690915346146\n",
            "shadow model: 91  epoch: 73  loss= 0.21855254471302032\n",
            "shadow model: 91  epoch: 74  loss= 0.1818511039018631\n",
            "shadow model: 91  epoch: 75  loss= 0.183991476893425\n",
            "shadow model: 91  epoch: 76  loss= 0.16475465893745422\n",
            "shadow model: 91  epoch: 77  loss= 0.10526084154844284\n",
            "shadow model: 91  epoch: 78  loss= 0.17026619613170624\n",
            "shadow model: 91  epoch: 79  loss= 0.20308555662631989\n",
            "shadow model: 91  epoch: 80  loss= 0.25674542784690857\n",
            "shadow model: 91  epoch: 81  loss= 0.10611904412508011\n",
            "shadow model: 91  epoch: 82  loss= 0.11239375919103622\n",
            "shadow model: 91  epoch: 83  loss= 0.1220204159617424\n",
            "shadow model: 91  epoch: 84  loss= 0.14473924040794373\n",
            "shadow model: 91  epoch: 85  loss= 0.150283545255661\n",
            "shadow model: 91  epoch: 86  loss= 0.09443109482526779\n",
            "shadow model: 91  epoch: 87  loss= 0.08805575966835022\n",
            "shadow model: 91  epoch: 88  loss= 0.13455305993556976\n",
            "shadow model: 91  epoch: 89  loss= 0.1168924868106842\n",
            "shadow model: 91  epoch: 90  loss= 0.032440949231386185\n",
            "shadow model: 91  epoch: 91  loss= 0.15041977167129517\n",
            "shadow model: 91  epoch: 92  loss= 0.09844360500574112\n",
            "shadow model: 91  epoch: 93  loss= 0.09363552927970886\n",
            "shadow model: 91  epoch: 94  loss= 0.12960021197795868\n",
            "shadow model: 91  epoch: 95  loss= 0.15220288932323456\n",
            "shadow model: 91  epoch: 96  loss= 0.24250537157058716\n",
            "shadow model: 91  epoch: 97  loss= 0.11323080211877823\n",
            "shadow model: 91  epoch: 98  loss= 0.1502366065979004\n",
            "shadow model: 91  epoch: 99  loss= 0.13389697670936584\n",
            "shadow model: 91  epoch: 100  loss= 0.05299343168735504\n",
            "shadow model: 91  epoch: 101  loss= 0.07353842258453369\n",
            "shadow model: 91  epoch: 102  loss= 0.1434517353773117\n",
            "shadow model: 91  epoch: 103  loss= 0.13872303068637848\n",
            "shadow model: 91  epoch: 104  loss= 0.07659498602151871\n",
            "shadow model: 91  epoch: 105  loss= 0.07770324498414993\n",
            "shadow model: 91  epoch: 106  loss= 0.07533928751945496\n",
            "shadow model: 91  epoch: 107  loss= 0.10483428835868835\n",
            "shadow model: 91  epoch: 108  loss= 0.05894644185900688\n",
            "shadow model: 91  epoch: 109  loss= 0.04083983972668648\n",
            "shadow model: 91  epoch: 110  loss= 0.09541832655668259\n",
            "shadow model: 91  epoch: 111  loss= 0.09748964756727219\n",
            "shadow model: 91  epoch: 112  loss= 0.10636253654956818\n",
            "shadow model: 91  epoch: 113  loss= 0.049510423094034195\n",
            "shadow model: 91  epoch: 114  loss= 0.19163647294044495\n",
            "shadow model: 91  epoch: 115  loss= 0.12457916885614395\n",
            "shadow model: 91  epoch: 116  loss= 0.03965598717331886\n",
            "shadow model: 91  epoch: 117  loss= 0.0710761770606041\n",
            "shadow model: 91  epoch: 118  loss= 0.09607852250337601\n",
            "shadow model: 91  epoch: 119  loss= 0.026681650429964066\n",
            "shadow model: 91  epoch: 120  loss= 0.11597440391778946\n",
            "shadow model: 91  epoch: 121  loss= 0.03195854648947716\n",
            "shadow model: 91  epoch: 122  loss= 0.037278905510902405\n",
            "shadow model: 91  epoch: 123  loss= 0.09974507987499237\n",
            "shadow model: 91  epoch: 124  loss= 0.16011486947536469\n",
            "shadow model: 91  epoch: 125  loss= 0.2029750943183899\n",
            "shadow model: 91  epoch: 126  loss= 0.10825499892234802\n",
            "shadow model: 91  epoch: 127  loss= 0.09090530127286911\n",
            "shadow model: 91  epoch: 128  loss= 0.10649997740983963\n",
            "shadow model: 91  epoch: 129  loss= 0.1035793274641037\n",
            "shadow model: 91  epoch: 130  loss= 0.10965944081544876\n",
            "shadow model: 91  epoch: 131  loss= 0.1460265964269638\n",
            "shadow model: 91  epoch: 132  loss= 0.026948459446430206\n",
            "shadow model: 91  epoch: 133  loss= 0.10713977366685867\n",
            "shadow model: 91  epoch: 134  loss= 0.08693774789571762\n",
            "shadow model: 91  epoch: 135  loss= 0.061795685440301895\n",
            "shadow model: 91  epoch: 136  loss= 0.060448721051216125\n",
            "shadow model: 91  epoch: 137  loss= 0.11561769992113113\n",
            "shadow model: 91  epoch: 138  loss= 0.039665523916482925\n",
            "shadow model: 91  epoch: 139  loss= 0.025778699666261673\n",
            "shadow model: 91  epoch: 140  loss= 0.1028088629245758\n",
            "shadow model: 91  epoch: 141  loss= 0.14400583505630493\n",
            "shadow model: 91  epoch: 142  loss= 0.13100861012935638\n",
            "shadow model: 91  epoch: 143  loss= 0.08357545733451843\n",
            "shadow model: 91  epoch: 144  loss= 0.11155955493450165\n",
            "shadow model: 91  epoch: 145  loss= 0.2000102400779724\n",
            "shadow model: 91  epoch: 146  loss= 0.02289643883705139\n",
            "shadow model: 91  epoch: 147  loss= 0.0538238063454628\n",
            "shadow model: 91  epoch: 148  loss= 0.06593183428049088\n",
            "shadow model: 91  epoch: 149  loss= 0.117160864174366\n",
            "\n",
            "shadow model: 92  epoch: 0  loss= 2.3500239849090576\n",
            "shadow model: 92  epoch: 1  loss= 2.228726387023926\n",
            "shadow model: 92  epoch: 2  loss= 2.212120532989502\n",
            "shadow model: 92  epoch: 3  loss= 2.0878407955169678\n",
            "shadow model: 92  epoch: 4  loss= 1.9770480394363403\n",
            "shadow model: 92  epoch: 5  loss= 1.8946553468704224\n",
            "shadow model: 92  epoch: 6  loss= 2.029458999633789\n",
            "shadow model: 92  epoch: 7  loss= 1.7911200523376465\n",
            "shadow model: 92  epoch: 8  loss= 1.8399536609649658\n",
            "shadow model: 92  epoch: 9  loss= 1.5772678852081299\n",
            "shadow model: 92  epoch: 10  loss= 1.590415596961975\n",
            "shadow model: 92  epoch: 11  loss= 1.531681776046753\n",
            "shadow model: 92  epoch: 12  loss= 1.327714204788208\n",
            "shadow model: 92  epoch: 13  loss= 1.5129245519638062\n",
            "shadow model: 92  epoch: 14  loss= 1.2264189720153809\n",
            "shadow model: 92  epoch: 15  loss= 1.165162205696106\n",
            "shadow model: 92  epoch: 16  loss= 1.146950602531433\n",
            "shadow model: 92  epoch: 17  loss= 1.0188010931015015\n",
            "shadow model: 92  epoch: 18  loss= 0.8551122546195984\n",
            "shadow model: 92  epoch: 19  loss= 1.1359106302261353\n",
            "shadow model: 92  epoch: 20  loss= 1.0422492027282715\n",
            "shadow model: 92  epoch: 21  loss= 0.8548213839530945\n",
            "shadow model: 92  epoch: 22  loss= 0.7675673961639404\n",
            "shadow model: 92  epoch: 23  loss= 0.9499974846839905\n",
            "shadow model: 92  epoch: 24  loss= 0.6514750123023987\n",
            "shadow model: 92  epoch: 25  loss= 0.7938512563705444\n",
            "shadow model: 92  epoch: 26  loss= 0.6086569428443909\n",
            "shadow model: 92  epoch: 27  loss= 0.5693110823631287\n",
            "shadow model: 92  epoch: 28  loss= 0.6757057309150696\n",
            "shadow model: 92  epoch: 29  loss= 0.5392410159111023\n",
            "shadow model: 92  epoch: 30  loss= 0.36487627029418945\n",
            "shadow model: 92  epoch: 31  loss= 0.5186020731925964\n",
            "shadow model: 92  epoch: 32  loss= 0.5090393424034119\n",
            "shadow model: 92  epoch: 33  loss= 0.3039431869983673\n",
            "shadow model: 92  epoch: 34  loss= 0.4330044686794281\n",
            "shadow model: 92  epoch: 35  loss= 0.3376155197620392\n",
            "shadow model: 92  epoch: 36  loss= 0.3411257565021515\n",
            "shadow model: 92  epoch: 37  loss= 0.3331988453865051\n",
            "shadow model: 92  epoch: 38  loss= 0.3143461048603058\n",
            "shadow model: 92  epoch: 39  loss= 0.2094396948814392\n",
            "shadow model: 92  epoch: 40  loss= 0.2921113967895508\n",
            "shadow model: 92  epoch: 41  loss= 0.3246074914932251\n",
            "shadow model: 92  epoch: 42  loss= 0.20932073891162872\n",
            "shadow model: 92  epoch: 43  loss= 0.3035929501056671\n",
            "shadow model: 92  epoch: 44  loss= 0.2114448994398117\n",
            "shadow model: 92  epoch: 45  loss= 0.22051171958446503\n",
            "shadow model: 92  epoch: 46  loss= 0.24945653975009918\n",
            "shadow model: 92  epoch: 47  loss= 0.4215635061264038\n",
            "shadow model: 92  epoch: 48  loss= 0.3331036865711212\n",
            "shadow model: 92  epoch: 49  loss= 0.3449096977710724\n",
            "shadow model: 92  epoch: 50  loss= 0.19215212762355804\n",
            "shadow model: 92  epoch: 51  loss= 0.28807783126831055\n",
            "shadow model: 92  epoch: 52  loss= 0.257621705532074\n",
            "shadow model: 92  epoch: 53  loss= 0.1946919560432434\n",
            "shadow model: 92  epoch: 54  loss= 0.24881796538829803\n",
            "shadow model: 92  epoch: 55  loss= 0.2717224359512329\n",
            "shadow model: 92  epoch: 56  loss= 0.13954411447048187\n",
            "shadow model: 92  epoch: 57  loss= 0.19979964196681976\n",
            "shadow model: 92  epoch: 58  loss= 0.07962413877248764\n",
            "shadow model: 92  epoch: 59  loss= 0.11388608813285828\n",
            "shadow model: 92  epoch: 60  loss= 0.16644710302352905\n",
            "shadow model: 92  epoch: 61  loss= 0.10475308448076248\n",
            "shadow model: 92  epoch: 62  loss= 0.0645231232047081\n",
            "shadow model: 92  epoch: 63  loss= 0.1746872216463089\n",
            "shadow model: 92  epoch: 64  loss= 0.11432377994060516\n",
            "shadow model: 92  epoch: 65  loss= 0.27440404891967773\n",
            "shadow model: 92  epoch: 66  loss= 0.22221285104751587\n",
            "shadow model: 92  epoch: 67  loss= 0.05296417325735092\n",
            "shadow model: 92  epoch: 68  loss= 0.13930906355381012\n",
            "shadow model: 92  epoch: 69  loss= 0.3008028268814087\n",
            "shadow model: 92  epoch: 70  loss= 0.13675802946090698\n",
            "shadow model: 92  epoch: 71  loss= 0.11972348392009735\n",
            "shadow model: 92  epoch: 72  loss= 0.22408966720104218\n",
            "shadow model: 92  epoch: 73  loss= 0.1874946504831314\n",
            "shadow model: 92  epoch: 74  loss= 0.0719495415687561\n",
            "shadow model: 92  epoch: 75  loss= 0.08629720658063889\n",
            "shadow model: 92  epoch: 76  loss= 0.1298452466726303\n",
            "shadow model: 92  epoch: 77  loss= 0.0742715448141098\n",
            "shadow model: 92  epoch: 78  loss= 0.11985040456056595\n",
            "shadow model: 92  epoch: 79  loss= 0.1642095148563385\n",
            "shadow model: 92  epoch: 80  loss= 0.17730073630809784\n",
            "shadow model: 92  epoch: 81  loss= 0.1250767707824707\n",
            "shadow model: 92  epoch: 82  loss= 0.05064784362912178\n",
            "shadow model: 92  epoch: 83  loss= 0.1250920444726944\n",
            "shadow model: 92  epoch: 84  loss= 0.09619835019111633\n",
            "shadow model: 92  epoch: 85  loss= 0.1194021999835968\n",
            "shadow model: 92  epoch: 86  loss= 0.11204054951667786\n",
            "shadow model: 92  epoch: 87  loss= 0.08764611929655075\n",
            "shadow model: 92  epoch: 88  loss= 0.14993548393249512\n",
            "shadow model: 92  epoch: 89  loss= 0.11195656657218933\n",
            "shadow model: 92  epoch: 90  loss= 0.11649096757173538\n",
            "shadow model: 92  epoch: 91  loss= 0.25544068217277527\n",
            "shadow model: 92  epoch: 92  loss= 0.06518996506929398\n",
            "shadow model: 92  epoch: 93  loss= 0.12889663875102997\n",
            "shadow model: 92  epoch: 94  loss= 0.09925754368305206\n",
            "shadow model: 92  epoch: 95  loss= 0.09973519295454025\n",
            "shadow model: 92  epoch: 96  loss= 0.04469359293580055\n",
            "shadow model: 92  epoch: 97  loss= 0.1279727816581726\n",
            "shadow model: 92  epoch: 98  loss= 0.14027000963687897\n",
            "shadow model: 92  epoch: 99  loss= 0.16687890887260437\n",
            "shadow model: 92  epoch: 100  loss= 0.10718531161546707\n",
            "shadow model: 92  epoch: 101  loss= 0.08586347848176956\n",
            "shadow model: 92  epoch: 102  loss= 0.03435301408171654\n",
            "shadow model: 92  epoch: 103  loss= 0.1360589861869812\n",
            "shadow model: 92  epoch: 104  loss= 0.11364132910966873\n",
            "shadow model: 92  epoch: 105  loss= 0.11076518893241882\n",
            "shadow model: 92  epoch: 106  loss= 0.1371871381998062\n",
            "shadow model: 92  epoch: 107  loss= 0.11348316073417664\n",
            "shadow model: 92  epoch: 108  loss= 0.04930787906050682\n",
            "shadow model: 92  epoch: 109  loss= 0.042763784527778625\n",
            "shadow model: 92  epoch: 110  loss= 0.04825245216488838\n",
            "shadow model: 92  epoch: 111  loss= 0.03528187796473503\n",
            "shadow model: 92  epoch: 112  loss= 0.07979787886142731\n",
            "shadow model: 92  epoch: 113  loss= 0.06507714837789536\n",
            "shadow model: 92  epoch: 114  loss= 0.05179020017385483\n",
            "shadow model: 92  epoch: 115  loss= 0.071659617125988\n",
            "shadow model: 92  epoch: 116  loss= 0.04712466150522232\n",
            "shadow model: 92  epoch: 117  loss= 0.09788301587104797\n",
            "shadow model: 92  epoch: 118  loss= 0.04372743144631386\n",
            "shadow model: 92  epoch: 119  loss= 0.059629324823617935\n",
            "shadow model: 92  epoch: 120  loss= 0.028451263904571533\n",
            "shadow model: 92  epoch: 121  loss= 0.034413643181324005\n",
            "shadow model: 92  epoch: 122  loss= 0.06573314219713211\n",
            "shadow model: 92  epoch: 123  loss= 0.12796245515346527\n",
            "shadow model: 92  epoch: 124  loss= 0.057602860033512115\n",
            "shadow model: 92  epoch: 125  loss= 0.08370285481214523\n",
            "shadow model: 92  epoch: 126  loss= 0.08458422869443893\n",
            "shadow model: 92  epoch: 127  loss= 0.05203758180141449\n",
            "shadow model: 92  epoch: 128  loss= 0.02048434317111969\n",
            "shadow model: 92  epoch: 129  loss= 0.12247584015130997\n",
            "shadow model: 92  epoch: 130  loss= 0.05028817430138588\n",
            "shadow model: 92  epoch: 131  loss= 0.030623365193605423\n",
            "shadow model: 92  epoch: 132  loss= 0.12120292335748672\n",
            "shadow model: 92  epoch: 133  loss= 0.060913655906915665\n",
            "shadow model: 92  epoch: 134  loss= 0.10443561524152756\n",
            "shadow model: 92  epoch: 135  loss= 0.08675549179315567\n",
            "shadow model: 92  epoch: 136  loss= 0.07464172691106796\n",
            "shadow model: 92  epoch: 137  loss= 0.05683434009552002\n",
            "shadow model: 92  epoch: 138  loss= 0.07041852176189423\n",
            "shadow model: 92  epoch: 139  loss= 0.06400163471698761\n",
            "shadow model: 92  epoch: 140  loss= 0.12097754329442978\n",
            "shadow model: 92  epoch: 141  loss= 0.03283686563372612\n",
            "shadow model: 92  epoch: 142  loss= 0.0734400525689125\n",
            "shadow model: 92  epoch: 143  loss= 0.0476464182138443\n",
            "shadow model: 92  epoch: 144  loss= 0.035039789974689484\n",
            "shadow model: 92  epoch: 145  loss= 0.04220159724354744\n",
            "shadow model: 92  epoch: 146  loss= 0.05611563101410866\n",
            "shadow model: 92  epoch: 147  loss= 0.05324847996234894\n",
            "shadow model: 92  epoch: 148  loss= 0.0658479854464531\n",
            "shadow model: 92  epoch: 149  loss= 0.1217324435710907\n",
            "\n",
            "shadow model: 93  epoch: 0  loss= 2.3342409133911133\n",
            "shadow model: 93  epoch: 1  loss= 2.227658271789551\n",
            "shadow model: 93  epoch: 2  loss= 2.2242841720581055\n",
            "shadow model: 93  epoch: 3  loss= 2.203489303588867\n",
            "shadow model: 93  epoch: 4  loss= 2.0169594287872314\n",
            "shadow model: 93  epoch: 5  loss= 2.033707857131958\n",
            "shadow model: 93  epoch: 6  loss= 1.9247844219207764\n",
            "shadow model: 93  epoch: 7  loss= 1.958520531654358\n",
            "shadow model: 93  epoch: 8  loss= 1.9282866716384888\n",
            "shadow model: 93  epoch: 9  loss= 1.718496322631836\n",
            "shadow model: 93  epoch: 10  loss= 1.6697933673858643\n",
            "shadow model: 93  epoch: 11  loss= 1.5966981649398804\n",
            "shadow model: 93  epoch: 12  loss= 1.5281453132629395\n",
            "shadow model: 93  epoch: 13  loss= 1.5163155794143677\n",
            "shadow model: 93  epoch: 14  loss= 1.2952325344085693\n",
            "shadow model: 93  epoch: 15  loss= 1.4624385833740234\n",
            "shadow model: 93  epoch: 16  loss= 1.2852767705917358\n",
            "shadow model: 93  epoch: 17  loss= 1.1289910078048706\n",
            "shadow model: 93  epoch: 18  loss= 1.1216071844100952\n",
            "shadow model: 93  epoch: 19  loss= 1.1215951442718506\n",
            "shadow model: 93  epoch: 20  loss= 0.9904904961585999\n",
            "shadow model: 93  epoch: 21  loss= 1.0014747381210327\n",
            "shadow model: 93  epoch: 22  loss= 0.7031909823417664\n",
            "shadow model: 93  epoch: 23  loss= 1.0203832387924194\n",
            "shadow model: 93  epoch: 24  loss= 0.6128567457199097\n",
            "shadow model: 93  epoch: 25  loss= 0.6093851327896118\n",
            "shadow model: 93  epoch: 26  loss= 0.8999732136726379\n",
            "shadow model: 93  epoch: 27  loss= 0.6919333934783936\n",
            "shadow model: 93  epoch: 28  loss= 0.6026507616043091\n",
            "shadow model: 93  epoch: 29  loss= 0.46248117089271545\n",
            "shadow model: 93  epoch: 30  loss= 0.3751928210258484\n",
            "shadow model: 93  epoch: 31  loss= 0.5324473977088928\n",
            "shadow model: 93  epoch: 32  loss= 0.5713045597076416\n",
            "shadow model: 93  epoch: 33  loss= 0.43671464920043945\n",
            "shadow model: 93  epoch: 34  loss= 0.42622753977775574\n",
            "shadow model: 93  epoch: 35  loss= 0.4578396677970886\n",
            "shadow model: 93  epoch: 36  loss= 0.3988242447376251\n",
            "shadow model: 93  epoch: 37  loss= 0.5347924828529358\n",
            "shadow model: 93  epoch: 38  loss= 0.32407668232917786\n",
            "shadow model: 93  epoch: 39  loss= 0.348514586687088\n",
            "shadow model: 93  epoch: 40  loss= 0.34073489904403687\n",
            "shadow model: 93  epoch: 41  loss= 0.2520450949668884\n",
            "shadow model: 93  epoch: 42  loss= 0.24787822365760803\n",
            "shadow model: 93  epoch: 43  loss= 0.2813713848590851\n",
            "shadow model: 93  epoch: 44  loss= 0.2639860212802887\n",
            "shadow model: 93  epoch: 45  loss= 0.19819855690002441\n",
            "shadow model: 93  epoch: 46  loss= 0.3589547574520111\n",
            "shadow model: 93  epoch: 47  loss= 0.24181947112083435\n",
            "shadow model: 93  epoch: 48  loss= 0.1514439433813095\n",
            "shadow model: 93  epoch: 49  loss= 0.2265271246433258\n",
            "shadow model: 93  epoch: 50  loss= 0.1476137489080429\n",
            "shadow model: 93  epoch: 51  loss= 0.15056636929512024\n",
            "shadow model: 93  epoch: 52  loss= 0.12984086573123932\n",
            "shadow model: 93  epoch: 53  loss= 0.0823921412229538\n",
            "shadow model: 93  epoch: 54  loss= 0.2358960658311844\n",
            "shadow model: 93  epoch: 55  loss= 0.21997766196727753\n",
            "shadow model: 93  epoch: 56  loss= 0.15990209579467773\n",
            "shadow model: 93  epoch: 57  loss= 0.28854456543922424\n",
            "shadow model: 93  epoch: 58  loss= 0.2915246784687042\n",
            "shadow model: 93  epoch: 59  loss= 0.15993432700634003\n",
            "shadow model: 93  epoch: 60  loss= 0.22203673422336578\n",
            "shadow model: 93  epoch: 61  loss= 0.1878909170627594\n",
            "shadow model: 93  epoch: 62  loss= 0.2396758794784546\n",
            "shadow model: 93  epoch: 63  loss= 0.09976525604724884\n",
            "shadow model: 93  epoch: 64  loss= 0.06571655720472336\n",
            "shadow model: 93  epoch: 65  loss= 0.14659090340137482\n",
            "shadow model: 93  epoch: 66  loss= 0.10071870684623718\n",
            "shadow model: 93  epoch: 67  loss= 0.08613482862710953\n",
            "shadow model: 93  epoch: 68  loss= 0.1264307051897049\n",
            "shadow model: 93  epoch: 69  loss= 0.1538640558719635\n",
            "shadow model: 93  epoch: 70  loss= 0.08020155876874924\n",
            "shadow model: 93  epoch: 71  loss= 0.06716427206993103\n",
            "shadow model: 93  epoch: 72  loss= 0.11851335316896439\n",
            "shadow model: 93  epoch: 73  loss= 0.1886935532093048\n",
            "shadow model: 93  epoch: 74  loss= 0.153836190700531\n",
            "shadow model: 93  epoch: 75  loss= 0.14260567724704742\n",
            "shadow model: 93  epoch: 76  loss= 0.06761326640844345\n",
            "shadow model: 93  epoch: 77  loss= 0.12865032255649567\n",
            "shadow model: 93  epoch: 78  loss= 0.14075827598571777\n",
            "shadow model: 93  epoch: 79  loss= 0.04651307687163353\n",
            "shadow model: 93  epoch: 80  loss= 0.12815260887145996\n",
            "shadow model: 93  epoch: 81  loss= 0.033168889582157135\n",
            "shadow model: 93  epoch: 82  loss= 0.05205515772104263\n",
            "shadow model: 93  epoch: 83  loss= 0.1339956372976303\n",
            "shadow model: 93  epoch: 84  loss= 0.11255718022584915\n",
            "shadow model: 93  epoch: 85  loss= 0.09985476732254028\n",
            "shadow model: 93  epoch: 86  loss= 0.05849560350179672\n",
            "shadow model: 93  epoch: 87  loss= 0.14788982272148132\n",
            "shadow model: 93  epoch: 88  loss= 0.1681482344865799\n",
            "shadow model: 93  epoch: 89  loss= 0.09463416785001755\n",
            "shadow model: 93  epoch: 90  loss= 0.13225549459457397\n",
            "shadow model: 93  epoch: 91  loss= 0.03888088837265968\n",
            "shadow model: 93  epoch: 92  loss= 0.1974652111530304\n",
            "shadow model: 93  epoch: 93  loss= 0.07534565776586533\n",
            "shadow model: 93  epoch: 94  loss= 0.16626082360744476\n",
            "shadow model: 93  epoch: 95  loss= 0.0264630988240242\n",
            "shadow model: 93  epoch: 96  loss= 0.08081027865409851\n",
            "shadow model: 93  epoch: 97  loss= 0.15682868659496307\n",
            "shadow model: 93  epoch: 98  loss= 0.10273681581020355\n",
            "shadow model: 93  epoch: 99  loss= 0.0999128445982933\n",
            "shadow model: 93  epoch: 100  loss= 0.05509832873940468\n",
            "shadow model: 93  epoch: 101  loss= 0.041624948382377625\n",
            "shadow model: 93  epoch: 102  loss= 0.06336098164319992\n",
            "shadow model: 93  epoch: 103  loss= 0.11096474528312683\n",
            "shadow model: 93  epoch: 104  loss= 0.054301533848047256\n",
            "shadow model: 93  epoch: 105  loss= 0.027260439470410347\n",
            "shadow model: 93  epoch: 106  loss= 0.12412155419588089\n",
            "shadow model: 93  epoch: 107  loss= 0.10092464834451675\n",
            "shadow model: 93  epoch: 108  loss= 0.06956581771373749\n",
            "shadow model: 93  epoch: 109  loss= 0.1329905241727829\n",
            "shadow model: 93  epoch: 110  loss= 0.052181705832481384\n",
            "shadow model: 93  epoch: 111  loss= 0.0809514969587326\n",
            "shadow model: 93  epoch: 112  loss= 0.10744072496891022\n",
            "shadow model: 93  epoch: 113  loss= 0.03487835079431534\n",
            "shadow model: 93  epoch: 114  loss= 0.05795788764953613\n",
            "shadow model: 93  epoch: 115  loss= 0.057243797928094864\n",
            "shadow model: 93  epoch: 116  loss= 0.14077846705913544\n",
            "shadow model: 93  epoch: 117  loss= 0.11120305955410004\n",
            "shadow model: 93  epoch: 118  loss= 0.020962228998541832\n",
            "shadow model: 93  epoch: 119  loss= 0.12520292401313782\n",
            "shadow model: 93  epoch: 120  loss= 0.10422690212726593\n",
            "shadow model: 93  epoch: 121  loss= 0.09662806987762451\n",
            "shadow model: 93  epoch: 122  loss= 0.03639470785856247\n",
            "shadow model: 93  epoch: 123  loss= 0.04176589474081993\n",
            "shadow model: 93  epoch: 124  loss= 0.20222614705562592\n",
            "shadow model: 93  epoch: 125  loss= 0.07262860238552094\n",
            "shadow model: 93  epoch: 126  loss= 0.14004819095134735\n",
            "shadow model: 93  epoch: 127  loss= 0.09757298231124878\n",
            "shadow model: 93  epoch: 128  loss= 0.014895470812916756\n",
            "shadow model: 93  epoch: 129  loss= 0.04750797897577286\n",
            "shadow model: 93  epoch: 130  loss= 0.07196364551782608\n",
            "shadow model: 93  epoch: 131  loss= 0.01644226536154747\n",
            "shadow model: 93  epoch: 132  loss= 0.07928087562322617\n",
            "shadow model: 93  epoch: 133  loss= 0.0566566027700901\n",
            "shadow model: 93  epoch: 134  loss= 0.07778362929821014\n",
            "shadow model: 93  epoch: 135  loss= 0.0671536773443222\n",
            "shadow model: 93  epoch: 136  loss= 0.012644744478166103\n",
            "shadow model: 93  epoch: 137  loss= 0.11250050365924835\n",
            "shadow model: 93  epoch: 138  loss= 0.03391726687550545\n",
            "shadow model: 93  epoch: 139  loss= 0.03717959299683571\n",
            "shadow model: 93  epoch: 140  loss= 0.10297207534313202\n",
            "shadow model: 93  epoch: 141  loss= 0.04188567399978638\n",
            "shadow model: 93  epoch: 142  loss= 0.14764130115509033\n",
            "shadow model: 93  epoch: 143  loss= 0.06816127151250839\n",
            "shadow model: 93  epoch: 144  loss= 0.13823966681957245\n",
            "shadow model: 93  epoch: 145  loss= 0.05494137853384018\n",
            "shadow model: 93  epoch: 146  loss= 0.1403941959142685\n",
            "shadow model: 93  epoch: 147  loss= 0.08174977451562881\n",
            "shadow model: 93  epoch: 148  loss= 0.013483893126249313\n",
            "shadow model: 93  epoch: 149  loss= 0.01082998514175415\n",
            "\n",
            "shadow model: 94  epoch: 0  loss= 2.352492094039917\n",
            "shadow model: 94  epoch: 1  loss= 2.2909443378448486\n",
            "shadow model: 94  epoch: 2  loss= 2.2398030757904053\n",
            "shadow model: 94  epoch: 3  loss= 2.209641456604004\n",
            "shadow model: 94  epoch: 4  loss= 2.1075375080108643\n",
            "shadow model: 94  epoch: 5  loss= 2.04692006111145\n",
            "shadow model: 94  epoch: 6  loss= 2.1154510974884033\n",
            "shadow model: 94  epoch: 7  loss= 2.154167890548706\n",
            "shadow model: 94  epoch: 8  loss= 2.1011996269226074\n",
            "shadow model: 94  epoch: 9  loss= 1.9047937393188477\n",
            "shadow model: 94  epoch: 10  loss= 1.8905420303344727\n",
            "shadow model: 94  epoch: 11  loss= 1.7663592100143433\n",
            "shadow model: 94  epoch: 12  loss= 1.6874576807022095\n",
            "shadow model: 94  epoch: 13  loss= 1.7081929445266724\n",
            "shadow model: 94  epoch: 14  loss= 1.5797438621520996\n",
            "shadow model: 94  epoch: 15  loss= 1.578636884689331\n",
            "shadow model: 94  epoch: 16  loss= 1.6079174280166626\n",
            "shadow model: 94  epoch: 17  loss= 1.6121056079864502\n",
            "shadow model: 94  epoch: 18  loss= 1.2960084676742554\n",
            "shadow model: 94  epoch: 19  loss= 1.4018843173980713\n",
            "shadow model: 94  epoch: 20  loss= 1.2901315689086914\n",
            "shadow model: 94  epoch: 21  loss= 1.2385469675064087\n",
            "shadow model: 94  epoch: 22  loss= 1.3642398118972778\n",
            "shadow model: 94  epoch: 23  loss= 1.2810384035110474\n",
            "shadow model: 94  epoch: 24  loss= 0.9466003179550171\n",
            "shadow model: 94  epoch: 25  loss= 0.9821049571037292\n",
            "shadow model: 94  epoch: 26  loss= 1.117152452468872\n",
            "shadow model: 94  epoch: 27  loss= 0.8101882934570312\n",
            "shadow model: 94  epoch: 28  loss= 0.9060012102127075\n",
            "shadow model: 94  epoch: 29  loss= 0.8168322443962097\n",
            "shadow model: 94  epoch: 30  loss= 0.774896502494812\n",
            "shadow model: 94  epoch: 31  loss= 0.7951951026916504\n",
            "shadow model: 94  epoch: 32  loss= 0.6788931488990784\n",
            "shadow model: 94  epoch: 33  loss= 0.7650498151779175\n",
            "shadow model: 94  epoch: 34  loss= 0.5435892939567566\n",
            "shadow model: 94  epoch: 35  loss= 0.5195404887199402\n",
            "shadow model: 94  epoch: 36  loss= 0.5285215377807617\n",
            "shadow model: 94  epoch: 37  loss= 0.5750643014907837\n",
            "shadow model: 94  epoch: 38  loss= 0.6069502234458923\n",
            "shadow model: 94  epoch: 39  loss= 0.4493456482887268\n",
            "shadow model: 94  epoch: 40  loss= 0.4264654815196991\n",
            "shadow model: 94  epoch: 41  loss= 0.5088793039321899\n",
            "shadow model: 94  epoch: 42  loss= 0.44046568870544434\n",
            "shadow model: 94  epoch: 43  loss= 0.3379285931587219\n",
            "shadow model: 94  epoch: 44  loss= 0.3706809878349304\n",
            "shadow model: 94  epoch: 45  loss= 0.4046765863895416\n",
            "shadow model: 94  epoch: 46  loss= 0.43648362159729004\n",
            "shadow model: 94  epoch: 47  loss= 0.5308356285095215\n",
            "shadow model: 94  epoch: 48  loss= 0.5012667775154114\n",
            "shadow model: 94  epoch: 49  loss= 0.4494953155517578\n",
            "shadow model: 94  epoch: 50  loss= 0.2328547090291977\n",
            "shadow model: 94  epoch: 51  loss= 0.29400983452796936\n",
            "shadow model: 94  epoch: 52  loss= 0.2535870373249054\n",
            "shadow model: 94  epoch: 53  loss= 0.44840553402900696\n",
            "shadow model: 94  epoch: 54  loss= 0.16089759767055511\n",
            "shadow model: 94  epoch: 55  loss= 0.31279557943344116\n",
            "shadow model: 94  epoch: 56  loss= 0.3277377188205719\n",
            "shadow model: 94  epoch: 57  loss= 0.36256489157676697\n",
            "shadow model: 94  epoch: 58  loss= 0.2838016748428345\n",
            "shadow model: 94  epoch: 59  loss= 0.3863968551158905\n",
            "shadow model: 94  epoch: 60  loss= 0.29070502519607544\n",
            "shadow model: 94  epoch: 61  loss= 0.2126794159412384\n",
            "shadow model: 94  epoch: 62  loss= 0.30427971482276917\n",
            "shadow model: 94  epoch: 63  loss= 0.11068663001060486\n",
            "shadow model: 94  epoch: 64  loss= 0.1980724036693573\n",
            "shadow model: 94  epoch: 65  loss= 0.24793866276741028\n",
            "shadow model: 94  epoch: 66  loss= 0.13650189340114594\n",
            "shadow model: 94  epoch: 67  loss= 0.1489391326904297\n",
            "shadow model: 94  epoch: 68  loss= 0.19660836458206177\n",
            "shadow model: 94  epoch: 69  loss= 0.30562883615493774\n",
            "shadow model: 94  epoch: 70  loss= 0.12587520480155945\n",
            "shadow model: 94  epoch: 71  loss= 0.11333183944225311\n",
            "shadow model: 94  epoch: 72  loss= 0.1522122472524643\n",
            "shadow model: 94  epoch: 73  loss= 0.35726940631866455\n",
            "shadow model: 94  epoch: 74  loss= 0.1646161526441574\n",
            "shadow model: 94  epoch: 75  loss= 0.12253643572330475\n",
            "shadow model: 94  epoch: 76  loss= 0.2528669536113739\n",
            "shadow model: 94  epoch: 77  loss= 0.2046998143196106\n",
            "shadow model: 94  epoch: 78  loss= 0.17246530950069427\n",
            "shadow model: 94  epoch: 79  loss= 0.15363934636116028\n",
            "shadow model: 94  epoch: 80  loss= 0.26739802956581116\n",
            "shadow model: 94  epoch: 81  loss= 0.2223799079656601\n",
            "shadow model: 94  epoch: 82  loss= 0.28930991888046265\n",
            "shadow model: 94  epoch: 83  loss= 0.08551840484142303\n",
            "shadow model: 94  epoch: 84  loss= 0.1121971383690834\n",
            "shadow model: 94  epoch: 85  loss= 0.3172881007194519\n",
            "shadow model: 94  epoch: 86  loss= 0.16824889183044434\n",
            "shadow model: 94  epoch: 87  loss= 0.2638912498950958\n",
            "shadow model: 94  epoch: 88  loss= 0.18387675285339355\n",
            "shadow model: 94  epoch: 89  loss= 0.05166981741786003\n",
            "shadow model: 94  epoch: 90  loss= 0.10523460060358047\n",
            "shadow model: 94  epoch: 91  loss= 0.07006661593914032\n",
            "shadow model: 94  epoch: 92  loss= 0.15782038867473602\n",
            "shadow model: 94  epoch: 93  loss= 0.17558275163173676\n",
            "shadow model: 94  epoch: 94  loss= 0.21183915436267853\n",
            "shadow model: 94  epoch: 95  loss= 0.07426964491605759\n",
            "shadow model: 94  epoch: 96  loss= 0.11323036253452301\n",
            "shadow model: 94  epoch: 97  loss= 0.17502252757549286\n",
            "shadow model: 94  epoch: 98  loss= 0.12968562543392181\n",
            "shadow model: 94  epoch: 99  loss= 0.1324315369129181\n",
            "shadow model: 94  epoch: 100  loss= 0.09329972416162491\n",
            "shadow model: 94  epoch: 101  loss= 0.07543724775314331\n",
            "shadow model: 94  epoch: 102  loss= 0.12071400880813599\n",
            "shadow model: 94  epoch: 103  loss= 0.07138177752494812\n",
            "shadow model: 94  epoch: 104  loss= 0.15915755927562714\n",
            "shadow model: 94  epoch: 105  loss= 0.08362307399511337\n",
            "shadow model: 94  epoch: 106  loss= 0.12292667478322983\n",
            "shadow model: 94  epoch: 107  loss= 0.26392704248428345\n",
            "shadow model: 94  epoch: 108  loss= 0.11665026098489761\n",
            "shadow model: 94  epoch: 109  loss= 0.10719893872737885\n",
            "shadow model: 94  epoch: 110  loss= 0.10481294989585876\n",
            "shadow model: 94  epoch: 111  loss= 0.11889732629060745\n",
            "shadow model: 94  epoch: 112  loss= 0.10429009795188904\n",
            "shadow model: 94  epoch: 113  loss= 0.10356827080249786\n",
            "shadow model: 94  epoch: 114  loss= 0.1424088180065155\n",
            "shadow model: 94  epoch: 115  loss= 0.05031658336520195\n",
            "shadow model: 94  epoch: 116  loss= 0.043600261211395264\n",
            "shadow model: 94  epoch: 117  loss= 0.04562242701649666\n",
            "shadow model: 94  epoch: 118  loss= 0.08039531111717224\n",
            "shadow model: 94  epoch: 119  loss= 0.06848464161157608\n",
            "shadow model: 94  epoch: 120  loss= 0.19184510409832\n",
            "shadow model: 94  epoch: 121  loss= 0.09361392259597778\n",
            "shadow model: 94  epoch: 122  loss= 0.07471362501382828\n",
            "shadow model: 94  epoch: 123  loss= 0.07737462222576141\n",
            "shadow model: 94  epoch: 124  loss= 0.11728779226541519\n",
            "shadow model: 94  epoch: 125  loss= 0.06634671986103058\n",
            "shadow model: 94  epoch: 126  loss= 0.04930214211344719\n",
            "shadow model: 94  epoch: 127  loss= 0.03166649863123894\n",
            "shadow model: 94  epoch: 128  loss= 0.055874258279800415\n",
            "shadow model: 94  epoch: 129  loss= 0.07610183954238892\n",
            "shadow model: 94  epoch: 130  loss= 0.21057571470737457\n",
            "shadow model: 94  epoch: 131  loss= 0.05135425552725792\n",
            "shadow model: 94  epoch: 132  loss= 0.037460535764694214\n",
            "shadow model: 94  epoch: 133  loss= 0.10663977265357971\n",
            "shadow model: 94  epoch: 134  loss= 0.08348953723907471\n",
            "shadow model: 94  epoch: 135  loss= 0.06238226220011711\n",
            "shadow model: 94  epoch: 136  loss= 0.2166273444890976\n",
            "shadow model: 94  epoch: 137  loss= 0.05759717896580696\n",
            "shadow model: 94  epoch: 138  loss= 0.075938381254673\n",
            "shadow model: 94  epoch: 139  loss= 0.09563391655683517\n",
            "shadow model: 94  epoch: 140  loss= 0.12817473709583282\n",
            "shadow model: 94  epoch: 141  loss= 0.22160379588603973\n",
            "shadow model: 94  epoch: 142  loss= 0.057701580226421356\n",
            "shadow model: 94  epoch: 143  loss= 0.18768808245658875\n",
            "shadow model: 94  epoch: 144  loss= 0.04094255715608597\n",
            "shadow model: 94  epoch: 145  loss= 0.05434498190879822\n",
            "shadow model: 94  epoch: 146  loss= 0.15720762312412262\n",
            "shadow model: 94  epoch: 147  loss= 0.09400232881307602\n",
            "shadow model: 94  epoch: 148  loss= 0.03264971449971199\n",
            "shadow model: 94  epoch: 149  loss= 0.0933750718832016\n",
            "\n",
            "shadow model: 95  epoch: 0  loss= 2.3546254634857178\n",
            "shadow model: 95  epoch: 1  loss= 2.217427968978882\n",
            "shadow model: 95  epoch: 2  loss= 2.176875352859497\n",
            "shadow model: 95  epoch: 3  loss= 2.161360502243042\n",
            "shadow model: 95  epoch: 4  loss= 2.029747486114502\n",
            "shadow model: 95  epoch: 5  loss= 2.002077579498291\n",
            "shadow model: 95  epoch: 6  loss= 2.060718059539795\n",
            "shadow model: 95  epoch: 7  loss= 1.8078478574752808\n",
            "shadow model: 95  epoch: 8  loss= 1.653554081916809\n",
            "shadow model: 95  epoch: 9  loss= 1.9540187120437622\n",
            "shadow model: 95  epoch: 10  loss= 1.5793588161468506\n",
            "shadow model: 95  epoch: 11  loss= 1.4260700941085815\n",
            "shadow model: 95  epoch: 12  loss= 1.6878690719604492\n",
            "shadow model: 95  epoch: 13  loss= 1.4633314609527588\n",
            "shadow model: 95  epoch: 14  loss= 1.309226393699646\n",
            "shadow model: 95  epoch: 15  loss= 1.40281343460083\n",
            "shadow model: 95  epoch: 16  loss= 1.2957147359848022\n",
            "shadow model: 95  epoch: 17  loss= 1.1439039707183838\n",
            "shadow model: 95  epoch: 18  loss= 1.013616919517517\n",
            "shadow model: 95  epoch: 19  loss= 1.1760015487670898\n",
            "shadow model: 95  epoch: 20  loss= 0.8436813354492188\n",
            "shadow model: 95  epoch: 21  loss= 1.1015268564224243\n",
            "shadow model: 95  epoch: 22  loss= 1.1184085607528687\n",
            "shadow model: 95  epoch: 23  loss= 0.9104005694389343\n",
            "shadow model: 95  epoch: 24  loss= 0.92652827501297\n",
            "shadow model: 95  epoch: 25  loss= 0.8156027793884277\n",
            "shadow model: 95  epoch: 26  loss= 0.8285485506057739\n",
            "shadow model: 95  epoch: 27  loss= 0.7781968116760254\n",
            "shadow model: 95  epoch: 28  loss= 0.6099404096603394\n",
            "shadow model: 95  epoch: 29  loss= 0.607161819934845\n",
            "shadow model: 95  epoch: 30  loss= 0.5625045895576477\n",
            "shadow model: 95  epoch: 31  loss= 0.554356038570404\n",
            "shadow model: 95  epoch: 32  loss= 0.44560250639915466\n",
            "shadow model: 95  epoch: 33  loss= 0.4763248562812805\n",
            "shadow model: 95  epoch: 34  loss= 0.44878441095352173\n",
            "shadow model: 95  epoch: 35  loss= 0.35571494698524475\n",
            "shadow model: 95  epoch: 36  loss= 0.4047144949436188\n",
            "shadow model: 95  epoch: 37  loss= 0.22932100296020508\n",
            "shadow model: 95  epoch: 38  loss= 0.6310999393463135\n",
            "shadow model: 95  epoch: 39  loss= 0.49392250180244446\n",
            "shadow model: 95  epoch: 40  loss= 0.3241068124771118\n",
            "shadow model: 95  epoch: 41  loss= 0.37355419993400574\n",
            "shadow model: 95  epoch: 42  loss= 0.41178449988365173\n",
            "shadow model: 95  epoch: 43  loss= 0.4149138033390045\n",
            "shadow model: 95  epoch: 44  loss= 0.37072765827178955\n",
            "shadow model: 95  epoch: 45  loss= 0.3089015483856201\n",
            "shadow model: 95  epoch: 46  loss= 0.2598930895328522\n",
            "shadow model: 95  epoch: 47  loss= 0.32235896587371826\n",
            "shadow model: 95  epoch: 48  loss= 0.295701801776886\n",
            "shadow model: 95  epoch: 49  loss= 0.14796067774295807\n",
            "shadow model: 95  epoch: 50  loss= 0.16911375522613525\n",
            "shadow model: 95  epoch: 51  loss= 0.12757699191570282\n",
            "shadow model: 95  epoch: 52  loss= 0.30804455280303955\n",
            "shadow model: 95  epoch: 53  loss= 0.16835813224315643\n",
            "shadow model: 95  epoch: 54  loss= 0.26844990253448486\n",
            "shadow model: 95  epoch: 55  loss= 0.23217891156673431\n",
            "shadow model: 95  epoch: 56  loss= 0.30526113510131836\n",
            "shadow model: 95  epoch: 57  loss= 0.22830602526664734\n",
            "shadow model: 95  epoch: 58  loss= 0.13335372507572174\n",
            "shadow model: 95  epoch: 59  loss= 0.3491385877132416\n",
            "shadow model: 95  epoch: 60  loss= 0.08500195294618607\n",
            "shadow model: 95  epoch: 61  loss= 0.21322891116142273\n",
            "shadow model: 95  epoch: 62  loss= 0.10913001000881195\n",
            "shadow model: 95  epoch: 63  loss= 0.2236935943365097\n",
            "shadow model: 95  epoch: 64  loss= 0.10601461678743362\n",
            "shadow model: 95  epoch: 65  loss= 0.13735109567642212\n",
            "shadow model: 95  epoch: 66  loss= 0.3504732847213745\n",
            "shadow model: 95  epoch: 67  loss= 0.06240716949105263\n",
            "shadow model: 95  epoch: 68  loss= 0.11332221329212189\n",
            "shadow model: 95  epoch: 69  loss= 0.22837021946907043\n",
            "shadow model: 95  epoch: 70  loss= 0.11406482756137848\n",
            "shadow model: 95  epoch: 71  loss= 0.0763385072350502\n",
            "shadow model: 95  epoch: 72  loss= 0.12112537771463394\n",
            "shadow model: 95  epoch: 73  loss= 0.05805894732475281\n",
            "shadow model: 95  epoch: 74  loss= 0.17341846227645874\n",
            "shadow model: 95  epoch: 75  loss= 0.060244981199502945\n",
            "shadow model: 95  epoch: 76  loss= 0.19502684473991394\n",
            "shadow model: 95  epoch: 77  loss= 0.1085343137383461\n",
            "shadow model: 95  epoch: 78  loss= 0.13857130706310272\n",
            "shadow model: 95  epoch: 79  loss= 0.06418231874704361\n",
            "shadow model: 95  epoch: 80  loss= 0.14929819107055664\n",
            "shadow model: 95  epoch: 81  loss= 0.2466239035129547\n",
            "shadow model: 95  epoch: 82  loss= 0.03634865954518318\n",
            "shadow model: 95  epoch: 83  loss= 0.07700854539871216\n",
            "shadow model: 95  epoch: 84  loss= 0.07393423467874527\n",
            "shadow model: 95  epoch: 85  loss= 0.14843174815177917\n",
            "shadow model: 95  epoch: 86  loss= 0.05807069316506386\n",
            "shadow model: 95  epoch: 87  loss= 0.07342006266117096\n",
            "shadow model: 95  epoch: 88  loss= 0.059973642230033875\n",
            "shadow model: 95  epoch: 89  loss= 0.07765612006187439\n",
            "shadow model: 95  epoch: 90  loss= 0.0421874076128006\n",
            "shadow model: 95  epoch: 91  loss= 0.07531528919935226\n",
            "shadow model: 95  epoch: 92  loss= 0.06727919727563858\n",
            "shadow model: 95  epoch: 93  loss= 0.04246126860380173\n",
            "shadow model: 95  epoch: 94  loss= 0.03811066225171089\n",
            "shadow model: 95  epoch: 95  loss= 0.10859624296426773\n",
            "shadow model: 95  epoch: 96  loss= 0.054122548550367355\n",
            "shadow model: 95  epoch: 97  loss= 0.049428798258304596\n",
            "shadow model: 95  epoch: 98  loss= 0.025446772575378418\n",
            "shadow model: 95  epoch: 99  loss= 0.0675785169005394\n",
            "shadow model: 95  epoch: 100  loss= 0.07782578468322754\n",
            "shadow model: 95  epoch: 101  loss= 0.06825278699398041\n",
            "shadow model: 95  epoch: 102  loss= 0.04327975586056709\n",
            "shadow model: 95  epoch: 103  loss= 0.01875237375497818\n",
            "shadow model: 95  epoch: 104  loss= 0.05334494635462761\n",
            "shadow model: 95  epoch: 105  loss= 0.07501278072595596\n",
            "shadow model: 95  epoch: 106  loss= 0.05124005302786827\n",
            "shadow model: 95  epoch: 107  loss= 0.017512332648038864\n",
            "shadow model: 95  epoch: 108  loss= 0.029219351708889008\n",
            "shadow model: 95  epoch: 109  loss= 0.0440228246152401\n",
            "shadow model: 95  epoch: 110  loss= 0.08325015753507614\n",
            "shadow model: 95  epoch: 111  loss= 0.08159704506397247\n",
            "shadow model: 95  epoch: 112  loss= 0.055461782962083817\n",
            "shadow model: 95  epoch: 113  loss= 0.11153584718704224\n",
            "shadow model: 95  epoch: 114  loss= 0.061575524508953094\n",
            "shadow model: 95  epoch: 115  loss= 0.037139277905225754\n",
            "shadow model: 95  epoch: 116  loss= 0.06190718337893486\n",
            "shadow model: 95  epoch: 117  loss= 0.11714476346969604\n",
            "shadow model: 95  epoch: 118  loss= 0.06388407945632935\n",
            "shadow model: 95  epoch: 119  loss= 0.054612886160612106\n",
            "shadow model: 95  epoch: 120  loss= 0.05670544132590294\n",
            "shadow model: 95  epoch: 121  loss= 0.08876506239175797\n",
            "shadow model: 95  epoch: 122  loss= 0.0875612124800682\n",
            "shadow model: 95  epoch: 123  loss= 0.08534672111272812\n",
            "shadow model: 95  epoch: 124  loss= 0.09857167303562164\n",
            "shadow model: 95  epoch: 125  loss= 0.012800089083611965\n",
            "shadow model: 95  epoch: 126  loss= 0.10224822908639908\n",
            "shadow model: 95  epoch: 127  loss= 0.06499167531728745\n",
            "shadow model: 95  epoch: 128  loss= 0.010269411839544773\n",
            "shadow model: 95  epoch: 129  loss= 0.1362609565258026\n",
            "shadow model: 95  epoch: 130  loss= 0.04630527272820473\n",
            "shadow model: 95  epoch: 131  loss= 0.07563139498233795\n",
            "shadow model: 95  epoch: 132  loss= 0.037627458572387695\n",
            "shadow model: 95  epoch: 133  loss= 0.15318238735198975\n",
            "shadow model: 95  epoch: 134  loss= 0.015725456178188324\n",
            "shadow model: 95  epoch: 135  loss= 0.07766960561275482\n",
            "shadow model: 95  epoch: 136  loss= 0.048440176993608475\n",
            "shadow model: 95  epoch: 137  loss= 0.009984281845390797\n",
            "shadow model: 95  epoch: 138  loss= 0.048254113644361496\n",
            "shadow model: 95  epoch: 139  loss= 0.04889995604753494\n",
            "shadow model: 95  epoch: 140  loss= 0.04794513061642647\n",
            "shadow model: 95  epoch: 141  loss= 0.02690074034035206\n",
            "shadow model: 95  epoch: 142  loss= 0.02736179530620575\n",
            "shadow model: 95  epoch: 143  loss= 0.043713051825761795\n",
            "shadow model: 95  epoch: 144  loss= 0.08974260091781616\n",
            "shadow model: 95  epoch: 145  loss= 0.10573950409889221\n",
            "shadow model: 95  epoch: 146  loss= 0.05214293301105499\n",
            "shadow model: 95  epoch: 147  loss= 0.06366115808486938\n",
            "shadow model: 95  epoch: 148  loss= 0.03331752493977547\n",
            "shadow model: 95  epoch: 149  loss= 0.06815266609191895\n",
            "\n",
            "shadow model: 96  epoch: 0  loss= 2.320193290710449\n",
            "shadow model: 96  epoch: 1  loss= 2.2430484294891357\n",
            "shadow model: 96  epoch: 2  loss= 2.219156503677368\n",
            "shadow model: 96  epoch: 3  loss= 2.0513415336608887\n",
            "shadow model: 96  epoch: 4  loss= 2.177747964859009\n",
            "shadow model: 96  epoch: 5  loss= 1.9460105895996094\n",
            "shadow model: 96  epoch: 6  loss= 1.8176076412200928\n",
            "shadow model: 96  epoch: 7  loss= 1.7963745594024658\n",
            "shadow model: 96  epoch: 8  loss= 1.8450802564620972\n",
            "shadow model: 96  epoch: 9  loss= 1.6972891092300415\n",
            "shadow model: 96  epoch: 10  loss= 1.4718941450119019\n",
            "shadow model: 96  epoch: 11  loss= 1.3531816005706787\n",
            "shadow model: 96  epoch: 12  loss= 1.2407106161117554\n",
            "shadow model: 96  epoch: 13  loss= 1.3167800903320312\n",
            "shadow model: 96  epoch: 14  loss= 1.5389376878738403\n",
            "shadow model: 96  epoch: 15  loss= 1.3409208059310913\n",
            "shadow model: 96  epoch: 16  loss= 1.091498613357544\n",
            "shadow model: 96  epoch: 17  loss= 1.3243077993392944\n",
            "shadow model: 96  epoch: 18  loss= 1.0865586996078491\n",
            "shadow model: 96  epoch: 19  loss= 1.2016693353652954\n",
            "shadow model: 96  epoch: 20  loss= 1.1781518459320068\n",
            "shadow model: 96  epoch: 21  loss= 0.8274710774421692\n",
            "shadow model: 96  epoch: 22  loss= 0.9690635204315186\n",
            "shadow model: 96  epoch: 23  loss= 0.9205847382545471\n",
            "shadow model: 96  epoch: 24  loss= 0.7844243049621582\n",
            "shadow model: 96  epoch: 25  loss= 0.8049298524856567\n",
            "shadow model: 96  epoch: 26  loss= 0.7993853688240051\n",
            "shadow model: 96  epoch: 27  loss= 0.7083533406257629\n",
            "shadow model: 96  epoch: 28  loss= 0.7648043036460876\n",
            "shadow model: 96  epoch: 29  loss= 0.6623458862304688\n",
            "shadow model: 96  epoch: 30  loss= 0.6709038019180298\n",
            "shadow model: 96  epoch: 31  loss= 0.7714682817459106\n",
            "shadow model: 96  epoch: 32  loss= 0.6929426789283752\n",
            "shadow model: 96  epoch: 33  loss= 0.8427330255508423\n",
            "shadow model: 96  epoch: 34  loss= 0.5407320857048035\n",
            "shadow model: 96  epoch: 35  loss= 0.6856947541236877\n",
            "shadow model: 96  epoch: 36  loss= 0.3645983338356018\n",
            "shadow model: 96  epoch: 37  loss= 0.6558247208595276\n",
            "shadow model: 96  epoch: 38  loss= 0.6264595985412598\n",
            "shadow model: 96  epoch: 39  loss= 0.38864585757255554\n",
            "shadow model: 96  epoch: 40  loss= 0.5308331251144409\n",
            "shadow model: 96  epoch: 41  loss= 0.4086119830608368\n",
            "shadow model: 96  epoch: 42  loss= 0.47378626465797424\n",
            "shadow model: 96  epoch: 43  loss= 0.39088454842567444\n",
            "shadow model: 96  epoch: 44  loss= 0.3054952025413513\n",
            "shadow model: 96  epoch: 45  loss= 0.3973432183265686\n",
            "shadow model: 96  epoch: 46  loss= 0.35958391427993774\n",
            "shadow model: 96  epoch: 47  loss= 0.4937652349472046\n",
            "shadow model: 96  epoch: 48  loss= 0.3171498775482178\n",
            "shadow model: 96  epoch: 49  loss= 0.40700235962867737\n",
            "shadow model: 96  epoch: 50  loss= 0.32069745659828186\n",
            "shadow model: 96  epoch: 51  loss= 0.32639259099960327\n",
            "shadow model: 96  epoch: 52  loss= 0.33351829648017883\n",
            "shadow model: 96  epoch: 53  loss= 0.39734750986099243\n",
            "shadow model: 96  epoch: 54  loss= 0.1378675252199173\n",
            "shadow model: 96  epoch: 55  loss= 0.3357492685317993\n",
            "shadow model: 96  epoch: 56  loss= 0.3564658761024475\n",
            "shadow model: 96  epoch: 57  loss= 0.19084501266479492\n",
            "shadow model: 96  epoch: 58  loss= 0.19975025951862335\n",
            "shadow model: 96  epoch: 59  loss= 0.23459602892398834\n",
            "shadow model: 96  epoch: 60  loss= 0.2933143973350525\n",
            "shadow model: 96  epoch: 61  loss= 0.24114267528057098\n",
            "shadow model: 96  epoch: 62  loss= 0.2862781882286072\n",
            "shadow model: 96  epoch: 63  loss= 0.15673953294754028\n",
            "shadow model: 96  epoch: 64  loss= 0.3532669246196747\n",
            "shadow model: 96  epoch: 65  loss= 0.2877162992954254\n",
            "shadow model: 96  epoch: 66  loss= 0.25791507959365845\n",
            "shadow model: 96  epoch: 67  loss= 0.354172945022583\n",
            "shadow model: 96  epoch: 68  loss= 0.23559744656085968\n",
            "shadow model: 96  epoch: 69  loss= 0.25464892387390137\n",
            "shadow model: 96  epoch: 70  loss= 0.236838698387146\n",
            "shadow model: 96  epoch: 71  loss= 0.28160765767097473\n",
            "shadow model: 96  epoch: 72  loss= 0.2059902399778366\n",
            "shadow model: 96  epoch: 73  loss= 0.1598825305700302\n",
            "shadow model: 96  epoch: 74  loss= 0.3264027535915375\n",
            "shadow model: 96  epoch: 75  loss= 0.18822436034679413\n",
            "shadow model: 96  epoch: 76  loss= 0.07077771425247192\n",
            "shadow model: 96  epoch: 77  loss= 0.13947375118732452\n",
            "shadow model: 96  epoch: 78  loss= 0.15024897456169128\n",
            "shadow model: 96  epoch: 79  loss= 0.23268826305866241\n",
            "shadow model: 96  epoch: 80  loss= 0.2620784640312195\n",
            "shadow model: 96  epoch: 81  loss= 0.1321408748626709\n",
            "shadow model: 96  epoch: 82  loss= 0.15657714009284973\n",
            "shadow model: 96  epoch: 83  loss= 0.11409612745046616\n",
            "shadow model: 96  epoch: 84  loss= 0.07251407206058502\n",
            "shadow model: 96  epoch: 85  loss= 0.28510597348213196\n",
            "shadow model: 96  epoch: 86  loss= 0.22348520159721375\n",
            "shadow model: 96  epoch: 87  loss= 0.1625516265630722\n",
            "shadow model: 96  epoch: 88  loss= 0.11687514930963516\n",
            "shadow model: 96  epoch: 89  loss= 0.09650027006864548\n",
            "shadow model: 96  epoch: 90  loss= 0.09480029344558716\n",
            "shadow model: 96  epoch: 91  loss= 0.20275604724884033\n",
            "shadow model: 96  epoch: 92  loss= 0.2792940139770508\n",
            "shadow model: 96  epoch: 93  loss= 0.15681558847427368\n",
            "shadow model: 96  epoch: 94  loss= 0.22644034028053284\n",
            "shadow model: 96  epoch: 95  loss= 0.11090373992919922\n",
            "shadow model: 96  epoch: 96  loss= 0.0731814056634903\n",
            "shadow model: 96  epoch: 97  loss= 0.12981073558330536\n",
            "shadow model: 96  epoch: 98  loss= 0.19735047221183777\n",
            "shadow model: 96  epoch: 99  loss= 0.11224720627069473\n",
            "shadow model: 96  epoch: 100  loss= 0.30127784609794617\n",
            "shadow model: 96  epoch: 101  loss= 0.14259839057922363\n",
            "shadow model: 96  epoch: 102  loss= 0.06694889813661575\n",
            "shadow model: 96  epoch: 103  loss= 0.1295270174741745\n",
            "shadow model: 96  epoch: 104  loss= 0.14316388964653015\n",
            "shadow model: 96  epoch: 105  loss= 0.09277836233377457\n",
            "shadow model: 96  epoch: 106  loss= 0.17476341128349304\n",
            "shadow model: 96  epoch: 107  loss= 0.0837787538766861\n",
            "shadow model: 96  epoch: 108  loss= 0.12429375946521759\n",
            "shadow model: 96  epoch: 109  loss= 0.23166027665138245\n",
            "shadow model: 96  epoch: 110  loss= 0.17476744949817657\n",
            "shadow model: 96  epoch: 111  loss= 0.0727592334151268\n",
            "shadow model: 96  epoch: 112  loss= 0.05403774231672287\n",
            "shadow model: 96  epoch: 113  loss= 0.13657376170158386\n",
            "shadow model: 96  epoch: 114  loss= 0.15055334568023682\n",
            "shadow model: 96  epoch: 115  loss= 0.17237962782382965\n",
            "shadow model: 96  epoch: 116  loss= 0.13371530175209045\n",
            "shadow model: 96  epoch: 117  loss= 0.15990588068962097\n",
            "shadow model: 96  epoch: 118  loss= 0.214187353849411\n",
            "shadow model: 96  epoch: 119  loss= 0.11363834142684937\n",
            "shadow model: 96  epoch: 120  loss= 0.02889682911336422\n",
            "shadow model: 96  epoch: 121  loss= 0.08799632638692856\n",
            "shadow model: 96  epoch: 122  loss= 0.14526240527629852\n",
            "shadow model: 96  epoch: 123  loss= 0.02291661873459816\n",
            "shadow model: 96  epoch: 124  loss= 0.06780309230089188\n",
            "shadow model: 96  epoch: 125  loss= 0.03940211609005928\n",
            "shadow model: 96  epoch: 126  loss= 0.12431859970092773\n",
            "shadow model: 96  epoch: 127  loss= 0.15689094364643097\n",
            "shadow model: 96  epoch: 128  loss= 0.18804243206977844\n",
            "shadow model: 96  epoch: 129  loss= 0.10823608934879303\n",
            "shadow model: 96  epoch: 130  loss= 0.0435962975025177\n",
            "shadow model: 96  epoch: 131  loss= 0.16639971733093262\n",
            "shadow model: 96  epoch: 132  loss= 0.09074332565069199\n",
            "shadow model: 96  epoch: 133  loss= 0.06695341318845749\n",
            "shadow model: 96  epoch: 134  loss= 0.10501106828451157\n",
            "shadow model: 96  epoch: 135  loss= 0.03983984887599945\n",
            "shadow model: 96  epoch: 136  loss= 0.13448260724544525\n",
            "shadow model: 96  epoch: 137  loss= 0.10684838891029358\n",
            "shadow model: 96  epoch: 138  loss= 0.018193665891885757\n",
            "shadow model: 96  epoch: 139  loss= 0.06806077808141708\n",
            "shadow model: 96  epoch: 140  loss= 0.2649417519569397\n",
            "shadow model: 96  epoch: 141  loss= 0.13589748740196228\n",
            "shadow model: 96  epoch: 142  loss= 0.10277865082025528\n",
            "shadow model: 96  epoch: 143  loss= 0.030686799436807632\n",
            "shadow model: 96  epoch: 144  loss= 0.12650035321712494\n",
            "shadow model: 96  epoch: 145  loss= 0.015352575108408928\n",
            "shadow model: 96  epoch: 146  loss= 0.06362544745206833\n",
            "shadow model: 96  epoch: 147  loss= 0.1247740238904953\n",
            "shadow model: 96  epoch: 148  loss= 0.04887445271015167\n",
            "shadow model: 96  epoch: 149  loss= 0.01394728384912014\n",
            "\n",
            "shadow model: 97  epoch: 0  loss= 2.2952516078948975\n",
            "shadow model: 97  epoch: 1  loss= 2.3116166591644287\n",
            "shadow model: 97  epoch: 2  loss= 2.1512532234191895\n",
            "shadow model: 97  epoch: 3  loss= 2.071563482284546\n",
            "shadow model: 97  epoch: 4  loss= 1.9387561082839966\n",
            "shadow model: 97  epoch: 5  loss= 1.9659010171890259\n",
            "shadow model: 97  epoch: 6  loss= 1.9561026096343994\n",
            "shadow model: 97  epoch: 7  loss= 1.8980015516281128\n",
            "shadow model: 97  epoch: 8  loss= 1.8381410837173462\n",
            "shadow model: 97  epoch: 9  loss= 1.6698005199432373\n",
            "shadow model: 97  epoch: 10  loss= 1.625038504600525\n",
            "shadow model: 97  epoch: 11  loss= 1.7030712366104126\n",
            "shadow model: 97  epoch: 12  loss= 1.587925910949707\n",
            "shadow model: 97  epoch: 13  loss= 1.4975248575210571\n",
            "shadow model: 97  epoch: 14  loss= 1.3833709955215454\n",
            "shadow model: 97  epoch: 15  loss= 1.184901475906372\n",
            "shadow model: 97  epoch: 16  loss= 1.3913062810897827\n",
            "shadow model: 97  epoch: 17  loss= 1.3563817739486694\n",
            "shadow model: 97  epoch: 18  loss= 1.1779005527496338\n",
            "shadow model: 97  epoch: 19  loss= 1.0643267631530762\n",
            "shadow model: 97  epoch: 20  loss= 1.3352558612823486\n",
            "shadow model: 97  epoch: 21  loss= 0.9444178342819214\n",
            "shadow model: 97  epoch: 22  loss= 0.9880102276802063\n",
            "shadow model: 97  epoch: 23  loss= 1.002606987953186\n",
            "shadow model: 97  epoch: 24  loss= 1.160390853881836\n",
            "shadow model: 97  epoch: 25  loss= 0.8962720036506653\n",
            "shadow model: 97  epoch: 26  loss= 0.816423237323761\n",
            "shadow model: 97  epoch: 27  loss= 0.5621877312660217\n",
            "shadow model: 97  epoch: 28  loss= 0.7595040202140808\n",
            "shadow model: 97  epoch: 29  loss= 0.8850283026695251\n",
            "shadow model: 97  epoch: 30  loss= 0.7294985055923462\n",
            "shadow model: 97  epoch: 31  loss= 0.8186601996421814\n",
            "shadow model: 97  epoch: 32  loss= 0.6408817172050476\n",
            "shadow model: 97  epoch: 33  loss= 0.6782416105270386\n",
            "shadow model: 97  epoch: 34  loss= 0.7015421390533447\n",
            "shadow model: 97  epoch: 35  loss= 0.5656626224517822\n",
            "shadow model: 97  epoch: 36  loss= 0.4529019296169281\n",
            "shadow model: 97  epoch: 37  loss= 0.653899073600769\n",
            "shadow model: 97  epoch: 38  loss= 0.49277931451797485\n",
            "shadow model: 97  epoch: 39  loss= 0.5138716697692871\n",
            "shadow model: 97  epoch: 40  loss= 0.31703731417655945\n",
            "shadow model: 97  epoch: 41  loss= 0.37642908096313477\n",
            "shadow model: 97  epoch: 42  loss= 0.393205463886261\n",
            "shadow model: 97  epoch: 43  loss= 0.2923390865325928\n",
            "shadow model: 97  epoch: 44  loss= 0.35876893997192383\n",
            "shadow model: 97  epoch: 45  loss= 0.631889820098877\n",
            "shadow model: 97  epoch: 46  loss= 0.3379504382610321\n",
            "shadow model: 97  epoch: 47  loss= 0.23399443924427032\n",
            "shadow model: 97  epoch: 48  loss= 0.4964732229709625\n",
            "shadow model: 97  epoch: 49  loss= 0.38606858253479004\n",
            "shadow model: 97  epoch: 50  loss= 0.34437742829322815\n",
            "shadow model: 97  epoch: 51  loss= 0.4440114200115204\n",
            "shadow model: 97  epoch: 52  loss= 0.45963963866233826\n",
            "shadow model: 97  epoch: 53  loss= 0.3624833822250366\n",
            "shadow model: 97  epoch: 54  loss= 0.24436739087104797\n",
            "shadow model: 97  epoch: 55  loss= 0.2747998833656311\n",
            "shadow model: 97  epoch: 56  loss= 0.3309119939804077\n",
            "shadow model: 97  epoch: 57  loss= 0.2153446078300476\n",
            "shadow model: 97  epoch: 58  loss= 0.15215380489826202\n",
            "shadow model: 97  epoch: 59  loss= 0.3362966775894165\n",
            "shadow model: 97  epoch: 60  loss= 0.16186974942684174\n",
            "shadow model: 97  epoch: 61  loss= 0.1639515608549118\n",
            "shadow model: 97  epoch: 62  loss= 0.3388821482658386\n",
            "shadow model: 97  epoch: 63  loss= 0.13743856549263\n",
            "shadow model: 97  epoch: 64  loss= 0.38097018003463745\n",
            "shadow model: 97  epoch: 65  loss= 0.2935045659542084\n",
            "shadow model: 97  epoch: 66  loss= 0.2022525519132614\n",
            "shadow model: 97  epoch: 67  loss= 0.25532233715057373\n",
            "shadow model: 97  epoch: 68  loss= 0.09764472395181656\n",
            "shadow model: 97  epoch: 69  loss= 0.18733660876750946\n",
            "shadow model: 97  epoch: 70  loss= 0.2142830789089203\n",
            "shadow model: 97  epoch: 71  loss= 0.29846012592315674\n",
            "shadow model: 97  epoch: 72  loss= 0.17645087838172913\n",
            "shadow model: 97  epoch: 73  loss= 0.13306410610675812\n",
            "shadow model: 97  epoch: 74  loss= 0.23626908659934998\n",
            "shadow model: 97  epoch: 75  loss= 0.13207949697971344\n",
            "shadow model: 97  epoch: 76  loss= 0.15301300585269928\n",
            "shadow model: 97  epoch: 77  loss= 0.14611074328422546\n",
            "shadow model: 97  epoch: 78  loss= 0.2571457326412201\n",
            "shadow model: 97  epoch: 79  loss= 0.1413341760635376\n",
            "shadow model: 97  epoch: 80  loss= 0.26904433965682983\n",
            "shadow model: 97  epoch: 81  loss= 0.14154747128486633\n",
            "shadow model: 97  epoch: 82  loss= 0.07897347211837769\n",
            "shadow model: 97  epoch: 83  loss= 0.20468690991401672\n",
            "shadow model: 97  epoch: 84  loss= 0.1339951902627945\n",
            "shadow model: 97  epoch: 85  loss= 0.2301819920539856\n",
            "shadow model: 97  epoch: 86  loss= 0.28114330768585205\n",
            "shadow model: 97  epoch: 87  loss= 0.07663895189762115\n",
            "shadow model: 97  epoch: 88  loss= 0.20224228501319885\n",
            "shadow model: 97  epoch: 89  loss= 0.05402181297540665\n",
            "shadow model: 97  epoch: 90  loss= 0.07425431162118912\n",
            "shadow model: 97  epoch: 91  loss= 0.06808041036128998\n",
            "shadow model: 97  epoch: 92  loss= 0.11730983108282089\n",
            "shadow model: 97  epoch: 93  loss= 0.08768092095851898\n",
            "shadow model: 97  epoch: 94  loss= 0.09815040975809097\n",
            "shadow model: 97  epoch: 95  loss= 0.04989171028137207\n",
            "shadow model: 97  epoch: 96  loss= 0.06105788052082062\n",
            "shadow model: 97  epoch: 97  loss= 0.22804208099842072\n",
            "shadow model: 97  epoch: 98  loss= 0.22364221513271332\n",
            "shadow model: 97  epoch: 99  loss= 0.40585604310035706\n",
            "shadow model: 97  epoch: 100  loss= 0.2125086486339569\n",
            "shadow model: 97  epoch: 101  loss= 0.1788329929113388\n",
            "shadow model: 97  epoch: 102  loss= 0.1929723173379898\n",
            "shadow model: 97  epoch: 103  loss= 0.14228017628192902\n",
            "shadow model: 97  epoch: 104  loss= 0.08405205607414246\n",
            "shadow model: 97  epoch: 105  loss= 0.14603839814662933\n",
            "shadow model: 97  epoch: 106  loss= 0.2085767686367035\n",
            "shadow model: 97  epoch: 107  loss= 0.14260371029376984\n",
            "shadow model: 97  epoch: 108  loss= 0.15023496747016907\n",
            "shadow model: 97  epoch: 109  loss= 0.07193242013454437\n",
            "shadow model: 97  epoch: 110  loss= 0.09237595647573471\n",
            "shadow model: 97  epoch: 111  loss= 0.16569112241268158\n",
            "shadow model: 97  epoch: 112  loss= 0.12085050344467163\n",
            "shadow model: 97  epoch: 113  loss= 0.13253872096538544\n",
            "shadow model: 97  epoch: 114  loss= 0.0425587072968483\n",
            "shadow model: 97  epoch: 115  loss= 0.0497920848429203\n",
            "shadow model: 97  epoch: 116  loss= 0.16897748410701752\n",
            "shadow model: 97  epoch: 117  loss= 0.12458337098360062\n",
            "shadow model: 97  epoch: 118  loss= 0.11694981902837753\n",
            "shadow model: 97  epoch: 119  loss= 0.04387153685092926\n",
            "shadow model: 97  epoch: 120  loss= 0.06527753919363022\n",
            "shadow model: 97  epoch: 121  loss= 0.30379071831703186\n",
            "shadow model: 97  epoch: 122  loss= 0.12374414503574371\n",
            "shadow model: 97  epoch: 123  loss= 0.07162108272314072\n",
            "shadow model: 97  epoch: 124  loss= 0.11664264649152756\n",
            "shadow model: 97  epoch: 125  loss= 0.06508723646402359\n",
            "shadow model: 97  epoch: 126  loss= 0.05415533855557442\n",
            "shadow model: 97  epoch: 127  loss= 0.05053829029202461\n",
            "shadow model: 97  epoch: 128  loss= 0.06957503408193588\n",
            "shadow model: 97  epoch: 129  loss= 0.0857907384634018\n",
            "shadow model: 97  epoch: 130  loss= 0.06730124354362488\n",
            "shadow model: 97  epoch: 131  loss= 0.04673879221081734\n",
            "shadow model: 97  epoch: 132  loss= 0.14332906901836395\n",
            "shadow model: 97  epoch: 133  loss= 0.10033323615789413\n",
            "shadow model: 97  epoch: 134  loss= 0.05341784656047821\n",
            "shadow model: 97  epoch: 135  loss= 0.06693712621927261\n",
            "shadow model: 97  epoch: 136  loss= 0.14076729118824005\n",
            "shadow model: 97  epoch: 137  loss= 0.30807235836982727\n",
            "shadow model: 97  epoch: 138  loss= 0.05989000201225281\n",
            "shadow model: 97  epoch: 139  loss= 0.14630834758281708\n",
            "shadow model: 97  epoch: 140  loss= 0.2092771828174591\n",
            "shadow model: 97  epoch: 141  loss= 0.10631753504276276\n",
            "shadow model: 97  epoch: 142  loss= 0.13988283276557922\n",
            "shadow model: 97  epoch: 143  loss= 0.04553430527448654\n",
            "shadow model: 97  epoch: 144  loss= 0.08059795945882797\n",
            "shadow model: 97  epoch: 145  loss= 0.06594359129667282\n",
            "shadow model: 97  epoch: 146  loss= 0.08478013426065445\n",
            "shadow model: 97  epoch: 147  loss= 0.10058505088090897\n",
            "shadow model: 97  epoch: 148  loss= 0.1681554615497589\n",
            "shadow model: 97  epoch: 149  loss= 0.040803246200084686\n",
            "\n",
            "shadow model: 98  epoch: 0  loss= 2.3301639556884766\n",
            "shadow model: 98  epoch: 1  loss= 2.2590372562408447\n",
            "shadow model: 98  epoch: 2  loss= 2.2513844966888428\n",
            "shadow model: 98  epoch: 3  loss= 2.2172131538391113\n",
            "shadow model: 98  epoch: 4  loss= 2.0440144538879395\n",
            "shadow model: 98  epoch: 5  loss= 2.1405632495880127\n",
            "shadow model: 98  epoch: 6  loss= 1.9458162784576416\n",
            "shadow model: 98  epoch: 7  loss= 1.9660731554031372\n",
            "shadow model: 98  epoch: 8  loss= 1.9532667398452759\n",
            "shadow model: 98  epoch: 9  loss= 1.8875905275344849\n",
            "shadow model: 98  epoch: 10  loss= 1.799257516860962\n",
            "shadow model: 98  epoch: 11  loss= 1.7860562801361084\n",
            "shadow model: 98  epoch: 12  loss= 1.7836779356002808\n",
            "shadow model: 98  epoch: 13  loss= 1.6559150218963623\n",
            "shadow model: 98  epoch: 14  loss= 1.659411072731018\n",
            "shadow model: 98  epoch: 15  loss= 1.3548699617385864\n",
            "shadow model: 98  epoch: 16  loss= 1.4949150085449219\n",
            "shadow model: 98  epoch: 17  loss= 1.329723596572876\n",
            "shadow model: 98  epoch: 18  loss= 1.174131989479065\n",
            "shadow model: 98  epoch: 19  loss= 1.3229953050613403\n",
            "shadow model: 98  epoch: 20  loss= 1.2408555746078491\n",
            "shadow model: 98  epoch: 21  loss= 1.1197519302368164\n",
            "shadow model: 98  epoch: 22  loss= 0.9785882234573364\n",
            "shadow model: 98  epoch: 23  loss= 1.195726990699768\n",
            "shadow model: 98  epoch: 24  loss= 1.0028681755065918\n",
            "shadow model: 98  epoch: 25  loss= 0.9293946027755737\n",
            "shadow model: 98  epoch: 26  loss= 0.8732309937477112\n",
            "shadow model: 98  epoch: 27  loss= 0.6637307405471802\n",
            "shadow model: 98  epoch: 28  loss= 0.8852128386497498\n",
            "shadow model: 98  epoch: 29  loss= 0.7928581237792969\n",
            "shadow model: 98  epoch: 30  loss= 0.7958275675773621\n",
            "shadow model: 98  epoch: 31  loss= 0.6784632205963135\n",
            "shadow model: 98  epoch: 32  loss= 0.5261132717132568\n",
            "shadow model: 98  epoch: 33  loss= 0.9133259654045105\n",
            "shadow model: 98  epoch: 34  loss= 0.7533485293388367\n",
            "shadow model: 98  epoch: 35  loss= 0.6112761497497559\n",
            "shadow model: 98  epoch: 36  loss= 0.520466148853302\n",
            "shadow model: 98  epoch: 37  loss= 0.5577599406242371\n",
            "shadow model: 98  epoch: 38  loss= 0.3445797264575958\n",
            "shadow model: 98  epoch: 39  loss= 0.5435047745704651\n",
            "shadow model: 98  epoch: 40  loss= 0.375149130821228\n",
            "shadow model: 98  epoch: 41  loss= 0.5591826438903809\n",
            "shadow model: 98  epoch: 42  loss= 0.4700382351875305\n",
            "shadow model: 98  epoch: 43  loss= 0.780059814453125\n",
            "shadow model: 98  epoch: 44  loss= 0.40122032165527344\n",
            "shadow model: 98  epoch: 45  loss= 0.33775994181632996\n",
            "shadow model: 98  epoch: 46  loss= 0.5540366768836975\n",
            "shadow model: 98  epoch: 47  loss= 0.32842519879341125\n",
            "shadow model: 98  epoch: 48  loss= 0.4653710722923279\n",
            "shadow model: 98  epoch: 49  loss= 0.4410756528377533\n",
            "shadow model: 98  epoch: 50  loss= 0.36476513743400574\n",
            "shadow model: 98  epoch: 51  loss= 0.3097165524959564\n",
            "shadow model: 98  epoch: 52  loss= 0.36706480383872986\n",
            "shadow model: 98  epoch: 53  loss= 0.25557389855384827\n",
            "shadow model: 98  epoch: 54  loss= 0.3829452395439148\n",
            "shadow model: 98  epoch: 55  loss= 0.1132422536611557\n",
            "shadow model: 98  epoch: 56  loss= 0.3735564947128296\n",
            "shadow model: 98  epoch: 57  loss= 0.203398659825325\n",
            "shadow model: 98  epoch: 58  loss= 0.14473390579223633\n",
            "shadow model: 98  epoch: 59  loss= 0.3333442807197571\n",
            "shadow model: 98  epoch: 60  loss= 0.11152100563049316\n",
            "shadow model: 98  epoch: 61  loss= 0.33552709221839905\n",
            "shadow model: 98  epoch: 62  loss= 0.24251392483711243\n",
            "shadow model: 98  epoch: 63  loss= 0.26486799120903015\n",
            "shadow model: 98  epoch: 64  loss= 0.18495042622089386\n",
            "shadow model: 98  epoch: 65  loss= 0.34773334860801697\n",
            "shadow model: 98  epoch: 66  loss= 0.3088989853858948\n",
            "shadow model: 98  epoch: 67  loss= 0.559060275554657\n",
            "shadow model: 98  epoch: 68  loss= 0.11404401063919067\n",
            "shadow model: 98  epoch: 69  loss= 0.24694335460662842\n",
            "shadow model: 98  epoch: 70  loss= 0.33655864000320435\n",
            "shadow model: 98  epoch: 71  loss= 0.16991029679775238\n",
            "shadow model: 98  epoch: 72  loss= 0.12390296906232834\n",
            "shadow model: 98  epoch: 73  loss= 0.2761662006378174\n",
            "shadow model: 98  epoch: 74  loss= 0.24149972200393677\n",
            "shadow model: 98  epoch: 75  loss= 0.09421732276678085\n",
            "shadow model: 98  epoch: 76  loss= 0.29075855016708374\n",
            "shadow model: 98  epoch: 77  loss= 0.20353853702545166\n",
            "shadow model: 98  epoch: 78  loss= 0.264339417219162\n",
            "shadow model: 98  epoch: 79  loss= 0.24588732421398163\n",
            "shadow model: 98  epoch: 80  loss= 0.19871646165847778\n",
            "shadow model: 98  epoch: 81  loss= 0.1739634871482849\n",
            "shadow model: 98  epoch: 82  loss= 0.19522367417812347\n",
            "shadow model: 98  epoch: 83  loss= 0.09687003493309021\n",
            "shadow model: 98  epoch: 84  loss= 0.1326184719800949\n",
            "shadow model: 98  epoch: 85  loss= 0.13676021993160248\n",
            "shadow model: 98  epoch: 86  loss= 0.15107570588588715\n",
            "shadow model: 98  epoch: 87  loss= 0.24271008372306824\n",
            "shadow model: 98  epoch: 88  loss= 0.17669223248958588\n",
            "shadow model: 98  epoch: 89  loss= 0.10804607719182968\n",
            "shadow model: 98  epoch: 90  loss= 0.14264129102230072\n",
            "shadow model: 98  epoch: 91  loss= 0.16327576339244843\n",
            "shadow model: 98  epoch: 92  loss= 0.19664590060710907\n",
            "shadow model: 98  epoch: 93  loss= 0.03747568279504776\n",
            "shadow model: 98  epoch: 94  loss= 0.10946708917617798\n",
            "shadow model: 98  epoch: 95  loss= 0.15924032032489777\n",
            "shadow model: 98  epoch: 96  loss= 0.29972922801971436\n",
            "shadow model: 98  epoch: 97  loss= 0.19413414597511292\n",
            "shadow model: 98  epoch: 98  loss= 0.148870587348938\n",
            "shadow model: 98  epoch: 99  loss= 0.13742224872112274\n",
            "shadow model: 98  epoch: 100  loss= 0.1628546565771103\n",
            "shadow model: 98  epoch: 101  loss= 0.22131560742855072\n",
            "shadow model: 98  epoch: 102  loss= 0.07154019922018051\n",
            "shadow model: 98  epoch: 103  loss= 0.24610882997512817\n",
            "shadow model: 98  epoch: 104  loss= 0.1384444534778595\n",
            "shadow model: 98  epoch: 105  loss= 0.19049818813800812\n",
            "shadow model: 98  epoch: 106  loss= 0.09161043912172318\n",
            "shadow model: 98  epoch: 107  loss= 0.24752993881702423\n",
            "shadow model: 98  epoch: 108  loss= 0.18712446093559265\n",
            "shadow model: 98  epoch: 109  loss= 0.16319842636585236\n",
            "shadow model: 98  epoch: 110  loss= 0.06119614467024803\n",
            "shadow model: 98  epoch: 111  loss= 0.15969251096248627\n",
            "shadow model: 98  epoch: 112  loss= 0.08041627705097198\n",
            "shadow model: 98  epoch: 113  loss= 0.16309256851673126\n",
            "shadow model: 98  epoch: 114  loss= 0.06580161303281784\n",
            "shadow model: 98  epoch: 115  loss= 0.13555459678173065\n",
            "shadow model: 98  epoch: 116  loss= 0.08637719601392746\n",
            "shadow model: 98  epoch: 117  loss= 0.08907168358564377\n",
            "shadow model: 98  epoch: 118  loss= 0.025452008470892906\n",
            "shadow model: 98  epoch: 119  loss= 0.09128882735967636\n",
            "shadow model: 98  epoch: 120  loss= 0.038653623312711716\n",
            "shadow model: 98  epoch: 121  loss= 0.05965990573167801\n",
            "shadow model: 98  epoch: 122  loss= 0.14187775552272797\n",
            "shadow model: 98  epoch: 123  loss= 0.12001059949398041\n",
            "shadow model: 98  epoch: 124  loss= 0.13251268863677979\n",
            "shadow model: 98  epoch: 125  loss= 0.11138211935758591\n",
            "shadow model: 98  epoch: 126  loss= 0.03999205306172371\n",
            "shadow model: 98  epoch: 127  loss= 0.05535378307104111\n",
            "shadow model: 98  epoch: 128  loss= 0.04850779101252556\n",
            "shadow model: 98  epoch: 129  loss= 0.15607209503650665\n",
            "shadow model: 98  epoch: 130  loss= 0.0792660042643547\n",
            "shadow model: 98  epoch: 131  loss= 0.07081262767314911\n",
            "shadow model: 98  epoch: 132  loss= 0.09800173342227936\n",
            "shadow model: 98  epoch: 133  loss= 0.056331731379032135\n",
            "shadow model: 98  epoch: 134  loss= 0.09351829439401627\n",
            "shadow model: 98  epoch: 135  loss= 0.10065588355064392\n",
            "shadow model: 98  epoch: 136  loss= 0.18822269141674042\n",
            "shadow model: 98  epoch: 137  loss= 0.06913800537586212\n",
            "shadow model: 98  epoch: 138  loss= 0.16478867828845978\n",
            "shadow model: 98  epoch: 139  loss= 0.0865427628159523\n",
            "shadow model: 98  epoch: 140  loss= 0.186715766787529\n",
            "shadow model: 98  epoch: 141  loss= 0.09949375689029694\n",
            "shadow model: 98  epoch: 142  loss= 0.07801628112792969\n",
            "shadow model: 98  epoch: 143  loss= 0.15705375373363495\n",
            "shadow model: 98  epoch: 144  loss= 0.04554212838411331\n",
            "shadow model: 98  epoch: 145  loss= 0.04275903478264809\n",
            "shadow model: 98  epoch: 146  loss= 0.1627397984266281\n",
            "shadow model: 98  epoch: 147  loss= 0.06855524331331253\n",
            "shadow model: 98  epoch: 148  loss= 0.06319211423397064\n",
            "shadow model: 98  epoch: 149  loss= 0.03433363512158394\n",
            "\n",
            "shadow model: 99  epoch: 0  loss= 2.3447628021240234\n",
            "shadow model: 99  epoch: 1  loss= 2.2764053344726562\n",
            "shadow model: 99  epoch: 2  loss= 2.1631577014923096\n",
            "shadow model: 99  epoch: 3  loss= 2.145907163619995\n",
            "shadow model: 99  epoch: 4  loss= 2.0148422718048096\n",
            "shadow model: 99  epoch: 5  loss= 1.8618745803833008\n",
            "shadow model: 99  epoch: 6  loss= 1.7964948415756226\n",
            "shadow model: 99  epoch: 7  loss= 1.9419775009155273\n",
            "shadow model: 99  epoch: 8  loss= 1.7752290964126587\n",
            "shadow model: 99  epoch: 9  loss= 1.737384557723999\n",
            "shadow model: 99  epoch: 10  loss= 1.5748662948608398\n",
            "shadow model: 99  epoch: 11  loss= 1.5158255100250244\n",
            "shadow model: 99  epoch: 12  loss= 1.3519428968429565\n",
            "shadow model: 99  epoch: 13  loss= 1.2216812372207642\n",
            "shadow model: 99  epoch: 14  loss= 1.1380529403686523\n",
            "shadow model: 99  epoch: 15  loss= 1.2586363554000854\n",
            "shadow model: 99  epoch: 16  loss= 1.0128488540649414\n",
            "shadow model: 99  epoch: 17  loss= 1.158357858657837\n",
            "shadow model: 99  epoch: 18  loss= 1.1244909763336182\n",
            "shadow model: 99  epoch: 19  loss= 0.9725838899612427\n",
            "shadow model: 99  epoch: 20  loss= 1.016534686088562\n",
            "shadow model: 99  epoch: 21  loss= 0.8929255604743958\n",
            "shadow model: 99  epoch: 22  loss= 0.866064190864563\n",
            "shadow model: 99  epoch: 23  loss= 0.8853350877761841\n",
            "shadow model: 99  epoch: 24  loss= 0.9275223612785339\n",
            "shadow model: 99  epoch: 25  loss= 0.6460272669792175\n",
            "shadow model: 99  epoch: 26  loss= 0.620805025100708\n",
            "shadow model: 99  epoch: 27  loss= 0.5698855519294739\n",
            "shadow model: 99  epoch: 28  loss= 0.6062644720077515\n",
            "shadow model: 99  epoch: 29  loss= 0.8492253422737122\n",
            "shadow model: 99  epoch: 30  loss= 0.4448936879634857\n",
            "shadow model: 99  epoch: 31  loss= 0.39320817589759827\n",
            "shadow model: 99  epoch: 32  loss= 0.4045150876045227\n",
            "shadow model: 99  epoch: 33  loss= 0.3195348381996155\n",
            "shadow model: 99  epoch: 34  loss= 0.43915557861328125\n",
            "shadow model: 99  epoch: 35  loss= 0.3126632273197174\n",
            "shadow model: 99  epoch: 36  loss= 0.29618820548057556\n",
            "shadow model: 99  epoch: 37  loss= 0.3017692565917969\n",
            "shadow model: 99  epoch: 38  loss= 0.34989863634109497\n",
            "shadow model: 99  epoch: 39  loss= 0.23872414231300354\n",
            "shadow model: 99  epoch: 40  loss= 0.25325191020965576\n",
            "shadow model: 99  epoch: 41  loss= 0.33478835225105286\n",
            "shadow model: 99  epoch: 42  loss= 0.22213953733444214\n",
            "shadow model: 99  epoch: 43  loss= 0.3009987473487854\n",
            "shadow model: 99  epoch: 44  loss= 0.26295343041419983\n",
            "shadow model: 99  epoch: 45  loss= 0.20231826603412628\n",
            "shadow model: 99  epoch: 46  loss= 0.22314804792404175\n",
            "shadow model: 99  epoch: 47  loss= 0.2534273862838745\n",
            "shadow model: 99  epoch: 48  loss= 0.20827695727348328\n",
            "shadow model: 99  epoch: 49  loss= 0.16791090369224548\n",
            "shadow model: 99  epoch: 50  loss= 0.1295345425605774\n",
            "shadow model: 99  epoch: 51  loss= 0.1531868577003479\n",
            "shadow model: 99  epoch: 52  loss= 0.11395134031772614\n",
            "shadow model: 99  epoch: 53  loss= 0.16177432239055634\n",
            "shadow model: 99  epoch: 54  loss= 0.11240827292203903\n",
            "shadow model: 99  epoch: 55  loss= 0.132395938038826\n",
            "shadow model: 99  epoch: 56  loss= 0.17250148952007294\n",
            "shadow model: 99  epoch: 57  loss= 0.12353773415088654\n",
            "shadow model: 99  epoch: 58  loss= 0.15676391124725342\n",
            "shadow model: 99  epoch: 59  loss= 0.10241314023733139\n",
            "shadow model: 99  epoch: 60  loss= 0.0522569976747036\n",
            "shadow model: 99  epoch: 61  loss= 0.16133944690227509\n",
            "shadow model: 99  epoch: 62  loss= 0.1674538403749466\n",
            "shadow model: 99  epoch: 63  loss= 0.0889856293797493\n",
            "shadow model: 99  epoch: 64  loss= 0.0657348483800888\n",
            "shadow model: 99  epoch: 65  loss= 0.1281924545764923\n",
            "shadow model: 99  epoch: 66  loss= 0.11857195198535919\n",
            "shadow model: 99  epoch: 67  loss= 0.051222141832113266\n",
            "shadow model: 99  epoch: 68  loss= 0.12027405202388763\n",
            "shadow model: 99  epoch: 69  loss= 0.07920072972774506\n",
            "shadow model: 99  epoch: 70  loss= 0.10463296622037888\n",
            "shadow model: 99  epoch: 71  loss= 0.1827189028263092\n",
            "shadow model: 99  epoch: 72  loss= 0.04335140436887741\n",
            "shadow model: 99  epoch: 73  loss= 0.0544135682284832\n",
            "shadow model: 99  epoch: 74  loss= 0.07590135931968689\n",
            "shadow model: 99  epoch: 75  loss= 0.17672669887542725\n",
            "shadow model: 99  epoch: 76  loss= 0.020660510286688805\n",
            "shadow model: 99  epoch: 77  loss= 0.08158022910356522\n",
            "shadow model: 99  epoch: 78  loss= 0.14043201506137848\n",
            "shadow model: 99  epoch: 79  loss= 0.05805138871073723\n",
            "shadow model: 99  epoch: 80  loss= 0.08036075532436371\n",
            "shadow model: 99  epoch: 81  loss= 0.10092657059431076\n",
            "shadow model: 99  epoch: 82  loss= 0.09665600210428238\n",
            "shadow model: 99  epoch: 83  loss= 0.10292790830135345\n",
            "shadow model: 99  epoch: 84  loss= 0.14145252108573914\n",
            "shadow model: 99  epoch: 85  loss= 0.1388094127178192\n",
            "shadow model: 99  epoch: 86  loss= 0.08760923147201538\n",
            "shadow model: 99  epoch: 87  loss= 0.021152133122086525\n",
            "shadow model: 99  epoch: 88  loss= 0.018723253160715103\n",
            "shadow model: 99  epoch: 89  loss= 0.07590612024068832\n",
            "shadow model: 99  epoch: 90  loss= 0.07085662335157394\n",
            "shadow model: 99  epoch: 91  loss= 0.07288729399442673\n",
            "shadow model: 99  epoch: 92  loss= 0.146530419588089\n",
            "shadow model: 99  epoch: 93  loss= 0.06537462025880814\n",
            "shadow model: 99  epoch: 94  loss= 0.08704613149166107\n",
            "shadow model: 99  epoch: 95  loss= 0.09765625\n",
            "shadow model: 99  epoch: 96  loss= 0.049962155520915985\n",
            "shadow model: 99  epoch: 97  loss= 0.11179432272911072\n",
            "shadow model: 99  epoch: 98  loss= 0.07206512242555618\n",
            "shadow model: 99  epoch: 99  loss= 0.11636339128017426\n",
            "shadow model: 99  epoch: 100  loss= 0.07926546782255173\n",
            "shadow model: 99  epoch: 101  loss= 0.05916549637913704\n",
            "shadow model: 99  epoch: 102  loss= 0.0657782182097435\n",
            "shadow model: 99  epoch: 103  loss= 0.02633049711585045\n",
            "shadow model: 99  epoch: 104  loss= 0.06271982938051224\n",
            "shadow model: 99  epoch: 105  loss= 0.057279251515865326\n",
            "shadow model: 99  epoch: 106  loss= 0.048674196004867554\n",
            "shadow model: 99  epoch: 107  loss= 0.02670978009700775\n",
            "shadow model: 99  epoch: 108  loss= 0.06055898219347\n",
            "shadow model: 99  epoch: 109  loss= 0.009805740788578987\n",
            "shadow model: 99  epoch: 110  loss= 0.14188113808631897\n",
            "shadow model: 99  epoch: 111  loss= 0.08845429122447968\n",
            "shadow model: 99  epoch: 112  loss= 0.07048139721155167\n",
            "shadow model: 99  epoch: 113  loss= 0.04495416209101677\n",
            "shadow model: 99  epoch: 114  loss= 0.08414426445960999\n",
            "shadow model: 99  epoch: 115  loss= 0.0584469698369503\n",
            "shadow model: 99  epoch: 116  loss= 0.060518793761730194\n",
            "shadow model: 99  epoch: 117  loss= 0.02443036250770092\n",
            "shadow model: 99  epoch: 118  loss= 0.03051440231502056\n",
            "shadow model: 99  epoch: 119  loss= 0.09221469610929489\n",
            "shadow model: 99  epoch: 120  loss= 0.012436940334737301\n",
            "shadow model: 99  epoch: 121  loss= 0.09024041891098022\n",
            "shadow model: 99  epoch: 122  loss= 0.16764575242996216\n",
            "shadow model: 99  epoch: 123  loss= 0.08067479729652405\n",
            "shadow model: 99  epoch: 124  loss= 0.026525670662522316\n",
            "shadow model: 99  epoch: 125  loss= 0.028897123411297798\n",
            "shadow model: 99  epoch: 126  loss= 0.13905426859855652\n",
            "shadow model: 99  epoch: 127  loss= 0.07770105451345444\n",
            "shadow model: 99  epoch: 128  loss= 0.014917619526386261\n",
            "shadow model: 99  epoch: 129  loss= 0.08421121537685394\n",
            "shadow model: 99  epoch: 130  loss= 0.0758712962269783\n",
            "shadow model: 99  epoch: 131  loss= 0.15348279476165771\n",
            "shadow model: 99  epoch: 132  loss= 0.0533728152513504\n",
            "shadow model: 99  epoch: 133  loss= 0.03477957844734192\n",
            "shadow model: 99  epoch: 134  loss= 0.07447666674852371\n",
            "shadow model: 99  epoch: 135  loss= 0.06860466301441193\n",
            "shadow model: 99  epoch: 136  loss= 0.08198531717061996\n",
            "shadow model: 99  epoch: 137  loss= 0.01850993186235428\n",
            "shadow model: 99  epoch: 138  loss= 0.012993534095585346\n",
            "shadow model: 99  epoch: 139  loss= 0.023489270359277725\n",
            "shadow model: 99  epoch: 140  loss= 0.02991253137588501\n",
            "shadow model: 99  epoch: 141  loss= 0.08344163000583649\n",
            "shadow model: 99  epoch: 142  loss= 0.06887726485729218\n",
            "shadow model: 99  epoch: 143  loss= 0.03171530365943909\n",
            "shadow model: 99  epoch: 144  loss= 0.032926108688116074\n",
            "shadow model: 99  epoch: 145  loss= 0.054488927125930786\n",
            "shadow model: 99  epoch: 146  loss= 0.23772132396697998\n",
            "shadow model: 99  epoch: 147  loss= 0.01742733083665371\n",
            "shadow model: 99  epoch: 148  loss= 0.0964105948805809\n",
            "shadow model: 99  epoch: 149  loss= 0.027768639847636223\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_shadow_model = mia.shadow_models[0]"
      ],
      "metadata": {
        "id": "ahcYuIUX4sEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        test_shadow_model.eval()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = test_shadow_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Loss: {test_loss / len(test_loader)}')\n",
        "print(f'Test Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i0KSg0C4rnw",
        "outputId": "37d3bd46-b649-4f83-bed6-10f31cdb559c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.56208118511613\n",
            "Test Accuracy: 41.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mia.prepare_attack_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC4RDq8-6OtD",
        "outputId": "37d3dc3a-85d6-47ba-bffb-6eb9b2a0b279"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cls= 0\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 1\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 2\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 3\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 4\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 5\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 6\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 7\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 8\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n",
            "cls= 9\n",
            "shadow model= 1\n",
            "shadow model= 2\n",
            "shadow model= 3\n",
            "shadow model= 4\n",
            "shadow model= 5\n",
            "shadow model= 6\n",
            "shadow model= 7\n",
            "shadow model= 8\n",
            "shadow model= 9\n",
            "shadow model= 10\n",
            "shadow model= 11\n",
            "shadow model= 12\n",
            "shadow model= 13\n",
            "shadow model= 14\n",
            "shadow model= 15\n",
            "shadow model= 16\n",
            "shadow model= 17\n",
            "shadow model= 18\n",
            "shadow model= 19\n",
            "shadow model= 20\n",
            "shadow model= 21\n",
            "shadow model= 22\n",
            "shadow model= 23\n",
            "shadow model= 24\n",
            "shadow model= 25\n",
            "shadow model= 26\n",
            "shadow model= 27\n",
            "shadow model= 28\n",
            "shadow model= 29\n",
            "shadow model= 30\n",
            "shadow model= 31\n",
            "shadow model= 32\n",
            "shadow model= 33\n",
            "shadow model= 34\n",
            "shadow model= 35\n",
            "shadow model= 36\n",
            "shadow model= 37\n",
            "shadow model= 38\n",
            "shadow model= 39\n",
            "shadow model= 40\n",
            "shadow model= 41\n",
            "shadow model= 42\n",
            "shadow model= 43\n",
            "shadow model= 44\n",
            "shadow model= 45\n",
            "shadow model= 46\n",
            "shadow model= 47\n",
            "shadow model= 48\n",
            "shadow model= 49\n",
            "shadow model= 50\n",
            "shadow model= 51\n",
            "shadow model= 52\n",
            "shadow model= 53\n",
            "shadow model= 54\n",
            "shadow model= 55\n",
            "shadow model= 56\n",
            "shadow model= 57\n",
            "shadow model= 58\n",
            "shadow model= 59\n",
            "shadow model= 60\n",
            "shadow model= 61\n",
            "shadow model= 62\n",
            "shadow model= 63\n",
            "shadow model= 64\n",
            "shadow model= 65\n",
            "shadow model= 66\n",
            "shadow model= 67\n",
            "shadow model= 68\n",
            "shadow model= 69\n",
            "shadow model= 70\n",
            "shadow model= 71\n",
            "shadow model= 72\n",
            "shadow model= 73\n",
            "shadow model= 74\n",
            "shadow model= 75\n",
            "shadow model= 76\n",
            "shadow model= 77\n",
            "shadow model= 78\n",
            "shadow model= 79\n",
            "shadow model= 80\n",
            "shadow model= 81\n",
            "shadow model= 82\n",
            "shadow model= 83\n",
            "shadow model= 84\n",
            "shadow model= 85\n",
            "shadow model= 86\n",
            "shadow model= 87\n",
            "shadow model= 88\n",
            "shadow model= 89\n",
            "shadow model= 90\n",
            "shadow model= 91\n",
            "shadow model= 92\n",
            "shadow model= 93\n",
            "shadow model= 94\n",
            "shadow model= 95\n",
            "shadow model= 96\n",
            "shadow model= 97\n",
            "shadow model= 98\n",
            "shadow model= 99\n",
            "shadow model= 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train attack models\n",
        "mia.train_attack_models()"
      ],
      "metadata": {
        "id": "dhwzda43h4ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4be8d29-6243-4e1b-b748-98e75b83b222"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "3512\n",
            "3512\n",
            "1\n",
            "3588\n",
            "3588\n",
            "2\n",
            "3614\n",
            "3614\n",
            "3\n",
            "3570\n",
            "3570\n",
            "4\n",
            "3582\n",
            "3582\n",
            "5\n",
            "3386\n",
            "3386\n",
            "6\n",
            "3522\n",
            "3522\n",
            "7\n",
            "3518\n",
            "3518\n",
            "8\n",
            "3552\n",
            "3552\n",
            "9\n",
            "3544\n",
            "3544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models to drive\n",
        "mia.save_shadow_models('shadow_models_4')\n",
        "mia.save_attack_models('attack_models_4')"
      ],
      "metadata": {
        "id": "hWoTU1vZh5nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload models to drive\n",
        "mia.upload_to_drive('shadow_models_4', 'shadow_models_4')\n",
        "mia.upload_to_drive('attack_models_4', 'attack_models_4')"
      ],
      "metadata": {
        "id": "qSRz_QI_h8hk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8dbfdb9-d1c7-4ffc-fa67-ab80b0c32a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from model import CIFAR10Classifier\n",
        "\n",
        "# Instantiate the model\n",
        "model = CIFAR10Classifier()\n",
        "\n",
        "# Load the state dict\n",
        "state_dict = torch.load(\"model_state_dict.pth\")\n",
        "new_state_dict = {}\n",
        "for key, value in state_dict.items():\n",
        "    new_key = key.replace('_module.', '')\n",
        "    new_state_dict[new_key] = value\n",
        "\n",
        "# Load the state dict into the model\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded and set to evaluation mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ha3Bt8cQQIb",
        "outputId": "9c6bb6ba-d1c7-4b6d-ef28-544a719a15a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and set to evaluation mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**download and load:**"
      ],
      "metadata": {
        "id": "1Ky_rUQsCZVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MembershipInferenceAttack\n",
        "mia = MembershipInferenceAttack(trainset, testset, model, device, epochs=200, num_shadow_models=5)"
      ],
      "metadata": {
        "id": "fY91fuCoCemg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you need to download models from Google Drive, use the following functions\n",
        "# Replace 'your_drive_path' and 'local_path' with the appropriate paths\n",
        "mia.download_from_drive('shadow_models_4', 'shadow_models_4')\n",
        "mia.download_from_drive('attack_models_4', 'attack_models_4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzhJ60iqCgCE",
        "outputId": "7f5308e0-6382-4f0c-dd3a-104ae1be83f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the shadow models and attack models\n",
        "mia.load_shadow_models(folder_path='shadow_models_4')\n",
        "mia.load_attack_models(folder_path='attack_models_4')"
      ],
      "metadata": {
        "id": "2gOffjgKCZjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_models = mia.attack_models"
      ],
      "metadata": {
        "id": "82kwRuPwNWG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **real model**"
      ],
      "metadata": {
        "id": "2BPYPw8QQrUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class CIFAR10Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CIFAR10Classifier, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.dropout2 = nn.Dropout2d(0.5)\n",
        "    self.fc1 = nn.Linear(6272, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "RMQsWdpPRaH9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Subset, DataLoader, TensorDataset\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the main model\n",
        "model = CIFAR10Classifier()\n",
        "state_dict = torch.load(\"model_state_dict.pth\", map_location=device)\n",
        "new_state_dict = {key.replace('_module.', ''): value for key, value in state_dict.items()}\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "DATA_ROOT = '../cifar10'\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "# Load the indices from list.txt\n",
        "indices_file = 'list.txt'\n",
        "with open(indices_file, 'r') as f:\n",
        "    indices = [int(line.strip()) for line in f]\n",
        "\n",
        "\n",
        "\n",
        "full_train_dataset = CIFAR10(root=DATA_ROOT, train=True, download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root=DATA_ROOT, train=False, download=True, transform=transform)\n",
        "\n",
        "train_indices_set = set(indices)\n",
        "all_indices = set(range(len(full_train_dataset)))\n",
        "other_indices = list(all_indices - train_indices_set)\n",
        "\n",
        "train_dataset = Subset(full_train_dataset, indices[:len(indices)//2])\n",
        "other_dataset = Subset(full_train_dataset, other_indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "other_loader = DataLoader(other_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Create labels\n",
        "train_labels = torch.ones(len(train_dataset)).to(device)\n",
        "other_labels = torch.zeros(len(other_dataset)).to(device)\n",
        "test_labels = torch.zeros(len(test_dataset)).to(device)\n",
        "\n",
        "def extract_features(model, dataloader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs, lbls = data\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs)\n",
        "            labels.append(lbls)\n",
        "    return torch.cat(features).to(device), torch.cat(labels).to(device)\n",
        "\n",
        "train_features, train_classes = extract_features(model, train_loader)\n",
        "other_features, other_classes = extract_features(model, other_loader)\n",
        "test_features, test_classes = extract_features(model, test_loader)\n",
        "\n",
        "combined_features = torch.cat((train_features, other_features, test_features))\n",
        "combined_classes = torch.cat((train_classes, other_classes, test_classes))\n",
        "combined_labels = torch.cat((train_labels, other_labels, test_labels))\n",
        "\n",
        "new_dataset = TensorDataset(combined_features, combined_classes, combined_labels)\n",
        "new_loader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Assuming self.attack_models is a list of trained attacker models for each class\n",
        "attack_models = mia.attack_models\n",
        "# Load your trained attack models (not shown here, replace with your actual loading mechanism)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBv8uKQTQDqU",
        "outputId": "0af356b6-f19b-41f2-baac-3c55134294a1"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a sample of 100 test examples\n",
        "sample_indices = torch.randperm(len(new_dataset))[:1000]\n",
        "test_data = torch.utils.data.Subset(new_dataset, sample_indices)\n",
        "new_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "f0DpGOgVaAx7"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a function to predict membership using attack models\n",
        "\n",
        "\n",
        "def predict_membership(attack_models, loader):\n",
        "    predicted_memberships = []\n",
        "    true_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for features, classes, labels in loader:\n",
        "        features, classes, labels = features.to(device), classes.to(device), labels.to(device)\n",
        "        print(total)\n",
        "        for i in range(len(features)):\n",
        "            cls = classes[i].item()\n",
        "            attacker_model = attack_models[cls]  # Select the attacker model for the class\n",
        "            predicted_membership = attacker_model.predict(features[i].cpu().numpy().reshape(1, -1))\n",
        "            predicted_memberships.append(predicted_membership)\n",
        "            true_labels.append(labels[i].item())\n",
        "            total += 1\n",
        "\n",
        "            correct += int(labels[i].item() == predicted_membership.item())\n",
        "    acc = float(correct/total)\n",
        "    return torch.tensor(predicted_memberships).to(device), torch.tensor(true_labels).to(device) , acc\n",
        "\n",
        "# Predict membership using the attack models\n",
        "predicted_memberships, true_labels, acc = predict_membership(attack_models, new_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg84hDZWWsQz",
        "outputId": "ed431985-f999-4b71-e979-206cdd589013"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "64\n",
            "128\n",
            "192\n",
            "256\n",
            "320\n",
            "384\n",
            "448\n",
            "512\n",
            "576\n",
            "640\n",
            "704\n",
            "768\n",
            "832\n",
            "896\n",
            "960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_memberships = predicted_memberships.cpu().numpy()  # Move to CPU\n",
        "true_labels = true_labels.cpu().numpy()  # Move to CPU"
      ],
      "metadata": {
        "id": "f3pPFnNxbh1O"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (predicted_memberships == true_labels).mean()\n",
        "print(f'Attack Model Accuracy: {accuracy:.4f}')\n",
        "\n",
        "cm = confusion_matrix(true_labels, predicted_memberships)\n",
        "precision = precision_score(true_labels, predicted_memberships)\n",
        "recall = recall_score(true_labels, predicted_memberships)\n",
        "f1 = f1_score(true_labels, predicted_memberships)\n",
        "\n",
        "print(f'Confusion Matrix:\\n{cm}')\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g07YrnfzVLR8",
        "outputId": "fcdfb308-b971-44cc-c86c-1843225debd1"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack Model Accuracy: 0.5110\n",
            "Confusion Matrix:\n",
            "[[511   0]\n",
            " [489   0]]\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1 Score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}